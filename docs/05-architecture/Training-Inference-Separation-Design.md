# OCAD í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬ ì„¤ê³„ (Training-Inference Separation Design)

## ğŸ“‹ ëª©ì°¨

1. [í˜„ì¬ ì‹œìŠ¤í…œ ë¶„ì„](#1-í˜„ì¬-ì‹œìŠ¤í…œ-ë¶„ì„)
2. [í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬ì˜ ëª©ì ê³¼ ì´ì ](#2-í•™ìŠµ-ì¶”ë¡ -ë¶„ë¦¬ì˜-ëª©ì ê³¼-ì´ì )
3. [ì•„í‚¤í…ì²˜ ì„¤ê³„](#3-ì•„í‚¤í…ì²˜-ì„¤ê³„)
4. [ë°ì´í„°ì…‹ ìš”êµ¬ì‚¬í•­ ë° êµ¬ì¡°](#4-ë°ì´í„°ì…‹-ìš”êµ¬ì‚¬í•­-ë°-êµ¬ì¡°)
5. [êµ¬í˜„ ê³„íš](#5-êµ¬í˜„-ê³„íš)
6. [ì„±ëŠ¥ ì¸¡ì • ì§€í‘œ](#6-ì„±ëŠ¥-ì¸¡ì •-ì§€í‘œ)

---

## 1. í˜„ì¬ ì‹œìŠ¤í…œ ë¶„ì„

### 1.1 í˜„ì¬ í•™ìŠµ-ì¶”ë¡  êµ¬ì¡°

OCAD ì‹œìŠ¤í…œì€ í˜„ì¬ **ì˜¨ë¼ì¸ í•™ìŠµ ë°©ì‹**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

```python
# ResidualDetector (ocad/detectors/residual.py)
class ResidualDetector:
    def detect(self, features):
        # 1. ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘
        self.history[metric_type].append(value)

        # 2. ì˜¨ë¼ì¸ í•™ìŠµ: 50ê°œ ìƒ˜í”Œ ìˆ˜ì§‘ ì‹œ ìë™ í›ˆë ¨
        if len(self.history[metric_type]) >= 50:
            self._train_model(metric_type)  # ì¶”ë¡  ì¤‘ í•™ìŠµ!

        # 3. ì˜ˆì¸¡ (ì¶”ë¡ )
        prediction = self._predict(metric_type, sequence)
        residual = abs(value - prediction)
        return score

# MultivariateDetector (ocad/detectors/multivariate.py)
class MultivariateDetector:
    def detect(self, features, capabilities):
        # 1. í”¼ì²˜ ì´ë ¥ ì €ì¥
        self.feature_history[group_key].append(features)

        # 2. ì˜¨ë¼ì¸ í•™ìŠµ: 50ê°œ ìƒ˜í”Œ ìˆ˜ì§‘ ì‹œ ìë™ í›ˆë ¨
        if len(self.feature_history[group_key]) >= 50:
            self._train_model(group_key, capabilities)  # ì¶”ë¡  ì¤‘ í•™ìŠµ!

        # 3. ì˜ˆì¸¡ (ì¶”ë¡ )
        score = self._predict_anomaly(group_key, feature_array)
        return score
```

### 1.2 í˜„ì¬ ë°©ì‹ì˜ ë¬¸ì œì 

| ë¬¸ì œì  | ì˜í–¥ | ì‹¬ê°ë„ |
|--------|------|--------|
| **ì¶”ë¡  ì§€ì—°** | í•™ìŠµì´ ì§„í–‰ë˜ëŠ” ë™ì•ˆ íƒì§€ ì¤‘ë‹¨ (TCN: 20 epoch, Isolation Forest: 100 trees) | ğŸ”´ ë†’ìŒ |
| **ì¬í˜„ì„± ë¶€ì¡±** | ë™ì¼í•œ ì¡°ê±´ì—ì„œë„ í•™ìŠµ íƒ€ì´ë°ì— ë”°ë¼ ê²°ê³¼ê°€ ë‹¬ë¼ì§ | ğŸŸ¡ ì¤‘ê°„ |
| **í‰ê°€ ë¶ˆê°€** | ì‚¬ì „ì— ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  ê²€ì¦í•  ìˆ˜ ì—†ìŒ | ğŸ”´ ë†’ìŒ |
| **ëª¨ë¸ ë²„ì „ ê´€ë¦¬ ë¶ˆê°€** | ì–´ë–¤ ëª¨ë¸ ë²„ì „ì´ ì‚¬ìš©ë˜ëŠ”ì§€ ì¶”ì  ë¶ˆê°€ | ğŸŸ¡ ì¤‘ê°„ |
| **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë¶ˆê°€** | í•™ìŠµë¥ , íˆë“  ìœ ë‹› ìˆ˜ ë“±ì„ ì‹¤í—˜ì ìœ¼ë¡œ íŠœë‹í•  ìˆ˜ ì—†ìŒ | ğŸŸ  ì¤‘ê°„-ë†’ìŒ |
| **ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìœ„í—˜** | ë¬´í•œì • ì´ë ¥ ë°ì´í„° ì €ì¥ (í˜„ì¬ëŠ” 500-1000ê°œë¡œ ì œí•œ) | ğŸŸ¡ ì¤‘ê°„ |

### 1.3 í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ AI ëª¨ë¸

| ëª¨ë¸ | íƒì§€ ë°©ë²• | í•™ìŠµ ë°©ì‹ | ë°ì´í„° ìš”êµ¬ì‚¬í•­ |
|------|----------|----------|----------------|
| **TCN** (SimpleTCN) | ì˜ˆì¸¡-ì”ì°¨ | ì˜¨ë¼ì¸ (20 epoch) | ìµœì†Œ 50ê°œ ì‹œê³„ì—´ ìƒ˜í”Œ |
| **Isolation Forest** | ë‹¤ë³€ëŸ‰ ì´ìƒ | ì˜¨ë¼ì¸ (100 trees) | ìµœì†Œ 50ê°œ ë‹¤ë³€ëŸ‰ í”¼ì²˜ ë²¡í„° |
| **CUSUM** | ë³€í™”ì  | ê·œì¹™ ê¸°ë°˜ (í•™ìŠµ ë¶ˆí•„ìš”) | N/A |
| **Rule-based** | ì„ê³„ê°’ | ê·œì¹™ ê¸°ë°˜ (í•™ìŠµ ë¶ˆí•„ìš”) | N/A |

---

## 2. í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬ì˜ ëª©ì ê³¼ ì´ì 

### 2.1 ì„¤ê³„ ëª©ì 

**í•µì‹¬ ëª©í‘œ**: í•™ìŠµ(Training)ê³¼ ì¶”ë¡ (Inference)ì„ ì™„ì „íˆ ë¶„ë¦¬í•˜ì—¬ **ì•ˆì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ** êµ¬ì¶•

```
í˜„ì¬ ë°©ì‹:
ë°ì´í„° ìˆ˜ì§‘ â†’ [í•™ìŠµ + ì¶”ë¡  í˜¼ì¬] â†’ íƒì§€ ê²°ê³¼

ìƒˆë¡œìš´ ë°©ì‹:
[ì˜¤í”„ë¼ì¸ í•™ìŠµ] â†’ í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥ â†’ [ì˜¨ë¼ì¸ ì¶”ë¡ ë§Œ] â†’ íƒì§€ ê²°ê³¼
```

### 2.2 ì£¼ìš” ì´ì 

#### 2.2.1 ì„±ëŠ¥ ë° ì•ˆì •ì„±
- âœ… **ì¼ê´€ëœ ì¶”ë¡  ì†ë„**: í•™ìŠµ ë¶€ë‹´ ì œê±°ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì§€ì—° ì‹œê°„ (<30ì´ˆ ëª©í‘œ ë‹¬ì„±)
- âœ… **ì‹¤ì‹œê°„ ë³´ì¥**: ì¶”ë¡ ë§Œ ìˆ˜í–‰í•˜ë¯€ë¡œ íƒì§€ ì¤‘ë‹¨ ì—†ìŒ
- âœ… **ë©”ëª¨ë¦¬ íš¨ìœ¨**: ì¶”ë¡  ì‹œ ëª¨ë¸ ê°€ì¤‘ì¹˜ë§Œ ë©”ëª¨ë¦¬ì— ë¡œë“œ (ì´ë ¥ ë°ì´í„° ë¶ˆí•„ìš”)

#### 2.2.2 ê°œë°œ ë° ìš´ì˜
- âœ… **ëª¨ë¸ ê²€ì¦**: ë°°í¬ ì „ ì„±ëŠ¥ ì¸¡ì • ë° ë²¤ì¹˜ë§ˆí¬ ê°€ëŠ¥
- âœ… **ë²„ì „ ê´€ë¦¬**: ëª¨ë¸ íŒŒì¼(`.pth`, `.pkl`) Git/MLflow ê´€ë¦¬
- âœ… **ë¡¤ë°± ê°€ëŠ¥**: ë¬¸ì œ ë°œìƒ ì‹œ ì´ì „ ëª¨ë¸ë¡œ ì¦‰ì‹œ ë³µêµ¬
- âœ… **A/B í…ŒìŠ¤íŒ…**: ì—¬ëŸ¬ ëª¨ë¸ ë²„ì „ ë™ì‹œ ë°°í¬ ë° ë¹„êµ

#### 2.2.3 ì—°êµ¬ ë° ê°œì„ 
- âœ… **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: Grid Search, Bayesian Optimization ì ìš©
- âœ… **ë°ì´í„°ì…‹ í™•ë³´**: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í‘œì¤€ ë°ì´í„°ì…‹ êµ¬ì¶•
- âœ… **ë²¤ì¹˜ë§ˆí¬**: ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ì •ëŸ‰ì  ë¹„êµ
- âœ… **ì „ì´ í•™ìŠµ**: ë‹¤ë¥¸ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì— ëª¨ë¸ ì¬ì‚¬ìš©

---

## 3. ì•„í‚¤í…ì²˜ ì„¤ê³„

### 3.1 ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     OCAD Training-Inference Separation          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OFFLINE TRAINING    â”‚          â”‚   ONLINE INFERENCE            â”‚
â”‚  (ocad/training/)    â”‚          â”‚   (ocad/detectors/)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[1. ë°ì´í„° ìˆ˜ì§‘]                   [1. ëª¨ë¸ ë¡œë”©]
    â†“                                  â†“
Historical Data                    Trained Models
  - Real Network Logs                - tcn_udp_echo.pth
  - Simulated Data                   - tcn_ecpri.pth
  - Injected Anomalies               - tcn_lbm.pth
    â†“                                 - isolation_forest.pkl
                                       â†“
[2. ë°ì´í„°ì…‹ ìƒì„±]                [2. ì‹¤ì‹œê°„ ì¶”ë¡ ]
    â†“                                  â†“
ocad/training/datasets/            MetricSample
  - TimeSeriesDataset                  â†“
  - MultivariateDataset            FeatureEngine
  - AnomalyDataset                     â†“
    â†“                              FeatureVector
                                       â†“
[3. ëª¨ë¸ í•™ìŠµ]                     Detectors (ì¶”ë¡ ë§Œ)
    â†“                                  â†“
Training Scripts                   Anomaly Score
  - train_tcn.py                       â†“
  - train_isolation_forest.py      AlertManager
  - hyperparameter_tuning.py
    â†“

[4. ëª¨ë¸ í‰ê°€]
    â†“
Metrics & Validation
  - Precision, Recall, F1
  - MTTD, Lead Time
  - ROC-AUC, Confusion Matrix
    â†“

[5. ëª¨ë¸ ì €ì¥]
    â†“
models/
  - tcn_udp_echo_v1.0.0.pth
  - metadata.json
  - performance_report.json
```

### 3.2 ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
ocad/
â”œâ”€â”€ training/                          # ìƒˆë¡œ ì¶”ê°€: í•™ìŠµ ì „ìš© ëª¨ë“ˆ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ datasets/                      # ë°ì´í„°ì…‹ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                    # BaseDataset ì¶”ìƒ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ timeseries_dataset.py      # TimeSeriesDataset (TCNìš©)
â”‚   â”‚   â”œâ”€â”€ multivariate_dataset.py    # MultivariateDataset (IFìš©)
â”‚   â”‚   â””â”€â”€ data_loader.py             # ë°ì´í„° ë¡œë”© ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ trainers/                      # í•™ìŠµ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_trainer.py            # BaseTrainer ì¶”ìƒ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ tcn_trainer.py             # TCN í•™ìŠµê¸°
â”‚   â”‚   â””â”€â”€ isolation_forest_trainer.py
â”‚   â”œâ”€â”€ evaluators/                    # ëª¨ë¸ í‰ê°€
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py                 # í‰ê°€ ì§€í‘œ ê³„ì‚°
â”‚   â”‚   â””â”€â”€ validator.py               # Cross-validation
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ model_saver.py             # ëª¨ë¸ ì €ì¥/ë¡œë“œ
â”‚       â””â”€â”€ hyperparameter_tuning.py   # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
â”‚
â”œâ”€â”€ detectors/                         # ê¸°ì¡´: ì¶”ë¡  ì „ìš©ìœ¼ë¡œ ë³€ê²½
â”‚   â”œâ”€â”€ base.py                        # (ìˆ˜ì •) ì¶”ë¡  ì¸í„°í˜ì´ìŠ¤ë§Œ
â”‚   â”œâ”€â”€ residual.py                    # (ìˆ˜ì •) í•™ìŠµ ì½”ë“œ ì œê±°
â”‚   â”œâ”€â”€ multivariate.py                # (ìˆ˜ì •) í•™ìŠµ ì½”ë“œ ì œê±°
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ models/                            # ìƒˆë¡œ ì¶”ê°€: í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ tcn/
â”‚   â”‚   â”œâ”€â”€ udp_echo_v1.0.0.pth
â”‚   â”‚   â”œâ”€â”€ ecpri_v1.0.0.pth
â”‚   â”‚   â””â”€â”€ lbm_v1.0.0.pth
â”‚   â”œâ”€â”€ isolation_forest/
â”‚   â”‚   â””â”€â”€ multivariate_v1.0.0.pkl
â”‚   â””â”€â”€ metadata/
â”‚       â”œâ”€â”€ tcn_udp_echo_v1.0.0.json
â”‚       â””â”€â”€ performance_reports/
â”‚
â”œâ”€â”€ data/                              # ìƒˆë¡œ ì¶”ê°€: í•™ìŠµ ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ raw/                           # ì›ì‹œ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ oran_logs_2024/
â”‚   â”‚   â””â”€â”€ simulated_data/
â”‚   â”œâ”€â”€ processed/                     # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ timeseries_train.parquet
â”‚   â”‚   â”œâ”€â”€ timeseries_val.parquet
â”‚   â”‚   â”œâ”€â”€ timeseries_test.parquet
â”‚   â”‚   â””â”€â”€ anomaly_labels.csv
â”‚   â””â”€â”€ synthetic/                     # í•©ì„± ë°ì´í„°
â”‚       â””â”€â”€ injected_anomalies.parquet
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ train_tcn_model.py             # ìƒˆë¡œ ì¶”ê°€: TCN í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
    â”œâ”€â”€ train_isolation_forest.py      # ìƒˆë¡œ ì¶”ê°€: IF í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
    â”œâ”€â”€ evaluate_models.py             # ìƒˆë¡œ ì¶”ê°€: ëª¨ë¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
    â””â”€â”€ generate_training_data.py      # ìƒˆë¡œ ì¶”ê°€: í•™ìŠµ ë°ì´í„° ìƒì„±
```

### 3.3 í´ë˜ìŠ¤ ì„¤ê³„

#### 3.3.1 í•™ìŠµ íŒŒì´í”„ë¼ì¸

```python
# ocad/training/trainers/base_trainer.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
import torch
from pathlib import Path

class BaseTrainer(ABC):
    """ëª¨ë“  í•™ìŠµê¸°ì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.model = None
        self.optimizer = None
        self.best_metrics = {}

    @abstractmethod
    def build_model(self) -> Any:
        """ëª¨ë¸ ì•„í‚¤í…ì²˜ êµ¬ì„±"""
        pass

    @abstractmethod
    def train_epoch(self, train_loader) -> Dict[str, float]:
        """1 ì—í¬í¬ í•™ìŠµ"""
        pass

    @abstractmethod
    def validate(self, val_loader) -> Dict[str, float]:
        """ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€"""
        pass

    def train(self, train_loader, val_loader, epochs: int):
        """ì „ì²´ í•™ìŠµ í”„ë¡œì„¸ìŠ¤"""
        for epoch in range(epochs):
            train_metrics = self.train_epoch(train_loader)
            val_metrics = self.validate(val_loader)

            if self._is_best_model(val_metrics):
                self.save_checkpoint()

    def save_checkpoint(self, path: Path):
        """ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        pass

    def load_checkpoint(self, path: Path):
        """ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        pass


# ocad/training/trainers/tcn_trainer.py
class TCNTrainer(BaseTrainer):
    """TCN ëª¨ë¸ í•™ìŠµê¸°"""

    def build_model(self):
        return SimpleTCN(
            input_size=self.config.input_size,
            hidden_size=self.config.hidden_size,
            output_size=1
        )

    def train_epoch(self, train_loader):
        self.model.train()
        total_loss = 0.0

        for batch_x, batch_y in train_loader:
            self.optimizer.zero_grad()
            predictions = self.model(batch_x)
            loss = self.criterion(predictions, batch_y)
            loss.backward()
            self.optimizer.step()
            total_loss += loss.item()

        return {"train_loss": total_loss / len(train_loader)}

    def validate(self, val_loader):
        self.model.eval()
        val_loss = 0.0
        predictions_list = []
        targets_list = []

        with torch.no_grad():
            for batch_x, batch_y in val_loader:
                predictions = self.model(batch_x)
                loss = self.criterion(predictions, batch_y)
                val_loss += loss.item()
                predictions_list.extend(predictions.cpu().numpy())
                targets_list.extend(batch_y.cpu().numpy())

        # í‰ê°€ ì§€í‘œ ê³„ì‚°
        mse = mean_squared_error(targets_list, predictions_list)
        mae = mean_absolute_error(targets_list, predictions_list)

        return {
            "val_loss": val_loss / len(val_loader),
            "mse": mse,
            "mae": mae
        }
```

#### 3.3.2 ì¶”ë¡  íŒŒì´í”„ë¼ì¸

```python
# ocad/detectors/residual.py (ìˆ˜ì • ë²„ì „)
class ResidualDetector(BaseDetector):
    """ì”ì°¨ ê¸°ë°˜ íƒì§€ê¸° (ì¶”ë¡  ì „ìš©)"""

    def __init__(self, config, model_path: Optional[Path] = None):
        super().__init__(config)

        # í•™ìŠµ ì½”ë“œ ì™„ì „ ì œê±°
        # self.history = {}  # ì‚­ì œ
        # self._train_model() # ì‚­ì œ

        # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
        self.models = self._load_pretrained_models(model_path)
        self.scalers = self._load_scalers(model_path)

        # ì¶”ë¡ ì„ ìœ„í•œ ìµœì†Œ ë²„í¼ë§Œ ìœ ì§€ (sequence_lengthë§Œí¼)
        self.inference_buffer = {
            "udp_echo": deque(maxlen=10),
            "ecpri": deque(maxlen=10),
            "lbm": deque(maxlen=10),
        }

    def _load_pretrained_models(self, model_path: Path) -> Dict:
        """ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ"""
        models = {}
        model_dir = model_path or Path("ocad/models/tcn/")

        for metric_type in ["udp_echo", "ecpri", "lbm"]:
            model_file = model_dir / f"{metric_type}_v1.0.0.pth"
            if model_file.exists():
                checkpoint = torch.load(model_file)
                model = SimpleTCN(
                    input_size=checkpoint['config']['input_size'],
                    hidden_size=checkpoint['config']['hidden_size'],
                    output_size=1
                )
                model.load_state_dict(checkpoint['model_state_dict'])
                model.eval()  # ì¶”ë¡  ëª¨ë“œ
                models[metric_type] = model

                self.logger.info(
                    "Pretrained model loaded",
                    metric_type=metric_type,
                    version=checkpoint['version'],
                    trained_on=checkpoint['metadata']['training_date']
                )

        return models

    def detect(self, features: FeatureVector, capabilities: Capabilities) -> float:
        """ì´ìƒ íƒì§€ (ì¶”ë¡ ë§Œ ìˆ˜í–‰)"""
        residuals = []

        if capabilities.udp_echo and features.udp_echo_p95 is not None:
            residual = self._calculate_residual(
                "udp_echo",
                features.udp_echo_p95,
                features.endpoint_id
            )
            if residual is not None:
                residuals.append(residual)

        # ... (ë‚˜ë¨¸ì§€ ë©”íŠ¸ë¦­ ë™ì¼)

        if not residuals:
            return 0.0

        max_residual = max(residuals)
        score = min(1.0, max_residual / self.config.residual_threshold)

        return score

    def _calculate_residual(self, metric_type: str, value: float, endpoint_id: str) -> Optional[float]:
        """ì”ì°¨ ê³„ì‚° (ì¶”ë¡ ë§Œ)"""
        # ì¶”ë¡  ë²„í¼ì— ì¶”ê°€
        self.inference_buffer[metric_type].append(value)

        # ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ëŒ€ê¸°
        if len(self.inference_buffer[metric_type]) < 10:
            return None

        # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì‚¬ìš© ë¶ˆê°€
        if metric_type not in self.models:
            self.logger.warning(
                "No pretrained model available",
                metric_type=metric_type
            )
            return None

        try:
            # ì˜ˆì¸¡ ìˆ˜í–‰ (í•™ìŠµ ì—†ìŒ!)
            sequence = list(self.inference_buffer[metric_type])[-10:]
            prediction = self._predict(metric_type, sequence)

            if prediction is not None:
                residual = abs(value - prediction)

                # ì •ê·œí™”
                recent_values = list(self.inference_buffer[metric_type])[-20:]
                if len(recent_values) > 3:
                    std_dev = np.std(recent_values)
                    if std_dev > 0:
                        return residual / std_dev

                return residual

        except Exception as e:
            self.logger.error(
                "Inference failed",
                metric_type=metric_type,
                error=str(e)
            )

        return None

    def _predict(self, metric_type: str, sequence: List[float]) -> Optional[float]:
        """ì˜ˆì¸¡ ìˆ˜í–‰ (ì¶”ë¡  ì „ìš©)"""
        model = self.models[metric_type]
        scaler = self.scalers[metric_type]

        # ì •ê·œí™”
        sequence_array = np.array(sequence).reshape(-1, 1)
        sequence_scaled = scaler.transform(sequence_array).flatten()

        # ì˜ˆì¸¡
        with torch.no_grad():
            x_tensor = torch.FloatTensor(sequence_scaled).unsqueeze(0).unsqueeze(0)
            prediction_scaled = model(x_tensor).item()

        # ì—­ì •ê·œí™”
        prediction = scaler.inverse_transform([[prediction_scaled]])[0][0]

        return prediction
```

---

## 4. ë°ì´í„°ì…‹ ìš”êµ¬ì‚¬í•­ ë° êµ¬ì¡°

### 4.1 ì¸¡ì • ì§€í‘œë³„ ë°ì´í„°ì…‹ ìš”êµ¬ì‚¬í•­

í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬ë¥¼ ìœ„í•´ì„œëŠ” ê° íƒì§€ ë°©ë²•ë¡ ì— ë§ëŠ” **í‘œì¤€ ë°ì´í„°ì…‹**ì´ í•„ìš”í•©ë‹ˆë‹¤.

#### 4.1.1 TCN ì‹œê³„ì—´ ì˜ˆì¸¡ ë°ì´í„°ì…‹

**ëª©ì **: ì‹œê³„ì—´ ê°’ì„ ì˜ˆì¸¡í•˜ì—¬ ì”ì°¨ë¡œ ì´ìƒ íƒì§€

**ë°ì´í„° êµ¬ì¡°**:
```python
{
    "metric_type": "udp_echo" | "ecpri" | "lbm",
    "endpoint_id": "o-ru-001",
    "timestamp_ms": 1234567890000,
    "sequence": [5.1, 5.3, 5.2, 5.4, 5.3, 5.5, 5.4, 5.6, 5.5, 5.7],  # 10ê°œ ì‹œê³„ì—´
    "target": 5.8,  # ë‹¤ìŒ ê°’
    "is_anomaly": false,  # ë¼ë²¨ (ì„ íƒ)
    "anomaly_type": null | "spike" | "drift" | "loss"  # ì´ìƒ ìœ í˜•
}
```

**ìˆ˜ì§‘ ë°©ë²•**:
1. **ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ ë¡œê·¸** (ìµœìš°ì„ )
   - ì •ìƒ ìš´ì˜ ë°ì´í„°: 80%
   - ì‹¤ì œ ì¥ì•  ë°ì´í„°: 20%

2. **ì‹œë®¬ë ˆì´í„° ìƒì„± ë°ì´í„°**
   - `ocad/utils/simulator.py` í™œìš©
   - ì •ìƒ íŒ¨í„´: í‰ê·  5ms, í‘œì¤€í¸ì°¨ 0.5ms
   - ì´ìƒ íŒ¨í„´ ì£¼ì…: ìŠ¤íŒŒì´í¬, ë“œë¦¬í”„íŠ¸, íŒ¨í‚· ì†ì‹¤

3. **í•©ì„± ì´ìƒ ì£¼ì…**
   ```python
   # ìŠ¤íŒŒì´í¬: ê¸‰ê²©í•œ ì§€ì—° ì¦ê°€
   spike_pattern = normal_data.copy()
   spike_pattern[50:60] += 20  # 10ms â†’ 30ms

   # ë“œë¦¬í”„íŠ¸: ì ì§„ì  ì„±ëŠ¥ ì €í•˜
   drift_pattern = normal_data.copy()
   drift_pattern += np.linspace(0, 10, len(drift_pattern))

   # íŒ¨í‚· ì†ì‹¤: ë¶ˆê·œì¹™í•œ ê°’
   loss_pattern = normal_data.copy()
   loss_pattern[::5] = np.nan  # 20% ì†ì‹¤
   ```

**ë°ì´í„°ì…‹ í¬ê¸°**:
- í›ˆë ¨ ë°ì´í„°: ìµœì†Œ 10,000 ì‹œí€€ìŠ¤ (ì•½ 100,000 ìƒ˜í”Œ)
- ê²€ì¦ ë°ì´í„°: 2,000 ì‹œí€€ìŠ¤
- í…ŒìŠ¤íŠ¸ ë°ì´í„°: 2,000 ì‹œí€€ìŠ¤
- **ì´ìƒ ë¹„ìœ¨**: 5-10% (ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ ë°˜ì˜)

#### 4.1.2 Isolation Forest ë‹¤ë³€ëŸ‰ ë°ì´í„°ì…‹

**ëª©ì **: ì—¬ëŸ¬ ë©”íŠ¸ë¦­ ê°„ ë³µí•© íŒ¨í„´ìœ¼ë¡œ ì´ìƒ íƒì§€

**ë°ì´í„° êµ¬ì¡°**:
```python
{
    "endpoint_id": "o-ru-001",
    "timestamp_ms": 1234567890000,
    "features": {
        # UDP Echo í”¼ì²˜
        "udp_echo_p95": 5.2,
        "udp_echo_p99": 5.8,
        "udp_echo_slope": 0.01,
        "cusum_udp_echo": 0.3,

        # eCPRI í”¼ì²˜
        "ecpri_p95": 98.5,
        "ecpri_p99": 102.3,
        "ecpri_slope": -0.02,
        "cusum_ecpri": 0.1,

        # LBM í”¼ì²˜
        "lbm_rtt_p95": 8.1,
        "lbm_rtt_p99": 8.6,
        "lbm_slope": 0.005,
        "cusum_lbm": 0.2,
        "lbm_fail_runlen": 0
    },
    "is_anomaly": false,
    "anomaly_type": null | "concurrent" | "correlated"
}
```

**ìˆ˜ì§‘ ë°©ë²•**:
1. **FeatureEngine ì¶œë ¥ ìˆ˜ì§‘**
   - `ocad/features/engine.py`ì—ì„œ ìƒì„±ëœ FeatureVector ì €ì¥
   - 5ë¶„ ìœˆë„ìš°ë§ˆë‹¤ 1ê°œ í”¼ì²˜ ë²¡í„° ìƒì„±

2. **ë‹¤ë³€ëŸ‰ ì´ìƒ íŒ¨í„´**
   ```python
   # ë™ì‹œì„± ì´ìƒ: ì—¬ëŸ¬ ë©”íŠ¸ë¦­ì´ ë™ì‹œì— ì¦ê°€
   concurrent_anomaly = {
       "udp_echo_p95": 15.0,  # ì •ìƒ 5.0 â†’ ì´ìƒ 15.0
       "ecpri_p95": 250.0,    # ì •ìƒ 100.0 â†’ ì´ìƒ 250.0
       "lbm_rtt_p95": 20.0,   # ì •ìƒ 8.0 â†’ ì´ìƒ 20.0
   }

   # ìƒê´€ê´€ê³„ ì´ìƒ: UDPëŠ” ì •ìƒ, eCPRIë§Œ ì¦ê°€ (ë¹„ì •ìƒ íŒ¨í„´)
   correlated_anomaly = {
       "udp_echo_p95": 5.2,   # ì •ìƒ
       "ecpri_p95": 300.0,    # ì´ìƒ (UDP ì •ìƒì¸ë° eCPRIë§Œ ë†’ìŒ)
       "lbm_rtt_p95": 8.1,    # ì •ìƒ
   }
   ```

**ë°ì´í„°ì…‹ í¬ê¸°**:
- í›ˆë ¨ ë°ì´í„°: ìµœì†Œ 5,000 í”¼ì²˜ ë²¡í„°
- ê²€ì¦ ë°ì´í„°: 1,000 í”¼ì²˜ ë²¡í„°
- í…ŒìŠ¤íŠ¸ ë°ì´í„°: 1,000 í”¼ì²˜ ë²¡í„°

### 4.2 ë°ì´í„°ì…‹ íŒŒì¼ í¬ë§·

#### 4.2.1 ì‹œê³„ì—´ ë°ì´í„°ì…‹ (Parquet)

```python
# data/processed/timeseries_train.parquet
import pandas as pd

df = pd.DataFrame({
    'endpoint_id': ['o-ru-001', 'o-ru-001', ...],
    'metric_type': ['udp_echo', 'udp_echo', ...],
    'timestamp_ms': [1234567890000, 1234567890100, ...],
    'sequence': [  # List[float] ì €ì¥ ê°€ëŠ¥
        [5.1, 5.3, 5.2, 5.4, 5.3, 5.5, 5.4, 5.6, 5.5, 5.7],
        [5.3, 5.2, 5.4, 5.3, 5.5, 5.4, 5.6, 5.5, 5.7, 5.8],
        ...
    ],
    'target': [5.8, 5.9, ...],
    'is_anomaly': [False, False, True, ...],
    'anomaly_type': [None, None, 'spike', ...]
})

df.to_parquet('data/processed/timeseries_train.parquet')
```

**ì¥ì **:
- ë¹ ë¥¸ ì½ê¸°/ì“°ê¸° ì†ë„
- ì••ì¶• íš¨ìœ¨ (CSV ëŒ€ë¹„ 10ë°°)
- List íƒ€ì… ì €ì¥ ê°€ëŠ¥
- Pandasì™€ ì™„ë²½ í˜¸í™˜

#### 4.2.2 ë¼ë²¨ ë°ì´í„° (CSV)

```csv
# data/processed/anomaly_labels.csv
endpoint_id,timestamp_ms,is_anomaly,anomaly_type,severity,description
o-ru-001,1234567890000,true,spike,critical,ê¸‰ê²©í•œ UDP Echo ì§€ì—° ì¦ê°€ (5ms â†’ 30ms)
o-ru-002,1234567891000,true,drift,warning,ì ì§„ì  eCPRI ì§€ì—° ì¦ê°€ (100Î¼s â†’ 200Î¼s)
o-du-001,1234567892000,true,loss,critical,LBM íŒ¨í‚· ì†ì‹¤ 50%
```

### 4.3 ë°ì´í„°ì…‹ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/generate_training_data.py
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
from ocad.utils.simulator import VirtualEndpoint
from ocad.features.engine import FeatureEngine
from ocad.core.config import Settings

def generate_timeseries_dataset(
    num_endpoints: int = 10,
    duration_hours: int = 24,
    anomaly_rate: float = 0.1,
    output_dir: Path = Path("data/processed")
):
    """ì‹œê³„ì—´ í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±"""

    sequences = []

    for endpoint_id in range(num_endpoints):
        # ê°€ìƒ ì—”ë“œí¬ì¸íŠ¸ ìƒì„±
        endpoint = VirtualEndpoint(
            endpoint_id=f"o-ru-{endpoint_id:03d}",
            role="o-ru"
        )

        # ì •ìƒ ë°ì´í„° ìƒì„±
        for hour in range(duration_hours):
            for minute in range(0, 60, 5):  # 5ë¶„ë§ˆë‹¤
                # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                samples = []
                for _ in range(10):  # 10ê°œ ì‹œí€€ìŠ¤
                    sample = endpoint.collect_metrics()
                    samples.append(sample['udp_echo_rtt_ms'])

                target = endpoint.collect_metrics()['udp_echo_rtt_ms']

                # ì´ìƒ ì£¼ì…
                is_anomaly = np.random.random() < anomaly_rate
                if is_anomaly:
                    anomaly_type = np.random.choice(['spike', 'drift', 'loss'])
                    target = inject_anomaly(target, anomaly_type)
                else:
                    anomaly_type = None

                sequences.append({
                    'endpoint_id': endpoint.endpoint_id,
                    'metric_type': 'udp_echo',
                    'timestamp_ms': int(time.time() * 1000),
                    'sequence': samples,
                    'target': target,
                    'is_anomaly': is_anomaly,
                    'anomaly_type': anomaly_type
                })

    # DataFrame ì €ì¥
    df = pd.DataFrame(sequences)

    # Train/Val/Test ë¶„í•  (70/15/15)
    train_df = df.sample(frac=0.7, random_state=42)
    remaining = df.drop(train_df.index)
    val_df = remaining.sample(frac=0.5, random_state=42)
    test_df = remaining.drop(val_df.index)

    # ì €ì¥
    output_dir.mkdir(parents=True, exist_ok=True)
    train_df.to_parquet(output_dir / "timeseries_train.parquet")
    val_df.to_parquet(output_dir / "timeseries_val.parquet")
    test_df.to_parquet(output_dir / "timeseries_test.parquet")

    print(f"âœ… Generated {len(df)} sequences")
    print(f"   Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}")
    print(f"   Anomaly rate: {df['is_anomaly'].mean():.1%}")

def inject_anomaly(value: float, anomaly_type: str) -> float:
    """ì´ìƒ íŒ¨í„´ ì£¼ì…"""
    if anomaly_type == 'spike':
        return value + np.random.uniform(15, 25)  # ê¸‰ê²©í•œ ì¦ê°€
    elif anomaly_type == 'drift':
        return value + np.random.uniform(5, 10)   # ì ì§„ì  ì¦ê°€
    elif anomaly_type == 'loss':
        return np.nan if np.random.random() < 0.5 else value
    return value

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--endpoints", type=int, default=10)
    parser.add_argument("--duration-hours", type=int, default=24)
    parser.add_argument("--anomaly-rate", type=float, default=0.1)
    args = parser.parse_args()

    generate_timeseries_dataset(
        num_endpoints=args.endpoints,
        duration_hours=args.duration_hours,
        anomaly_rate=args.anomaly_rate
    )
```

---

## 5. êµ¬í˜„ ê³„íš

### 5.1 Phase 1: ì¸í”„ë¼ êµ¬ì¶• (Week 1-2)

**ëª©í‘œ**: í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬ë¥¼ ìœ„í•œ ê¸°ë³¸ ì¸í”„ë¼ êµ¬ì¶•

#### Task 1.1: ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
```bash
mkdir -p ocad/training/{datasets,trainers,evaluators,utils}
mkdir -p ocad/models/{tcn,isolation_forest,metadata}
mkdir -p data/{raw,processed,synthetic}
touch ocad/training/__init__.py
touch ocad/training/datasets/__init__.py
touch ocad/training/trainers/__init__.py
```

#### Task 1.2: BaseTrainer êµ¬í˜„
- íŒŒì¼: `ocad/training/trainers/base_trainer.py`
- ë‚´ìš©: ì¶”ìƒ í´ë˜ìŠ¤, í•™ìŠµ ë£¨í”„, ì²´í¬í¬ì¸íŠ¸ ì €ì¥/ë¡œë“œ
- í…ŒìŠ¤íŠ¸: `tests/unit/test_base_trainer.py`

#### Task 1.3: ë°ì´í„°ì…‹ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
- íŒŒì¼: `scripts/generate_training_data.py`
- ê¸°ëŠ¥:
  - ì‹œë®¬ë ˆì´í„°ë¡œ 10ê°œ ì—”ë“œí¬ì¸íŠ¸ Ã— 24ì‹œê°„ ë°ì´í„° ìƒì„±
  - ì´ìƒ íŒ¨í„´ ì£¼ì… (spike, drift, loss)
  - Train/Val/Test ë¶„í•  (70/15/15)
  - Parquet í˜•ì‹ ì €ì¥

#### Task 1.4: ëª¨ë¸ ì €ì¥/ë¡œë“œ ìœ í‹¸ë¦¬í‹°
- íŒŒì¼: `ocad/training/utils/model_saver.py`
- ê¸°ëŠ¥:
  ```python
  class ModelSaver:
      def save_model(self, model, path, metadata):
          """ëª¨ë¸ + ë©”íƒ€ë°ì´í„° ì €ì¥"""
          torch.save({
              'model_state_dict': model.state_dict(),
              'config': model.config,
              'version': metadata['version'],
              'training_date': metadata['training_date'],
              'performance': metadata['performance']
          }, path)

      def load_model(self, model_class, path):
          """ëª¨ë¸ ë¡œë“œ"""
          checkpoint = torch.load(path)
          model = model_class(**checkpoint['config'])
          model.load_state_dict(checkpoint['model_state_dict'])
          return model, checkpoint['metadata']
  ```

**ì‚°ì¶œë¬¼**:
- âœ… í•™ìŠµ ì¸í”„ë¼ ì½”ë“œ
- âœ… ìƒ˜í”Œ ë°ì´í„°ì…‹ (10,000 ì‹œí€€ìŠ¤)
- âœ… ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

---

### 5.2 Phase 2: TCN ëª¨ë¸ í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬ (Week 3-4)

**ëª©í‘œ**: ResidualDetectorë¥¼ í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬ ì•„í‚¤í…ì²˜ë¡œ ì „í™˜

#### Task 2.1: TCNTrainer êµ¬í˜„
- íŒŒì¼: `ocad/training/trainers/tcn_trainer.py`
- ê¸°ëŠ¥:
  - SimpleTCN í•™ìŠµ
  - í•˜ì´í¼íŒŒë¼ë¯¸í„°: learning_rate, hidden_size, num_epochs
  - Early stopping (validation loss ê¸°ì¤€)
  - ëª¨ë¸ ì €ì¥ (`.pth` í˜•ì‹)

#### Task 2.2: TCN í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
- íŒŒì¼: `scripts/train_tcn_model.py`
- ì‚¬ìš©ë²•:
  ```bash
  python scripts/train_tcn_model.py \
      --metric-type udp_echo \
      --data-path data/processed/timeseries_train.parquet \
      --epochs 50 \
      --batch-size 32 \
      --learning-rate 0.001 \
      --hidden-size 32 \
      --output models/tcn/udp_echo_v1.0.0.pth
  ```

#### Task 2.3: ResidualDetector ì¶”ë¡  ì „ìš© ë³€í™˜
- íŒŒì¼: `ocad/detectors/residual.py`
- ë³€ê²½ì‚¬í•­:
  - âŒ `self.history` ì‚­ì œ
  - âŒ `_train_model()` ë©”ì„œë“œ ì‚­ì œ
  - âœ… `_load_pretrained_models()` ì¶”ê°€
  - âœ… `inference_buffer` (sequence_lengthë§Œí¼ë§Œ ìœ ì§€)
  - âœ… `detect()` ë©”ì„œë“œì—ì„œ í•™ìŠµ ë¡œì§ ì œê±°

#### Task 2.4: ëª¨ë¸ í‰ê°€
- íŒŒì¼: `scripts/evaluate_models.py`
- í‰ê°€ ì§€í‘œ:
  - MSE, MAE (ì˜ˆì¸¡ ì •í™•ë„)
  - Precision, Recall, F1 (ì´ìƒ íƒì§€ ì„±ëŠ¥)
  - Lead Time (ì¡°ê¸° ê²½ê³  ì‹œê°„)
  - Inference Latency (ì¶”ë¡  ì§€ì—°)

**ì‚°ì¶œë¬¼**:
- âœ… í›ˆë ¨ëœ TCN ëª¨ë¸ (udp_echo, ecpri, lbm)
- âœ… ì„±ëŠ¥ ë¦¬í¬íŠ¸ (performance_report.json)
- âœ… ì¶”ë¡  ì „ìš© ResidualDetector
- âœ… ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

---

### 5.3 Phase 3: Isolation Forest í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬ (Week 5)

**ëª©í‘œ**: MultivariateDetectorë¥¼ í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬ ì•„í‚¤í…ì²˜ë¡œ ì „í™˜

#### Task 3.1: ë‹¤ë³€ëŸ‰ ë°ì´í„°ì…‹ ìƒì„±
- íŒŒì¼: `scripts/generate_multivariate_data.py`
- ê¸°ëŠ¥:
  - FeatureEngineìœ¼ë¡œ í”¼ì²˜ ë²¡í„° ìƒì„±
  - ë‹¤ë³€ëŸ‰ ì´ìƒ íŒ¨í„´ ì£¼ì… (concurrent, correlated)
  - 5,000ê°œ í”¼ì²˜ ë²¡í„° ìƒì„±

#### Task 3.2: IsolationForestTrainer êµ¬í˜„
- íŒŒì¼: `ocad/training/trainers/isolation_forest_trainer.py`
- ê¸°ëŠ¥:
  - Scikit-learn IsolationForest í•™ìŠµ
  - Cross-validation (5-fold)
  - ëª¨ë¸ ì €ì¥ (`.pkl` í˜•ì‹)

#### Task 3.3: MultivariateDetector ì¶”ë¡  ì „ìš© ë³€í™˜
- íŒŒì¼: `ocad/detectors/multivariate.py`
- ë³€ê²½ì‚¬í•­:
  - âŒ `feature_history` ì‚­ì œ
  - âŒ `_train_model()` ë©”ì„œë“œ ì‚­ì œ
  - âœ… `_load_pretrained_model()` ì¶”ê°€
  - âœ… ì¶”ë¡ ë§Œ ìˆ˜í–‰

**ì‚°ì¶œë¬¼**:
- âœ… í›ˆë ¨ëœ Isolation Forest ëª¨ë¸
- âœ… ì¶”ë¡  ì „ìš© MultivariateDetector

---

### 5.4 Phase 4: í†µí•© ë° ê²€ì¦ (Week 6)

**ëª©í‘œ**: ì „ì²´ ì‹œìŠ¤í…œ í†µí•© ë° ì„±ëŠ¥ ê²€ì¦

#### Task 4.1: ëª¨ë¸ ë²„ì „ ê´€ë¦¬
- Git LFS ì„¤ì • (ëŒ€ìš©ëŸ‰ ëª¨ë¸ íŒŒì¼)
  ```bash
  git lfs install
  git lfs track "*.pth"
  git lfs track "*.pkl"
  ```

#### Task 4.2: í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- íŒŒì¼: `ocad/training/utils/hyperparameter_tuning.py`
- ë¼ì´ë¸ŒëŸ¬ë¦¬: Optuna
- íŠœë‹ ëŒ€ìƒ:
  - TCN: learning_rate, hidden_size, num_layers
  - Isolation Forest: n_estimators, contamination

#### Task 4.3: A/B í…ŒìŠ¤íŒ… í”„ë ˆì„ì›Œí¬
- ì—¬ëŸ¬ ëª¨ë¸ ë²„ì „ ë™ì‹œ ë°°í¬
- ì„±ëŠ¥ ë¹„êµ (MTTD, FAR, Lead Time)

#### Task 4.4: ë¬¸ì„œ ì—…ë°ì´íŠ¸
- CLAUDE.mdì— í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬ ì„¤ëª… ì¶”ê°€
- README.mdì— í•™ìŠµ ëª…ë ¹ì–´ ì¶”ê°€
- API.mdì— ëª¨ë¸ ê´€ë¦¬ API ì¶”ê°€

**ì‚°ì¶œë¬¼**:
- âœ… ìµœì í™”ëœ ëª¨ë¸ (v1.1.0)
- âœ… A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼
- âœ… ì™„ì „í•œ ë¬¸ì„œí™”

---

### 5.5 Phase 5: ìë™í™” ë° MLOps (Week 7-8)

**ëª©í‘œ**: í•™ìŠµ-ë°°í¬ ìë™í™” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

#### Task 5.1: MLflow í†µí•© (ì„ íƒ)
```python
import mlflow

with mlflow.start_run():
    mlflow.log_param("learning_rate", 0.001)
    mlflow.log_param("hidden_size", 32)

    # í•™ìŠµ
    trainer.train(train_loader, val_loader, epochs=50)

    mlflow.log_metric("val_loss", val_loss)
    mlflow.log_metric("f1_score", f1)

    # ëª¨ë¸ ì €ì¥
    mlflow.pytorch.log_model(model, "tcn_model")
```

#### Task 5.2: CI/CD íŒŒì´í”„ë¼ì¸
```yaml
# .github/workflows/train_models.yml
name: Train Models

on:
  schedule:
    - cron: '0 0 * * 0'  # ë§¤ì£¼ ì¼ìš”ì¼

jobs:
  train:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Generate training data
        run: python scripts/generate_training_data.py

      - name: Train TCN models
        run: |
          python scripts/train_tcn_model.py --metric-type udp_echo
          python scripts/train_tcn_model.py --metric-type ecpri
          python scripts/train_tcn_model.py --metric-type lbm

      - name: Evaluate models
        run: python scripts/evaluate_models.py

      - name: Upload artifacts
        uses: actions/upload-artifact@v2
        with:
          name: trained-models
          path: ocad/models/
```

**ì‚°ì¶œë¬¼**:
- âœ… MLflow ì‹¤í—˜ ì¶”ì 
- âœ… ìë™ í•™ìŠµ íŒŒì´í”„ë¼ì¸
- âœ… ëª¨ë¸ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ

---

## 6. ì„±ëŠ¥ ì¸¡ì • ì§€í‘œ

### 6.1 ëª¨ë¸ í‰ê°€ ì§€í‘œ

#### 6.1.1 ì˜ˆì¸¡ ì •í™•ë„ (TCN)

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œê°’ |
|------|------|--------|
| **MSE** (Mean Squared Error) | ì˜ˆì¸¡ ì˜¤ì°¨ ì œê³±ì˜ í‰ê·  | < 1.0 msÂ² |
| **MAE** (Mean Absolute Error) | ì˜ˆì¸¡ ì˜¤ì°¨ ì ˆëŒ€ê°’ì˜ í‰ê·  | < 0.5 ms |
| **RMSE** (Root MSE) | MSEì˜ ì œê³±ê·¼ | < 1.0 ms |
| **RÂ² Score** | ê²°ì • ê³„ìˆ˜ (ì„¤ëª…ë ¥) | > 0.85 |

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def evaluate_tcn(predictions, targets):
    mse = mean_squared_error(targets, predictions)
    mae = mean_absolute_error(targets, predictions)
    rmse = np.sqrt(mse)
    r2 = r2_score(targets, predictions)

    return {
        "mse": mse,
        "mae": mae,
        "rmse": rmse,
        "r2_score": r2
    }
```

#### 6.1.2 ì´ìƒ íƒì§€ ì„±ëŠ¥

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œê°’ |
|------|------|--------|
| **Precision** | ì •ë°€ë„ (íƒì§€ ì¤‘ ì‹¤ì œ ì´ìƒ ë¹„ìœ¨) | > 0.90 |
| **Recall** | ì¬í˜„ìœ¨ (ì‹¤ì œ ì´ìƒ ì¤‘ íƒì§€ ë¹„ìœ¨) | > 0.85 |
| **F1-Score** | Precisionê³¼ Recallì˜ ì¡°í™”í‰ê·  | > 0.87 |
| **FAR** (False Alarm Rate) | ì˜¤íƒë¥  | < 0.06 |
| **ROC-AUC** | ROC ê³¡ì„  ì•„ë˜ ë©´ì  | > 0.92 |

```python
from sklearn.metrics import precision_recall_fscore_support, roc_auc_score

def evaluate_anomaly_detection(y_true, y_pred, y_scores):
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_true, y_pred, average='binary'
    )

    far = (y_pred == 1).sum() / len(y_pred) - precision
    roc_auc = roc_auc_score(y_true, y_scores)

    return {
        "precision": precision,
        "recall": recall,
        "f1_score": f1,
        "false_alarm_rate": far,
        "roc_auc": roc_auc
    }
```

#### 6.1.3 ìš´ì˜ ì§€í‘œ

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œê°’ |
|------|------|--------|
| **MTTD** (Mean Time To Detect) | í‰ê·  íƒì§€ ì‹œê°„ | < 20ì´ˆ (ë£° ëŒ€ë¹„ 30% ë‹¨ì¶•) |
| **Lead Time** | ì¡°ê¸° ê²½ê³  ì‹œê°„ | â‰¥ 4ë¶„ (P50) |
| **Inference Latency** | ì¶”ë¡  ì§€ì—° ì‹œê°„ | < 100ms (P95) |
| **Model Size** | ëª¨ë¸ íŒŒì¼ í¬ê¸° | < 10MB |
| **Memory Usage** | ì¶”ë¡  ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | < 100MB |

```python
import time
import psutil

def benchmark_inference(detector, feature_vectors):
    latencies = []

    for features in feature_vectors:
        start = time.time()
        score = detector.detect(features)
        latency = (time.time() - start) * 1000  # ms
        latencies.append(latency)

    memory_mb = psutil.Process().memory_info().rss / 1024 / 1024

    return {
        "mean_latency_ms": np.mean(latencies),
        "p95_latency_ms": np.percentile(latencies, 95),
        "p99_latency_ms": np.percentile(latencies, 99),
        "memory_usage_mb": memory_mb
    }
```

### 6.2 ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±

```python
# scripts/evaluate_models.py
def generate_performance_report(model_path, test_data):
    """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""

    report = {
        "model_info": {
            "name": "TCN UDP Echo Predictor",
            "version": "v1.0.0",
            "training_date": "2024-01-15",
            "architecture": "SimpleTCN (3 layers, 32 hidden units)",
            "parameters": 3456
        },
        "prediction_accuracy": {
            "mse": 0.85,
            "mae": 0.42,
            "rmse": 0.92,
            "r2_score": 0.89
        },
        "anomaly_detection": {
            "precision": 0.92,
            "recall": 0.87,
            "f1_score": 0.89,
            "false_alarm_rate": 0.05,
            "roc_auc": 0.94
        },
        "operational_metrics": {
            "mttd_seconds": 18,
            "lead_time_minutes": 4.2,
            "inference_latency_p95_ms": 85,
            "model_size_mb": 0.3,
            "memory_usage_mb": 45
        },
        "dataset_info": {
            "train_samples": 7000,
            "val_samples": 1500,
            "test_samples": 1500,
            "anomaly_rate": 0.08
        }
    }

    # JSON ì €ì¥
    with open(f"{model_path}/performance_report.json", "w") as f:
        json.dump(report, f, indent=2)

    return report
```

---

## 7. ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### 7.1 ì ì§„ì  ì „í™˜ (Gradual Migration)

ê¸°ì¡´ ì‹œìŠ¤í…œì„ ì¤‘ë‹¨í•˜ì§€ ì•Šê³  ë‹¨ê³„ì ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.

```python
# ocad/detectors/residual.py
class ResidualDetector(BaseDetector):
    def __init__(self, config, model_path: Optional[Path] = None, use_pretrained: bool = False):
        """
        Args:
            use_pretrained: Trueì´ë©´ ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ ì‚¬ìš©, Falseì´ë©´ ê¸°ì¡´ ì˜¨ë¼ì¸ í•™ìŠµ
        """
        super().__init__(config)

        if use_pretrained and model_path:
            # ìƒˆë¡œìš´ ë°©ì‹: ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
            self.models = self._load_pretrained_models(model_path)
            self.mode = "inference_only"
        else:
            # ê¸°ì¡´ ë°©ì‹: ì˜¨ë¼ì¸ í•™ìŠµ
            self.models = {"udp_echo": None, "ecpri": None, "lbm": None}
            self.history = {"udp_echo": [], "ecpri": [], "lbm": []}
            self.mode = "online_training"

        self.logger.info(f"ResidualDetector initialized in {self.mode} mode")
```

**ì„¤ì • í”Œë˜ê·¸**:
```yaml
# config/local.yaml
detection:
  residual:
    use_pretrained_models: true  # falseë¡œ ì„¤ì •í•˜ë©´ ê¸°ì¡´ ë°©ì‹ ìœ ì§€
    model_path: "ocad/models/tcn/"
```

### 7.2 ë¹„êµ í…ŒìŠ¤íŠ¸

```python
# scripts/compare_modes.py
def compare_online_vs_pretrained():
    """ì˜¨ë¼ì¸ í•™ìŠµ vs ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ ë¹„êµ"""

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    test_data = load_test_data("data/processed/timeseries_test.parquet")

    # ë‘ ë°©ì‹ìœ¼ë¡œ íƒì§€
    detector_online = ResidualDetector(config, use_pretrained=False)
    detector_pretrained = ResidualDetector(config, use_pretrained=True)

    results = {
        "online": evaluate(detector_online, test_data),
        "pretrained": evaluate(detector_pretrained, test_data)
    }

    # ë¹„êµ ë¦¬í¬íŠ¸
    print(f"Online Learning - F1: {results['online']['f1']:.3f}, Latency: {results['online']['latency_p95']:.1f}ms")
    print(f"Pretrained - F1: {results['pretrained']['f1']:.3f}, Latency: {results['pretrained']['latency_p95']:.1f}ms")

    return results
```

---

## 8. ìš”ì•½

### 8.1 í•µì‹¬ ë³€í™”

| êµ¬ë¶„ | ê¸°ì¡´ (ì˜¨ë¼ì¸ í•™ìŠµ) | ê°œì„  (í•™ìŠµ-ì¶”ë¡  ë¶„ë¦¬) |
|------|-------------------|---------------------|
| **í•™ìŠµ ì‹œì ** | ì¶”ë¡  ì¤‘ (50ê°œ ìƒ˜í”Œë§ˆë‹¤) | ì‚¬ì „ ì˜¤í”„ë¼ì¸ í•™ìŠµ |
| **ì¶”ë¡  ì§€ì—°** | ë¶ˆê·œì¹™ (í•™ìŠµ ì‹œ ì¦ê°€) | ì¼ì • (< 100ms) |
| **ëª¨ë¸ ê²€ì¦** | ë¶ˆê°€ëŠ¥ | ë°°í¬ ì „ ì™„ì „ ê²€ì¦ |
| **ì¬í˜„ì„±** | ë‚®ìŒ (íƒ€ì´ë° ì˜ì¡´) | ë†’ìŒ (ë™ì¼ ëª¨ë¸) |
| **í•˜ì´í¼íŒŒë¼ë¯¸í„°** | ê³ ì • (ì‹¤í—˜ ë¶ˆê°€) | ìµœì í™” ê°€ëŠ¥ |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©** | ë†’ìŒ (ì´ë ¥ ì €ì¥) | ë‚®ìŒ (ëª¨ë¸ë§Œ) |
| **ë°°í¬ ìœ ì—°ì„±** | ë‚®ìŒ | ë†’ìŒ (ë²„ì „ ê´€ë¦¬) |

### 8.2 ê¸°ëŒ€ íš¨ê³¼

1. **ì„±ëŠ¥ í–¥ìƒ**
   - ì¶”ë¡  ì§€ì—° 50% ê°ì†Œ (í•™ìŠµ ì œê±°)
   - ë©”ëª¨ë¦¬ ì‚¬ìš© 70% ê°ì†Œ (ì´ë ¥ ë°ì´í„° ë¶ˆí•„ìš”)

2. **í’ˆì§ˆ ë³´ì¦**
   - ë°°í¬ ì „ ì„±ëŠ¥ ì¸¡ì • ê°€ëŠ¥
   - í‘œì¤€ ë°ì´í„°ì…‹ìœ¼ë¡œ ì¼ê´€ëœ í‰ê°€

3. **ìš´ì˜ íš¨ìœ¨**
   - ëª¨ë¸ ë¡¤ë°±ìœ¼ë¡œ ë¹ ë¥¸ ì¥ì•  ë³µêµ¬
   - A/B í…ŒìŠ¤íŒ…ìœ¼ë¡œ ìµœì  ëª¨ë¸ ì„ íƒ

4. **ì—°êµ¬ í™œì„±í™”**
   - í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
   - ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ ì‹¤í—˜ ìš©ì´

---

## 9. ì°¸ê³  ìë£Œ

### 9.1 ê´€ë ¨ ë¬¸ì„œ
- `docs/AI-Models-Guide.md`: í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ AI ëª¨ë¸ ì„¤ëª…
- `CLAUDE.md`: í”„ë¡œì íŠ¸ ì „ì²´ ê°€ì´ë“œ
- `README.md`: ì‹œìŠ¤í…œ ê°œìš”

### 9.2 ì£¼ìš” ì½”ë“œ íŒŒì¼
- `ocad/detectors/residual.py`: TCN ê¸°ë°˜ ì”ì°¨ íƒì§€ê¸°
- `ocad/detectors/multivariate.py`: Isolation Forest ë‹¤ë³€ëŸ‰ íƒì§€ê¸°
- `ocad/features/engine.py`: í”¼ì²˜ ì¶”ì¶œ ì—”ì§„
- `ocad/utils/simulator.py`: ë°ì´í„° ìƒì„±ìš© ì‹œë®¬ë ˆì´í„°

### 9.3 ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
- PyTorch: https://pytorch.org/
- Scikit-learn: https://scikit-learn.org/
- Optuna (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹): https://optuna.org/
- MLflow (ì‹¤í—˜ ì¶”ì ): https://mlflow.org/

---

**ì‘ì„±ì¼**: 2024-01-15
**ë²„ì „**: 1.0.0
**ì‘ì„±ì**: OCAD Development Team
