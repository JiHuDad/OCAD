# ë°ì´í„° ì†ŒìŠ¤ ê°€ì´ë“œ

**ëª©ì **: OCADì— ë°ì´í„°ë¥¼ ì œê³µí•˜ëŠ” ëª¨ë“  ë°©ë²•ì„ ì„¤ëª…í•˜ëŠ” í†µí•© ê°€ì´ë“œ

**ëŒ€ìƒ**: CFM ë‹´ë‹¹ì, ë°ì´í„° ì œê³µì, ì‹œìŠ¤í…œ ìš´ì˜ì

---

## ğŸ“Š ë°ì´í„° ì…ë ¥ ë°©ì‹ ê°œìš”

OCADëŠ” ë‘ ê°€ì§€ ë°ì´í„° ì…ë ¥ ë°©ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            OCAD ë°ì´í„° ì…ë ¥                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  âœ… 1. íŒŒì¼ ê¸°ë°˜ (í˜„ì¬ ì§€ì›)                      â”‚
â”‚     - CSV, Excel, Parquet                       â”‚
â”‚     - ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹                       â”‚
â”‚     - í•™ìŠµ/ì¶”ë¡  ëª¨ë‘ ì‚¬ìš©                         â”‚
â”‚                                                  â”‚
â”‚  ğŸ”„ 2. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (í–¥í›„ ì§€ì›)                â”‚
â”‚     - Kafka, WebSocket                          â”‚
â”‚     - NETCONF/YANG ì‹¤ì‹œê°„ ìˆ˜ì§‘                   â”‚
â”‚     - ì¶”ë¡  ì „ìš©                                  â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… ë°©ë²• 1: íŒŒì¼ ê¸°ë°˜ ì…ë ¥ (í˜„ì¬)

### ì§€ì› í˜•ì‹

| í˜•ì‹ | í™•ì¥ì | ê¶Œì¥ ìš©ë„ | ë¼ì´ë¸ŒëŸ¬ë¦¬ |
|------|--------|-----------|------------|
| CSV | `.csv` | ì†Œê·œëª¨ ë°ì´í„° (<10MB) | pandas |
| Excel | `.xlsx` | ì‚¬ëŒì´ í¸ì§‘ | openpyxl |
| Parquet | `.parquet` | ëŒ€ìš©ëŸ‰ ë°ì´í„° (>10MB) | pyarrow |

### CSV íŒŒì¼ ì˜ˆì œ

```csv
timestamp,endpoint_id,udp_echo_rtt_ms,ecpri_delay_us,lbm_rtt_ms,lbm_success,ccm_interval_ms,ccm_miss_count,label
1760529600000,o-ru-test-001,4.76,93.93,7.33,1,10,0,normal
1760529610000,o-ru-test-001,4.61,110.28,6.3,1,10,0,normal
1760529620000,o-ru-test-001,4.87,92.53,7.14,1,10,0,normal
```

**í•„ìˆ˜ ì»¬ëŸ¼**:
- `timestamp` - Unix timestamp (ë°€ë¦¬ì´ˆ)
- `endpoint_id` - ì—”ë“œí¬ì¸íŠ¸ ID
- `udp_echo_rtt_ms` - UDP Echo RTT (ë°€ë¦¬ì´ˆ)
- `ecpri_delay_us` - eCPRI delay (ë§ˆì´í¬ë¡œì´ˆ)
- `lbm_rtt_ms` - LBM RTT (ë°€ë¦¬ì´ˆ)

**ì„ íƒ ì»¬ëŸ¼**:
- `label` - ë¼ë²¨ (normal/anomaly) - í…ŒìŠ¤íŠ¸ìš©
- `scenario` - ì‹œë‚˜ë¦¬ì˜¤ ì´ë¦„ - í…ŒìŠ¤íŠ¸ìš©
- `site_name` - ì‚¬ì´íŠ¸ ì´ë¦„
- `zone` - ì¡´ ì •ë³´

### Excel íŒŒì¼ ì˜ˆì œ

Excel íŒŒì¼ë„ ë™ì¼í•œ êµ¬ì¡°ì´ì§€ë§Œ, ì—¬ëŸ¬ ì‹œíŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

**Sheet 1: Metrics**
| timestamp | endpoint_id | udp_echo_rtt_ms | ecpri_delay_us | lbm_rtt_ms |
|-----------|-------------|-----------------|----------------|------------|
| 1760529600000 | o-ru-test-001 | 4.76 | 93.93 | 7.33 |

**Sheet 2: Metadata** (ì„ íƒ ì‚¬í•­)
| key | value |
|-----|-------|
| collection_date | 2025-10-27 |
| site | Seoul-01 |

### Parquet íŒŒì¼ (ëŒ€ìš©ëŸ‰)

ParquetëŠ” ì»¬ëŸ¼ ê¸°ë°˜ ì••ì¶• í˜•ì‹ìœ¼ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ì í•©í•©ë‹ˆë‹¤:

```bash
# CSV â†’ Parquet ë³€í™˜
python3 -c "
import pandas as pd
df = pd.read_csv('data/metrics.csv')
df.to_parquet('data/metrics.parquet', compression='snappy')
"

# íŒŒì¼ í¬ê¸° ë¹„êµ
ls -lh data/metrics.csv      # 10 MB
ls -lh data/metrics.parquet  # 2 MB (80% ì••ì¶•)
```

---

## ğŸ“ ë°ì´í„° í˜•ì‹ ìƒì„¸

### Wide í˜•ì‹ (ê¶Œì¥)

**í•œ í–‰ì— ëª¨ë“  ë©”íŠ¸ë¦­ í¬í•¨**:

```csv
timestamp,endpoint_id,udp_echo_rtt_ms,ecpri_delay_us,lbm_rtt_ms
1760529600000,o-ru-001,5.2,100.5,7.1
1760529610000,o-ru-001,5.3,102.3,7.2
```

**ì¥ì **:
- ì‚¬ëŒì´ ì½ê¸° ì‰¬ì›€
- Excelì—ì„œ í¸ì§‘ ìš©ì´
- ì‹œê³„ì—´ ë¶„ì„ì— ì§ê´€ì 

### Long í˜•ì‹ (ì§€ì›)

**í•œ í–‰ì— í•˜ë‚˜ì˜ ë©”íŠ¸ë¦­**:

```csv
timestamp,endpoint_id,metric_name,metric_value
1760529600000,o-ru-001,udp_echo_rtt_ms,5.2
1760529600000,o-ru-001,ecpri_delay_us,100.5
1760529600000,o-ru-001,lbm_rtt_ms,7.1
```

**ì¥ì **:
- ë©”íŠ¸ë¦­ ì¶”ê°€/ì œê±° ìš©ì´
- ë°ì´í„°ë² ì´ìŠ¤ ì¹œí™”ì 

**ìë™ ê°ì§€**: OCADëŠ” í˜•ì‹ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.

---

## ğŸš€ íŒŒì¼ ê¸°ë°˜ ì…ë ¥ ì‚¬ìš©ë²•

### Step 1: ë°ì´í„° ìƒì„±

#### Option A: í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±

```bash
# í•™ìŠµìš© (ì •ìƒ ë°ì´í„°ë§Œ)
python scripts/generate_training_inference_data.py --mode training
# ì¶œë ¥: data/training_normal_only.csv (28,800ê°œ)

# ì¶”ë¡  í…ŒìŠ¤íŠ¸ìš© (ì •ìƒ + ì´ìƒ)
python scripts/generate_training_inference_data.py --mode inference
# ì¶œë ¥: data/inference_test_scenarios.csv (780ê°œ)
```

#### Option B: ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘

CFM ë‹´ë‹¹ìê°€ ORAN ì¥ë¹„ì—ì„œ ìˆ˜ì§‘:

1. **ë©”íŠ¸ë¦­ ìˆ˜ì§‘** (NETCONF/YANG)
   ```bash
   # UDP Echo RTT
   # eCPRI delay
   # LBM RTT, success rate
   # CCM interval, miss count
   ```

2. **CSV íŒŒì¼ë¡œ ì €ì¥**
   ```bash
   # íŒŒì¼ëª…: metrics_YYYYMMDD.csv
   # ì˜ˆ: metrics_20251027.csv
   ```

3. **íŒŒì¼ ì „ë‹¬**
   ```bash
   cp metrics_20251027.csv /path/to/ocad/data/
   ```

**ìƒì„¸ ìš”êµ¬ì‚¬í•­**: [CFM-Data-Requirements.md](CFM-Data-Requirements.md)

### Step 2: ë°ì´í„° ê²€ì¦

```bash
# Pythonìœ¼ë¡œ ë°ì´í„° ê²€ì¦
python3 -c "
import pandas as pd

df = pd.read_csv('data/metrics.csv')

# 1. ì»¬ëŸ¼ í™•ì¸
required_cols = ['timestamp', 'endpoint_id', 'udp_echo_rtt_ms', 'ecpri_delay_us', 'lbm_rtt_ms']
missing_cols = [col for col in required_cols if col not in df.columns]
if missing_cols:
    print(f'ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_cols}')
else:
    print('âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬')

# 2. ë°ì´í„° íƒ€ì… í™•ì¸
print(df.dtypes)

# 3. ê²°ì¸¡ì¹˜ í™•ì¸
print(df.isnull().sum())

# 4. í†µê³„ ìš”ì•½
print(df.describe())
"
```

### Step 3: í•™ìŠµ ë˜ëŠ” ì¶”ë¡  ì‹¤í–‰

```bash
# í•™ìŠµ
python scripts/train_model.py \
    --data-source data/training_normal_only.csv

# ì¶”ë¡ 
python scripts/run_inference.py \
    --data-source data/metrics.csv \
    --output data/results.csv
```

---

## ğŸ”„ ë°©ë²• 2: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (í–¥í›„)

### Kafka í†µí•© (ì˜ˆì •)

```bash
# Kafkaì—ì„œ ì‹¤ì‹œê°„ ì¶”ë¡ 
python scripts/run_inference.py \
    --streaming \
    --kafka-broker localhost:9092 \
    --kafka-topic oran-metrics \
    --kafka-group ocad-inference \
    --batch-size 100
```

**Kafka ë©”ì‹œì§€ í˜•ì‹**:
```json
{
  "timestamp": 1760529600000,
  "endpoint_id": "o-ru-test-001",
  "metrics": {
    "udp_echo_rtt_ms": 5.2,
    "ecpri_delay_us": 100.5,
    "lbm_rtt_ms": 7.1
  }
}
```

### WebSocket í†µí•© (ì˜ˆì •)

```bash
# WebSocketì—ì„œ ì‹¤ì‹œê°„ ì¶”ë¡ 
python scripts/run_inference.py \
    --streaming \
    --websocket-url ws://oran-server:8080/metrics \
    --batch-size 100
```

### NETCONF/YANG ì§ì ‘ ìˆ˜ì§‘ (ê¸°ë³¸)

```yaml
# config/local.yaml
endpoints:
  - id: o-ru-001
    host: 192.168.1.100
    port: 830
    username: admin
    capabilities:
      udp_echo: true
      ecpri_delay: true
      lbm: true
```

```bash
# ì‹œìŠ¤í…œ ì‹¤í–‰ (ìë™ ìˆ˜ì§‘)
python -m ocad.main
```

---

## ğŸ¨ ë°ì´í„° ì†ŒìŠ¤ ì¶”ìƒí™”

### í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤

OCADëŠ” ë°ì´í„° ì†ŒìŠ¤ì— ê´€ê³„ì—†ì´ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤:

```python
from ocad.core.data_source import DataSourceFactory

# íŒŒì¼ ê¸°ë°˜
config = {
    "type": "file",
    "file_path": "data/metrics.csv",
    "batch_size": 100
}
data_source = DataSourceFactory.create_from_config(config)

# ìŠ¤íŠ¸ë¦¬ë° (í–¥í›„)
config = {
    "type": "kafka",
    "kafka": {
        "bootstrap_servers": "localhost:9092",
        "topic": "oran-metrics"
    },
    "batch_size": 100
}
data_source = DataSourceFactory.create_from_config(config)

# ì‚¬ìš© ë°©ë²•ì€ ë™ì¼
for batch in data_source:
    for metric in batch.metrics:
        process(metric)
```

**ìƒì„¸ ì„¤ê³„**: [Data-Source-Abstraction-Design.md](../05-architecture/Data-Source-Abstraction-Design.md)

---

## ğŸ“‹ ë°ì´í„° í’ˆì§ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… í•„ìˆ˜ ì‚¬í•­

- [ ] ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬
- [ ] timestampê°€ Unix timestamp (ë°€ë¦¬ì´ˆ)
- [ ] ê²°ì¸¡ì¹˜ ì—†ìŒ (ë˜ëŠ” < 1%)
- [ ] ë°ì´í„° íƒ€ì… ì˜¬ë°”ë¦„ (ìˆ«ìëŠ” float/int)
- [ ] endpoint_id ì¼ê´€ì„± ìœ ì§€

### âš ï¸ ê¶Œì¥ ì‚¬í•­

- [ ] ìµœì†Œ 1ì‹œê°„ ì´ìƒì˜ ë°ì´í„°
- [ ] 10ì´ˆ ì´í•˜ ê°„ê²© (ì‹¤ì‹œê°„ì„±)
- [ ] ì—¬ëŸ¬ ì—”ë“œí¬ì¸íŠ¸ í¬í•¨ (í•™ìŠµ ë°ì´í„°)
- [ ] ì •ìƒ ë°ì´í„°ë§Œ í¬í•¨ (í•™ìŠµìš©)
- [ ] ì •ìƒ + ì´ìƒ í˜¼í•© (ì¶”ë¡  í…ŒìŠ¤íŠ¸ìš©)

### ğŸ” ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

```bash
# ë°ì´í„° í’ˆì§ˆ ì²´í¬
python scripts/validate_data.py data/metrics.csv
```

**ì˜ˆìƒ ì¶œë ¥**:
```
======================================================================
ë°ì´í„° í’ˆì§ˆ ê²€ì¦
======================================================================
íŒŒì¼: data/metrics.csv

âœ… í•„ìˆ˜ ì»¬ëŸ¼: ëª¨ë‘ ì¡´ì¬
âœ… ë°ì´í„° íƒ€ì…: ì˜¬ë°”ë¦„
âœ… ê²°ì¸¡ì¹˜: ì—†ìŒ
âš ï¸  ì‹œê°„ ê°„ê²©: í‰ê·  15ì´ˆ (ê¶Œì¥: 10ì´ˆ ì´í•˜)
âœ… ì—”ë“œí¬ì¸íŠ¸: 8ê°œ

ì´ ë ˆì½”ë“œ: 28,800ê°œ
ì‹œì‘ ì‹œê°„: 2025-10-27 12:00:00
ì¢…ë£Œ ì‹œê°„: 2025-10-27 13:00:00
ì§€ì† ì‹œê°„: 1ì‹œê°„

âœ… ë°ì´í„° í’ˆì§ˆ: ì–‘í˜¸
======================================================================
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"

**ì˜¤ë¥˜**:
```
FileNotFoundError: data/metrics.csv
```

**í•´ê²°**:
```bash
# 1. íŒŒì¼ ê²½ë¡œ í™•ì¸
ls -l data/metrics.csv

# 2. ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
python scripts/run_inference.py \
    --data-source /home/finux/dev/OCAD/data/metrics.csv
```

### ë¬¸ì œ 2: "í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½"

**ì˜¤ë¥˜**:
```
KeyError: 'udp_echo_rtt_ms'
```

**í•´ê²°**:
```python
# ì»¬ëŸ¼ëª… í™•ì¸
import pandas as pd
df = pd.read_csv('data/metrics.csv')
print(df.columns.tolist())

# ì»¬ëŸ¼ëª… ìˆ˜ì •
df = df.rename(columns={'udp_rtt': 'udp_echo_rtt_ms'})
df.to_csv('data/metrics_fixed.csv', index=False)
```

### ë¬¸ì œ 3: "ë°ì´í„° íƒ€ì… ì˜¤ë¥˜"

**ì˜¤ë¥˜**:
```
TypeError: float() argument must be a string or a number, not 'NoneType'
```

**í•´ê²°**:
```python
# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
import pandas as pd
df = pd.read_csv('data/metrics.csv')

# ê²°ì¸¡ì¹˜ í™•ì¸
print(df.isnull().sum())

# ê²°ì¸¡ì¹˜ ì œê±°
df = df.dropna()
df.to_csv('data/metrics_clean.csv', index=False)
```

### ë¬¸ì œ 4: "ë©”ëª¨ë¦¬ ë¶€ì¡±"

**ì˜¤ë¥˜**:
```
MemoryError: Unable to allocate array
```

**í•´ê²°**:
```bash
# Option 1: Parquet ë³€í™˜ (ì••ì¶•)
python3 -c "
import pandas as pd
df = pd.read_csv('data/large_metrics.csv')
df.to_parquet('data/large_metrics.parquet')
"

# Option 2: íŒŒì¼ ë¶„í• 
split -l 10000 data/large_metrics.csv data/chunk_

# Option 3: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
python scripts/run_inference.py \
    --data-source data/metrics.csv \
    --batch-size 50
```

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

### CFM ë‹´ë‹¹ì
- [CFM-Data-Requirements.md](CFM-Data-Requirements.md) - ìˆ˜ì§‘í•´ì•¼ í•  ë©”íŠ¸ë¦­
- [Data-Format-Specification.md](Data-Format-Specification.md) - í˜•ì‹ ëª…ì„¸

### ì‚¬ìš©ì
- [Training-Guide.md](../04-training-inference/Training-Guide.md) - í•™ìŠµ ê°€ì´ë“œ
- [Inference-Guide.md](../04-training-inference/Inference-Guide.md) - ì¶”ë¡  ê°€ì´ë“œ
- [Training-Inference-Workflow.md](../02-user-guides/Training-Inference-Workflow.md) - ì „ì²´ ì›Œí¬í”Œë¡œìš°

### ê°œë°œì
- [Data-Source-Abstraction-Design.md](../05-architecture/Data-Source-Abstraction-Design.md) - ì•„í‚¤í…ì²˜ ìƒì„¸

---

## â“ FAQ

### Q1: CSVì™€ Parquet ì¤‘ ì–´ëŠ ê²ƒì„ ì‚¬ìš©í•´ì•¼ í•˜ë‚˜ìš”?

**A**:
- **CSV**: ì†Œê·œëª¨ (<10MB), ì‚¬ëŒì´ í¸ì§‘ í•„ìš”
- **Parquet**: ëŒ€ê·œëª¨ (>10MB), ì••ì¶• íš¨ìœ¨ ì¤‘ìš”

### Q2: Excel íŒŒì¼ì— ì—¬ëŸ¬ ì‹œíŠ¸ê°€ ìˆìœ¼ë©´?

**A**: ì²« ë²ˆì§¸ ì‹œíŠ¸ë§Œ ì½ìŠµë‹ˆë‹¤. íŠ¹ì • ì‹œíŠ¸ ì§€ì •ì€ í–¥í›„ ì¶”ê°€ ì˜ˆì •.

### Q3: ì‹¤ì‹œê°„ ìˆ˜ì§‘ê³¼ íŒŒì¼ ì…ë ¥ ì¤‘ ì–´ëŠ ê²ƒì´ ì¢‹ë‚˜ìš”?

**A**:
- **í•™ìŠµ**: íŒŒì¼ ì…ë ¥ ê¶Œì¥ (ì¬í˜„ ê°€ëŠ¥)
- **ì¶”ë¡ **: ì‹¤ì‹œê°„ ìˆ˜ì§‘ ê¶Œì¥ (ì§€ì—° ìµœì†Œí™”)

### Q4: ë°ì´í„° í˜•ì‹ì„ ë³€í™˜í•˜ë ¤ë©´?

**A**:
```bash
# CSV â†’ Excel
python3 -c "
import pandas as pd
df = pd.read_csv('data/metrics.csv')
df.to_excel('data/metrics.xlsx', index=False)
"

# Excel â†’ CSV
python3 -c "
import pandas as pd
df = pd.read_excel('data/metrics.xlsx')
df.to_csv('data/metrics.csv', index=False)
"

# CSV â†’ Parquet
python3 -c "
import pandas as pd
df = pd.read_csv('data/metrics.csv')
df.to_parquet('data/metrics.parquet')
"
```

### Q5: ì—¬ëŸ¬ íŒŒì¼ì„ í•©ì¹˜ë ¤ë©´?

**A**:
```bash
# CSV íŒŒì¼ í•©ì¹˜ê¸°
python3 -c "
import pandas as pd
import glob

files = glob.glob('data/metrics_*.csv')
df = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)
df = df.sort_values('timestamp')
df.to_csv('data/metrics_merged.csv', index=False)
"
```

---

**ì‘ì„±ì**: Claude Code
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-10-27
**ë²„ì „**: 1.0.0
