#!/usr/bin/env python3
"""ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸.

ì¶”ë¡  ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”ëœ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- ì‹œê³„ì—´ ê·¸ë˜í”„ë¡œ ì´ìƒ êµ¬ê°„ í‘œì‹œ
- ì´ìƒ ë°ì´í„° í†µê³„ ë° ì„¤ëª…
- Markdown í˜•ì‹ì˜ ë¦¬í¬íŠ¸ ìƒì„±
"""

import argparse
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))


class InferenceReportGenerator:
    """ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±ê¸°."""

    def __init__(self, inference_result_path: Path, original_data_path: Path):
        """ì´ˆê¸°í™”.

        Args:
            inference_result_path: ì¶”ë¡  ê²°ê³¼ CSV íŒŒì¼ ê²½ë¡œ
            original_data_path: ì›ë³¸ ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ
        """
        self.inference_result_path = inference_result_path
        self.original_data_path = original_data_path

        # ë°ì´í„° ë¡œë“œ
        self.results_df = pd.read_csv(inference_result_path)
        self.original_df = pd.read_csv(original_data_path)

        # timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
        self.results_df['timestamp'] = pd.to_datetime(self.results_df['timestamp'])
        self.original_df['timestamp'] = pd.to_datetime(self.original_df['timestamp'])

        # ë‘ ë°ì´í„° ë³‘í•©
        self.merged_df = pd.merge(
            self.original_df,
            self.results_df[['timestamp', 'endpoint_id', 'residual_score',
                             'multivariate_score', 'final_score', 'is_anomaly']],
            on=['timestamp', 'endpoint_id'],
            how='left'
        )

    def generate_summary(self) -> dict:
        """ì „ì²´ ìš”ì•½ í†µê³„ ìƒì„±."""
        total_samples = len(self.results_df)
        anomaly_count = self.results_df['is_anomaly'].sum()
        anomaly_rate = (anomaly_count / total_samples) * 100

        # ì ìˆ˜ í†µê³„
        residual_mean = self.results_df['residual_score'].mean()
        multivariate_mean = self.results_df['multivariate_score'].mean()
        final_mean = self.results_df['final_score'].mean()

        return {
            'total_samples': total_samples,
            'anomaly_count': anomaly_count,
            'anomaly_rate': anomaly_rate,
            'normal_count': total_samples - anomaly_count,
            'residual_mean': residual_mean,
            'multivariate_mean': multivariate_mean,
            'final_mean': final_mean,
        }

    def find_anomaly_periods(self) -> list:
        """ì´ìƒ êµ¬ê°„ ì°¾ê¸°."""
        anomaly_df = self.merged_df[self.merged_df['is_anomaly'] == 1].copy()

        if len(anomaly_df) == 0:
            return []

        # ì—°ì†ëœ ì´ìƒ êµ¬ê°„ ê·¸ë£¹í™”
        anomaly_df['group'] = (anomaly_df['timestamp'].diff() > pd.Timedelta(minutes=2)).cumsum()

        periods = []
        for group_id, group in anomaly_df.groupby('group'):
            period = {
                'start': group['timestamp'].min(),
                'end': group['timestamp'].max(),
                'duration_minutes': (group['timestamp'].max() - group['timestamp'].min()).total_seconds() / 60,
                'count': len(group),
                'max_score': group['final_score'].max(),
                'avg_score': group['final_score'].mean(),
            }
            periods.append(period)

        return periods

    def analyze_anomaly_causes(self) -> dict:
        """ì´ìƒ ì›ì¸ ë¶„ì„."""
        anomaly_df = self.merged_df[self.merged_df['is_anomaly'] == 1]

        if len(anomaly_df) == 0:
            return {}

        # ë©”íŠ¸ë¦­ë³„ í‰ê· ê°’ ë¹„êµ
        normal_df = self.merged_df[self.merged_df['is_anomaly'] == 0]

        analysis = {}
        metrics = ['udp_echo_rtt_ms', 'ecpri_delay_us', 'lbm_rtt_ms', 'ccm_miss_count']

        for metric in metrics:
            if metric in anomaly_df.columns and metric in normal_df.columns:
                normal_mean = normal_df[metric].mean()
                anomaly_mean = anomaly_df[metric].mean()
                normal_std = normal_df[metric].std()

                # ë³€í™”ìœ¨ ê³„ì‚°
                if normal_mean > 0:
                    change_pct = ((anomaly_mean - normal_mean) / normal_mean) * 100
                else:
                    change_pct = 0

                # í‘œì¤€í¸ì°¨ ë°°ìˆ˜
                if normal_std > 0:
                    sigma_diff = (anomaly_mean - normal_mean) / normal_std
                else:
                    sigma_diff = 0

                analysis[metric] = {
                    'normal_mean': normal_mean,
                    'anomaly_mean': anomaly_mean,
                    'change_pct': change_pct,
                    'sigma_diff': sigma_diff,
                    'is_significant': abs(change_pct) > 20 or abs(sigma_diff) > 2,
                }

        return analysis

    def generate_markdown_report(self, output_path: Path):
        """Markdown ë¦¬í¬íŠ¸ ìƒì„±."""
        summary = self.generate_summary()
        periods = self.find_anomaly_periods()
        causes = self.analyze_anomaly_causes()

        report_lines = []

        # í—¤ë”
        report_lines.append("# OCAD ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸")
        report_lines.append("")
        report_lines.append(f"**ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"**ì›ë³¸ ë°ì´í„°**: {self.original_data_path.name}")
        report_lines.append(f"**ì¶”ë¡  ê²°ê³¼**: {self.inference_result_path.name}")
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # ì „ì²´ ìš”ì•½
        report_lines.append("## ğŸ“Š ì „ì²´ ìš”ì•½")
        report_lines.append("")
        report_lines.append(f"- **ì´ ìƒ˜í”Œ ìˆ˜**: {summary['total_samples']:,}ê°œ")
        report_lines.append(f"- **ì •ìƒ ë°ì´í„°**: {summary['normal_count']:,}ê°œ ({100 - summary['anomaly_rate']:.1f}%)")
        report_lines.append(f"- **ì´ìƒ ë°ì´í„°**: {summary['anomaly_count']:,}ê°œ ({summary['anomaly_rate']:.1f}%)")
        report_lines.append("")
        report_lines.append("### íƒì§€ ì ìˆ˜ í‰ê· ")
        report_lines.append("")
        report_lines.append(f"- **Residual Detector**: {summary['residual_mean']:.4f}")
        report_lines.append(f"- **Multivariate Detector**: {summary['multivariate_mean']:.4f}")
        report_lines.append(f"- **Final Score**: {summary['final_mean']:.4f}")
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # ì´ìƒ êµ¬ê°„ ë¶„ì„
        if periods:
            report_lines.append("## âš ï¸ ì´ìƒ êµ¬ê°„ ë¶„ì„")
            report_lines.append("")
            report_lines.append(f"**ì´ {len(periods)}ê°œì˜ ì´ìƒ êµ¬ê°„ì´ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.**")
            report_lines.append("")

            for i, period in enumerate(periods, 1):
                report_lines.append(f"### ì´ìƒ êµ¬ê°„ #{i}")
                report_lines.append("")
                report_lines.append(f"- **ì‹œì‘ ì‹œê°„**: {period['start'].strftime('%Y-%m-%d %H:%M:%S')}")
                report_lines.append(f"- **ì¢…ë£Œ ì‹œê°„**: {period['end'].strftime('%Y-%m-%d %H:%M:%S')}")
                report_lines.append(f"- **ì§€ì† ì‹œê°„**: {period['duration_minutes']:.1f}ë¶„")
                report_lines.append(f"- **ì´ìƒ ìƒ˜í”Œ ìˆ˜**: {period['count']}ê°œ")
                report_lines.append(f"- **ìµœëŒ€ ì´ìƒ ì ìˆ˜**: {period['max_score']:.4f}")
                report_lines.append(f"- **í‰ê·  ì´ìƒ ì ìˆ˜**: {period['avg_score']:.4f}")
                report_lines.append("")

            report_lines.append("---")
            report_lines.append("")
        else:
            report_lines.append("## âœ… ì´ìƒ êµ¬ê°„ ì—†ìŒ")
            report_lines.append("")
            report_lines.append("ëª¨ë“  ë°ì´í„°ê°€ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.")
            report_lines.append("")
            report_lines.append("---")
            report_lines.append("")

        # ì´ìƒ ì›ì¸ ë¶„ì„
        if causes:
            report_lines.append("## ğŸ” ì´ìƒ ì›ì¸ ë¶„ì„")
            report_lines.append("")
            report_lines.append("ì •ìƒ ë°ì´í„°ì™€ ì´ìƒ ë°ì´í„°ì˜ ë©”íŠ¸ë¦­ ë¹„êµ:")
            report_lines.append("")

            metric_names = {
                'udp_echo_rtt_ms': 'UDP Echo RTT',
                'ecpri_delay_us': 'eCPRI Delay',
                'lbm_rtt_ms': 'LBM RTT',
                'ccm_miss_count': 'CCM Miss Count',
            }

            for metric, data in causes.items():
                if data['is_significant']:
                    report_lines.append(f"### âš ï¸ {metric_names.get(metric, metric)}")
                    report_lines.append("")
                    report_lines.append(f"- **ì •ìƒ ì‹œ í‰ê· **: {data['normal_mean']:.2f}")
                    report_lines.append(f"- **ì´ìƒ ì‹œ í‰ê· **: {data['anomaly_mean']:.2f}")
                    report_lines.append(f"- **ë³€í™”ìœ¨**: {data['change_pct']:+.1f}%")
                    report_lines.append(f"- **í‘œì¤€í¸ì°¨ ë°°ìˆ˜**: {data['sigma_diff']:+.2f}Ïƒ")
                    report_lines.append("")

                    # ì„¤ëª… ì¶”ê°€
                    if data['change_pct'] > 50:
                        report_lines.append(f"**ğŸ’¡ ë¶„ì„**: {metric_names.get(metric, metric)}ê°€ ì •ìƒ ëŒ€ë¹„ **{data['change_pct']:.0f}% ì´ìƒ ì¦ê°€**í–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì§€ì—° ë˜ëŠ” ì„±ëŠ¥ ì €í•˜ê°€ ë°œìƒí–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
                    elif data['change_pct'] > 20:
                        report_lines.append(f"**ğŸ’¡ ë¶„ì„**: {metric_names.get(metric, metric)}ê°€ ì •ìƒ ëŒ€ë¹„ **{data['change_pct']:.0f}% ì¦ê°€**í–ˆìŠµë‹ˆë‹¤. ì„±ëŠ¥ ì €í•˜ ì§•í›„ê°€ ê´€ì°°ë©ë‹ˆë‹¤.")
                    elif data['change_pct'] < -20:
                        report_lines.append(f"**ğŸ’¡ ë¶„ì„**: {metric_names.get(metric, metric)}ê°€ ì •ìƒ ëŒ€ë¹„ **{abs(data['change_pct']):.0f}% ê°ì†Œ**í–ˆìŠµë‹ˆë‹¤.")

                    if abs(data['sigma_diff']) > 3:
                        report_lines.append(f"**âš ï¸ ê²½ê³ **: ì •ìƒ ë²”ìœ„ì—ì„œ **{abs(data['sigma_diff']):.1f} í‘œì¤€í¸ì°¨** ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤. ë§¤ìš° ì´ë¡€ì ì¸ íŒ¨í„´ì…ë‹ˆë‹¤.")

                    report_lines.append("")

            report_lines.append("---")
            report_lines.append("")

        # ê¶Œì¥ ì‚¬í•­
        report_lines.append("## ğŸ’¡ ê¶Œì¥ ì‚¬í•­")
        report_lines.append("")

        if summary['anomaly_rate'] > 50:
            report_lines.append("### ğŸ”´ ë†’ì€ ì´ìƒ íƒì§€ìœ¨ (50% ì´ìƒ)")
            report_lines.append("")
            report_lines.append("1. **ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”**: ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ì¥ë¹„ì— ì‹¬ê°í•œ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            report_lines.append("2. **ì›ì¸ íŒŒì•…**: ì´ìƒ êµ¬ê°„ì˜ ì‹œì‘ ì‹œê°„ê³¼ ì‹œìŠ¤í…œ ë¡œê·¸ë¥¼ ëŒ€ì¡°í•˜ì—¬ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.")
            report_lines.append("3. **ì¥ë¹„ ì ê²€**: í•´ë‹¹ ì‹œê°„ëŒ€ì— ì¥ë¹„ ì¬ì‹œì‘, ì„¤ì • ë³€ê²½ ë“±ì´ ìˆì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        elif summary['anomaly_rate'] > 20:
            report_lines.append("### ğŸŸ¡ ì¤‘ê°„ ì´ìƒ íƒì§€ìœ¨ (20-50%)")
            report_lines.append("")
            report_lines.append("1. **ëª¨ë‹ˆí„°ë§ ê°•í™”**: ì´ìƒ êµ¬ê°„ì´ ê³„ì† ì¦ê°€í•˜ëŠ”ì§€ ê´€ì°°í•˜ì„¸ìš”.")
            report_lines.append("2. **ì„±ëŠ¥ ë¶„ì„**: ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ì¦ê°€, ê°„ì„­ ë“± ì™¸ë¶€ ìš”ì¸ì„ í™•ì¸í•˜ì„¸ìš”.")
            report_lines.append("3. **ì˜ˆë°© ì¡°ì¹˜**: í•„ìš”ì‹œ ì¥ë¹„ ì„¤ì • ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        elif summary['anomaly_rate'] > 5:
            report_lines.append("### ğŸŸ¢ ë‚®ì€ ì´ìƒ íƒì§€ìœ¨ (5-20%)")
            report_lines.append("")
            report_lines.append("1. **ì •ìƒ ë²”ìœ„**: ì¼ì‹œì ì¸ ì´ìƒ íŒ¨í„´ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.")
            report_lines.append("2. **ê³„ì† ëª¨ë‹ˆí„°ë§**: ì´ìƒ êµ¬ê°„ì´ ë°˜ë³µë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            report_lines.append("3. **íŒ¨í„´ ë¶„ì„**: íŠ¹ì • ì‹œê°„ëŒ€ì— ì´ìƒì´ ì§‘ì¤‘ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        else:
            report_lines.append("### âœ… ì •ìƒ ìƒíƒœ (5% ë¯¸ë§Œ)")
            report_lines.append("")
            report_lines.append("1. **ì–‘í˜¸í•œ ìƒíƒœ**: ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            report_lines.append("2. **ì¼ìƒì  ëª¨ë‹ˆí„°ë§**: ì •ê¸°ì ì¸ ì ê²€ì„ ê³„ì†í•˜ì„¸ìš”.")

        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # ë°ì´í„° ìƒ˜í”Œ (ìƒì„¸ ì„¤ëª… í¬í•¨)
        report_lines.append("## ğŸ“‹ ì´ìƒ ë°ì´í„° ìƒ˜í”Œ (ìƒìœ„ 10ê°œ)")
        report_lines.append("")

        anomaly_samples = self.merged_df[self.merged_df['is_anomaly'] == 1].head(10)

        if len(anomaly_samples) > 0:
            # ì •ìƒ ë°ì´í„° ê¸°ì¤€ê°’ ê³„ì‚°
            normal_df = self.merged_df[self.merged_df['is_anomaly'] == 0]
            normal_means = {}
            normal_stds = {}

            for metric in ['udp_echo_rtt_ms', 'ecpri_delay_us', 'lbm_rtt_ms', 'ccm_miss_count']:
                if metric in normal_df.columns:
                    normal_means[metric] = normal_df[metric].mean()
                    normal_stds[metric] = normal_df[metric].std()

            report_lines.append("ê° ìƒ˜í”Œì´ ì™œ ì´ìƒìœ¼ë¡œ íŒë‹¨ë˜ì—ˆëŠ”ì§€ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤:")
            report_lines.append("")

            for idx, (_, row) in enumerate(anomaly_samples.iterrows(), 1):
                report_lines.append(f"### ğŸ”´ ì´ìƒ ìƒ˜í”Œ #{idx}")
                report_lines.append("")
                report_lines.append(f"**ì‹œê°„**: {row['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                report_lines.append(f"**ìµœì¢… ì´ìƒ ì ìˆ˜**: {row['final_score']:.4f}")
                report_lines.append("")

                # ë©”íŠ¸ë¦­ë³„ ìƒì„¸ ë¶„ì„
                report_lines.append("**ë©”íŠ¸ë¦­ ë¶„ì„**:")
                report_lines.append("")

                problems = []

                # UDP Echo RTT
                if 'udp_echo_rtt_ms' in row.index and 'udp_echo_rtt_ms' in normal_means:
                    value = row['udp_echo_rtt_ms']
                    normal = normal_means['udp_echo_rtt_ms']
                    std = normal_stds['udp_echo_rtt_ms']
                    diff_pct = ((value - normal) / normal * 100) if normal > 0 else 0
                    sigma = ((value - normal) / std) if std > 0 else 0

                    status = "ğŸ”´" if abs(diff_pct) > 50 or abs(sigma) > 3 else "ğŸŸ¡" if abs(diff_pct) > 20 or abs(sigma) > 2 else "ğŸŸ¢"
                    report_lines.append(f"- {status} **UDP Echo RTT**: {value:.2f} ms")
                    report_lines.append(f"  - ì •ìƒ í‰ê· : {normal:.2f} ms")
                    report_lines.append(f"  - ì°¨ì´: {diff_pct:+.1f}% ({sigma:+.2f}Ïƒ)")

                    if abs(diff_pct) > 50:
                        problems.append(f"UDP Echo RTTê°€ ì •ìƒ ëŒ€ë¹„ {abs(diff_pct):.0f}% {'ì¦ê°€' if diff_pct > 0 else 'ê°ì†Œ'}")
                    elif abs(diff_pct) > 20:
                        problems.append(f"UDP Echo RTTê°€ ì•½ê°„ {'ë†’ìŒ' if diff_pct > 0 else 'ë‚®ìŒ'}")
                    report_lines.append("")

                # eCPRI Delay
                if 'ecpri_delay_us' in row.index and 'ecpri_delay_us' in normal_means:
                    value = row['ecpri_delay_us']
                    normal = normal_means['ecpri_delay_us']
                    std = normal_stds['ecpri_delay_us']
                    diff_pct = ((value - normal) / normal * 100) if normal > 0 else 0
                    sigma = ((value - normal) / std) if std > 0 else 0

                    status = "ğŸ”´" if abs(diff_pct) > 50 or abs(sigma) > 3 else "ğŸŸ¡" if abs(diff_pct) > 20 or abs(sigma) > 2 else "ğŸŸ¢"
                    report_lines.append(f"- {status} **eCPRI Delay**: {value:.2f} Î¼s")
                    report_lines.append(f"  - ì •ìƒ í‰ê· : {normal:.2f} Î¼s")
                    report_lines.append(f"  - ì°¨ì´: {diff_pct:+.1f}% ({sigma:+.2f}Ïƒ)")

                    if abs(diff_pct) > 50:
                        problems.append(f"eCPRI ì§€ì—°ì´ ì •ìƒ ëŒ€ë¹„ {abs(diff_pct):.0f}% {'ì¦ê°€' if diff_pct > 0 else 'ê°ì†Œ'}")
                    elif abs(diff_pct) > 20:
                        problems.append(f"eCPRI ì§€ì—°ì´ ì•½ê°„ {'ë†’ìŒ' if diff_pct > 0 else 'ë‚®ìŒ'}")
                    report_lines.append("")

                # LBM RTT
                if 'lbm_rtt_ms' in row.index and 'lbm_rtt_ms' in normal_means:
                    value = row['lbm_rtt_ms']
                    normal = normal_means['lbm_rtt_ms']
                    std = normal_stds['lbm_rtt_ms']
                    diff_pct = ((value - normal) / normal * 100) if normal > 0 else 0
                    sigma = ((value - normal) / std) if std > 0 else 0

                    status = "ğŸ”´" if abs(diff_pct) > 50 or abs(sigma) > 3 else "ğŸŸ¡" if abs(diff_pct) > 20 or abs(sigma) > 2 else "ğŸŸ¢"
                    report_lines.append(f"- {status} **LBM RTT**: {value:.2f} ms")
                    report_lines.append(f"  - ì •ìƒ í‰ê· : {normal:.2f} ms")
                    report_lines.append(f"  - ì°¨ì´: {diff_pct:+.1f}% ({sigma:+.2f}Ïƒ)")

                    if abs(diff_pct) > 50:
                        problems.append(f"LBM RTTê°€ ì •ìƒ ëŒ€ë¹„ {abs(diff_pct):.0f}% {'ì¦ê°€' if diff_pct > 0 else 'ê°ì†Œ'}")
                    elif abs(diff_pct) > 20:
                        problems.append(f"LBM RTTê°€ ì•½ê°„ {'ë†’ìŒ' if diff_pct > 0 else 'ë‚®ìŒ'}")
                    report_lines.append("")

                # CCM Miss Count
                if 'ccm_miss_count' in row.index and 'ccm_miss_count' in normal_means:
                    value = int(row['ccm_miss_count'])
                    normal = normal_means['ccm_miss_count']

                    status = "ğŸ”´" if value > 5 else "ğŸŸ¡" if value > 0 else "ğŸŸ¢"
                    report_lines.append(f"- {status} **CCM Miss Count**: {value}íšŒ")
                    report_lines.append(f"  - ì •ìƒ í‰ê· : {normal:.1f}íšŒ")

                    if value > 5:
                        problems.append(f"íŒ¨í‚· ì†ì‹¤ì´ ì‹¬ê°í•¨ ({value}íšŒ)")
                    elif value > 0:
                        problems.append(f"íŒ¨í‚· ì†ì‹¤ ë°œìƒ ({value}íšŒ)")
                    report_lines.append("")

                # ì¢…í•© íŒë‹¨
                if problems:
                    report_lines.append("**ğŸ’¡ ì¢…í•© íŒë‹¨**:")
                    report_lines.append("")
                    for problem in problems:
                        report_lines.append(f"- {problem}")
                else:
                    report_lines.append("**ğŸ’¡ ì¢…í•© íŒë‹¨**: ëª¨ë“  ë©”íŠ¸ë¦­ì´ ì •ìƒ ë²”ìœ„ì´ì§€ë§Œ, ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë¶„ì„ì—ì„œ ì´ìƒìœ¼ë¡œ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")

                report_lines.append("")
                report_lines.append("---")
                report_lines.append("")
        else:
            report_lines.append("ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            report_lines.append("")
            report_lines.append("---")
            report_lines.append("")

        # í‘¸í„°
        report_lines.append("## ğŸ“Œ ì°¸ê³ ì‚¬í•­")
        report_lines.append("")
        report_lines.append("- **ì´ìƒ ì ìˆ˜ (Final Score)**: 0.0 (ì •ìƒ) ~ 1.0 (ì´ìƒ)")
        report_lines.append("- **ì´ìƒ ê¸°ì¤€**: Final Score > 0.5")
        report_lines.append("- **Residual Detector**: ì‹œê³„ì—´ ì˜ˆì¸¡-ì”ì°¨ ê¸°ë°˜ íƒì§€")
        report_lines.append("- **Multivariate Detector**: ë‹¤ë³€ëŸ‰ ì´ìƒ íƒì§€ (Isolation Forest)")
        report_lines.append("")

        # íŒŒì¼ ì €ì¥
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

        print(f"\nâœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_path}")
        return output_path


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(
        description="ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "--inference-result",
        type=Path,
        required=True,
        help="ì¶”ë¡  ê²°ê³¼ CSV íŒŒì¼ (inference_simple.py ì¶œë ¥)",
    )
    parser.add_argument(
        "--original-data",
        type=Path,
        required=True,
        help="ì›ë³¸ ë°ì´í„° CSV íŒŒì¼",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=None,
        help="ì¶œë ¥ ë¦¬í¬íŠ¸ ê²½ë¡œ (ê¸°ë³¸: ìë™ ìƒì„±)",
    )

    args = parser.parse_args()

    # ì¶œë ¥ ê²½ë¡œ ìë™ ìƒì„±
    if args.output is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        args.output = Path(f"reports/inference_report_{timestamp}.md")

    print("=" * 70)
    print("ğŸ“Š OCAD ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±ê¸°")
    print("=" * 70)
    print(f"\nì¶”ë¡  ê²°ê³¼: {args.inference_result}")
    print(f"ì›ë³¸ ë°ì´í„°: {args.original_data}")
    print(f"ì¶œë ¥ ê²½ë¡œ: {args.output}")

    # ë¦¬í¬íŠ¸ ìƒì„±
    generator = InferenceReportGenerator(args.inference_result, args.original_data)
    output_path = generator.generate_markdown_report(args.output)

    print("\n" + "=" * 70)
    print("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
    print("=" * 70)
    print(f"\në¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”: {output_path.absolute()}")
    print(f"\nëª…ë ¹ì–´: cat {output_path}")


if __name__ == "__main__":
    main()
