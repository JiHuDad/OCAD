# ë‚´ì¼ ì‘ì—… Quick Start Guide

**ë‚ ì§œ**: 2025-10-29
**ëª©í‘œ**: TCN, Isolation Forest ëª¨ë¸ í•™ìŠµ ì™„ë£Œ

---

## âš¡ ë¹ ë¥¸ ì‹œì‘

### 1ë‹¨ê³„: ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„ (í•„ìˆ˜!)

í˜„ì¬ ë°ì´í„°ëŠ” TCN í•™ìŠµì— í•„ìš”í•œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ë¨¼ì € ë³€í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤.

#### í•„ìš”í•œ ë°ì´í„° í˜•ì‹

```
í•„ìš”í•œ ì»¬ëŸ¼:
- timestamp: ì‹œê°„
- endpoint_id: ì—”ë“œí¬ì¸íŠ¸ ID
- metric_type: ë©”íŠ¸ë¦­ íƒ€ì… (udp_echo, ecpri, lbm)
- sequence: [v1, v2, ..., v10] (ë¦¬ìŠ¤íŠ¸, 10ê°œ timestep)
- target: v11 (ë‹¤ìŒ ê°’ ì˜ˆì¸¡)
- is_anomaly: False (ì •ìƒ ë°ì´í„°ë§Œ)
```

#### ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

```bash
# scripts/prepare_timeseries_data.py ìƒì„±
cat > scripts/prepare_timeseries_data.py << 'EOF'
#!/usr/bin/env python3
"""ì‹œê³„ì—´ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸.

ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ìƒì„±:
- Input: [t1, t2, t3, ..., t100]
- Output:
  - sequence: [t1, t2, ..., t10], target: t11
  - sequence: [t2, t3, ..., t11], target: t12
  - ...
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime

SEQUENCE_LENGTH = 10  # ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´

def create_sequences(df, metric_col, sequence_length=10):
    """ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ìƒì„±."""
    sequences = []
    targets = []

    # ì—”ë“œí¬ì¸íŠ¸ë³„ë¡œ ê·¸ë£¹í™”
    for endpoint_id, group in df.groupby('endpoint_id'):
        # ì‹œê°„ìˆœ ì •ë ¬
        group = group.sort_values('timestamp').reset_index(drop=True)
        values = group[metric_col].values

        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
        for i in range(len(values) - sequence_length):
            seq = values[i:i + sequence_length].tolist()
            target = values[i + sequence_length]

            sequences.append({
                'timestamp': group.iloc[i + sequence_length]['timestamp'],
                'endpoint_id': endpoint_id,
                'sequence': seq,
                'target': float(target),
                'is_anomaly': False,  # ì •ìƒ ë°ì´í„°ë§Œ
            })

    return pd.DataFrame(sequences)

def main():
    print("=" * 70)
    print("ì‹œê³„ì—´ í•™ìŠµ ë°ì´í„° ì¤€ë¹„")
    print("=" * 70)

    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    input_file = Path("data/training_normal_only.csv")
    df = pd.read_csv(input_file)
    df['timestamp'] = pd.to_datetime(df['timestamp'])

    print(f"\nì›ë³¸ ë°ì´í„°: {len(df):,}ê°œ ë ˆì½”ë“œ")

    # ë©”íŠ¸ë¦­ë³„ ì‹œí€€ìŠ¤ ìƒì„±
    metrics_config = [
        ('udp_echo', 'udp_echo_rtt_ms'),
        ('ecpri', 'ecpri_delay_us'),
        ('lbm', 'lbm_rtt_ms'),
    ]

    all_sequences = []

    for metric_type, col_name in metrics_config:
        print(f"\n[{metric_type}] ì‹œí€€ìŠ¤ ìƒì„± ì¤‘...")

        seq_df = create_sequences(df, col_name, SEQUENCE_LENGTH)
        seq_df['metric_type'] = metric_type

        print(f"  - ìƒì„±ëœ ì‹œí€€ìŠ¤: {len(seq_df):,}ê°œ")
        all_sequences.append(seq_df)

    # ëª¨ë“  ë©”íŠ¸ë¦­ ê²°í•©
    combined_df = pd.concat(all_sequences, ignore_index=True)
    print(f"\nì „ì²´ ì‹œí€€ìŠ¤: {len(combined_df):,}ê°œ")

    # í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í•  (80/10/10)
    train_size = int(len(combined_df) * 0.8)
    val_size = int(len(combined_df) * 0.1)

    train_df = combined_df[:train_size]
    val_df = combined_df[train_size:train_size + val_size]
    test_df = combined_df[train_size + val_size:]

    # ì €ì¥
    output_dir = Path("data/processed")
    output_dir.mkdir(exist_ok=True)

    train_df.to_parquet(output_dir / "timeseries_train.parquet", index=False)
    val_df.to_parquet(output_dir / "timeseries_val.parquet", index=False)
    test_df.to_parquet(output_dir / "timeseries_test.parquet", index=False)

    print(f"\nâœ… ì €ì¥ ì™„ë£Œ:")
    print(f"  - í•™ìŠµ: {len(train_df):,}ê°œ ({len(train_df)/len(combined_df)*100:.1f}%)")
    print(f"  - ê²€ì¦: {len(val_df):,}ê°œ ({len(val_df)/len(combined_df)*100:.1f}%)")
    print(f"  - í…ŒìŠ¤íŠ¸: {len(test_df):,}ê°œ ({len(test_df)/len(combined_df)*100:.1f}%)")

    print(f"\në°ì´í„° ìƒ˜í”Œ:")
    print(train_df.head(2))

    print("\n" + "=" * 70)

if __name__ == "__main__":
    main()
EOF

chmod +x scripts/prepare_timeseries_data.py
```

#### ì‹¤í–‰

```bash
source .venv/bin/activate
python scripts/prepare_timeseries_data.py
```

**ì˜ˆìƒ ê²°ê³¼**:
- `data/processed/timeseries_train.parquet` (ì•½ 70,000ê°œ ì‹œí€€ìŠ¤)
- `data/processed/timeseries_val.parquet` (ì•½ 8,700ê°œ ì‹œí€€ìŠ¤)
- `data/processed/timeseries_test.parquet` (ì•½ 8,700ê°œ ì‹œí€€ìŠ¤)

---

### 2ë‹¨ê³„: TCN ëª¨ë¸ í•™ìŠµ (ì‹œê°„ ì œí•œ ì—†ìŒ)

#### UDP Echo í•™ìŠµ

```bash
source .venv/bin/activate

python scripts/train_tcn_model.py \
    --metric-type udp_echo \
    --train-data data/processed/timeseries_train.parquet \
    --val-data data/processed/timeseries_val.parquet \
    --test-data data/processed/timeseries_test.parquet \
    --epochs 50 \
    --batch-size 64 \
    --learning-rate 0.001 \
    --early-stopping \
    --patience 10 \
    --output-dir ocad/models/tcn \
    --version v2.0.0
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 30-60ë¶„ (CPU), 5-10ë¶„ (GPU)

#### eCPRI í•™ìŠµ

```bash
python scripts/train_tcn_model.py \
    --metric-type ecpri \
    --epochs 50 \
    --batch-size 64 \
    --output-dir ocad/models/tcn \
    --version v2.0.0
```

#### LBM í•™ìŠµ

```bash
python scripts/train_tcn_model.py \
    --metric-type lbm \
    --epochs 50 \
    --batch-size 64 \
    --output-dir ocad/models/tcn \
    --version v2.0.0
```

#### ë³‘ë ¬ ì‹¤í–‰ (ê¶Œì¥)

í„°ë¯¸ë„ 3ê°œë¥¼ ì—´ì–´ì„œ ë™ì‹œì— ì‹¤í–‰:

```bash
# Terminal 1
python scripts/train_tcn_model.py --metric-type udp_echo --epochs 50 --version v2.0.0

# Terminal 2
python scripts/train_tcn_model.py --metric-type ecpri --epochs 50 --version v2.0.0

# Terminal 3
python scripts/train_tcn_model.py --metric-type lbm --epochs 50 --version v2.0.0
```

---

### 3ë‹¨ê³„: Isolation Forest í•™ìŠµ

#### ë‹¤ë³€ëŸ‰ ë°ì´í„° ì¤€ë¹„

```bash
cat > scripts/prepare_multivariate_data.py << 'EOF'
#!/usr/bin/env python3
"""ë‹¤ë³€ëŸ‰ ì´ìƒ íƒì§€ ë°ì´í„° ì¤€ë¹„."""

import pandas as pd
from pathlib import Path

def main():
    print("=" * 70)
    print("ë‹¤ë³€ëŸ‰ í•™ìŠµ ë°ì´í„° ì¤€ë¹„")
    print("=" * 70)

    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    df = pd.read_csv("data/training_normal_only.csv")

    # íŠ¹ì§• ì„ íƒ
    features = [
        'udp_echo_rtt_ms',
        'ecpri_delay_us',
        'lbm_rtt_ms',
        'ccm_miss_count',
    ]

    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    multi_df = df[['timestamp', 'endpoint_id'] + features].copy()
    multi_df['is_anomaly'] = False

    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  (80/20)
    train_size = int(len(multi_df) * 0.8)
    train_df = multi_df[:train_size]
    test_df = multi_df[train_size:]

    # ì €ì¥
    output_dir = Path("data/processed")
    output_dir.mkdir(exist_ok=True)

    train_df.to_parquet(output_dir / "multivariate_train.parquet", index=False)
    test_df.to_parquet(output_dir / "multivariate_test.parquet", index=False)

    print(f"\nâœ… ì €ì¥ ì™„ë£Œ:")
    print(f"  - í•™ìŠµ: {len(train_df):,}ê°œ")
    print(f"  - í…ŒìŠ¤íŠ¸: {len(test_df):,}ê°œ")
    print(f"\níŠ¹ì§•: {features}")
    print("=" * 70)

if __name__ == "__main__":
    main()
EOF

chmod +x scripts/prepare_multivariate_data.py
python scripts/prepare_multivariate_data.py
```

#### Isolation Forest í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ í™•ì¸

```bash
# ìŠ¤í¬ë¦½íŠ¸ ì¡´ì¬ í™•ì¸
ls -lh scripts/train_isolation_forest.py

# ì—†ìœ¼ë©´ ê¸°ì¡´ ì°¸ê³ í•˜ì—¬ ì‘ì„± í•„ìš”
# ë˜ëŠ” ocad/training/trainers/ ì— IsolationForestTrainer ì‚¬ìš©
```

#### í•™ìŠµ ì‹¤í–‰

```bash
python scripts/train_isolation_forest.py \
    --train-data data/processed/multivariate_train.parquet \
    --test-data data/processed/multivariate_test.parquet \
    --n-estimators 100 \
    --contamination 0.1 \
    --output-dir ocad/models/isolation_forest \
    --version v2.0.0
```

---

## ğŸ” í•™ìŠµ ì§„í–‰ í™•ì¸

### í•™ìŠµ ì¤‘ ëª¨ë‹ˆí„°ë§

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
tail -f logs/training_*.log

# ëª¨ë¸ íŒŒì¼ ìƒì„± í™•ì¸
watch -n 5 'ls -lh ocad/models/tcn/'

# GPU ì‚¬ìš©ëŸ‰ í™•ì¸ (GPU ìˆëŠ” ê²½ìš°)
watch -n 1 nvidia-smi
```

### í•™ìŠµ ì™„ë£Œ í™•ì¸

```bash
# ëª¨ë¸ íŒŒì¼ í™•ì¸
ls -lh ocad/models/tcn/*.pth
ls -lh ocad/models/isolation_forest/*.pkl

# ë©”íƒ€ë°ì´í„° í™•ì¸
cat ocad/models/tcn/udp_echo_v2.0.0.json
```

**ê¸°ëŒ€ ê²°ê³¼**:
```
ocad/models/tcn/
â”œâ”€â”€ udp_echo_v2.0.0.pth   (ìˆ˜ì‹­ MB)
â”œâ”€â”€ udp_echo_v2.0.0.json
â”œâ”€â”€ ecpri_v2.0.0.pth
â”œâ”€â”€ ecpri_v2.0.0.json
â”œâ”€â”€ lbm_v2.0.0.pth
â””â”€â”€ lbm_v2.0.0.json

ocad/models/isolation_forest/
â”œâ”€â”€ multivariate_v2.0.0.pkl
â””â”€â”€ multivariate_v2.0.0.json
```

---

## ğŸ§ª í•™ìŠµ ì™„ë£Œ í›„ ê²€ì¦

### ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸

```python
# test_models.py
import torch
import joblib

# TCN ëª¨ë¸ ë¡œë“œ
tcn_model = torch.load('ocad/models/tcn/udp_echo_v2.0.0.pth')
print("âœ… TCN ëª¨ë¸ ë¡œë“œ ì„±ê³µ")

# Isolation Forest ë¡œë“œ
if_model = joblib.load('ocad/models/isolation_forest/multivariate_v2.0.0.pkl')
print("âœ… Isolation Forest ë¡œë“œ ì„±ê³µ")
```

### ì¶”ë¡  í…ŒìŠ¤íŠ¸

```bash
# í•™ìŠµëœ ëª¨ë¸ë¡œ ì¶”ë¡  (ì—…ë°ì´íŠ¸ í•„ìš”)
python scripts/inference_with_report.py \
    --data-source data/inference_anomaly_only.csv \
    --model-path ocad/models/tcn
```

---

## âš ï¸ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: "KeyError: 'sequence'"

**ì›ì¸**: ì‹œê³„ì—´ ë°ì´í„° í˜•ì‹ ë¶ˆì¼ì¹˜

**í•´ê²°**: 1ë‹¨ê³„ (prepare_timeseries_data.py) ë°˜ë“œì‹œ ì‹¤í–‰

### ë¬¸ì œ 2: "CUDA out of memory"

**í•´ê²°**: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°

```bash
python scripts/train_tcn_model.py \
    --metric-type udp_echo \
    --batch-size 32 \  # 64 â†’ 32ë¡œ ê°ì†Œ
    --epochs 50
```

### ë¬¸ì œ 3: í•™ìŠµ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¼

**í•´ê²° ì˜µì…˜**:
1. Early stopping í™œì„±í™” (ê¸°ë³¸ í™œì„±í™”ë¨)
2. Epoch ìˆ˜ ê°ì†Œ (50 â†’ 20)
3. GPU ì‚¬ìš© (ê°€ëŠ¥í•œ ê²½ìš°)

```bash
python scripts/train_tcn_model.py \
    --metric-type udp_echo \
    --epochs 20 \
    --device cuda  # GPU ì‚¬ìš©
```

### ë¬¸ì œ 4: "FileNotFoundError: timeseries_train.parquet"

**í•´ê²°**: 1ë‹¨ê³„ ë°ì´í„° ì¤€ë¹„ ë¨¼ì € ì‹¤í–‰

```bash
python scripts/prepare_timeseries_data.py
ls -lh data/processed/
```

---

## ğŸ“Š ì„±ê³µ ê¸°ì¤€

### í•™ìŠµ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `data/processed/timeseries_train.parquet` ìƒì„±ë¨ (ì•½ 70,000ê°œ ì‹œí€€ìŠ¤)
- [ ] `ocad/models/tcn/udp_echo_v2.0.0.pth` ìƒì„±ë¨
- [ ] `ocad/models/tcn/ecpri_v2.0.0.pth` ìƒì„±ë¨
- [ ] `ocad/models/tcn/lbm_v2.0.0.pth` ìƒì„±ë¨
- [ ] `ocad/models/isolation_forest/multivariate_v2.0.0.pkl` ìƒì„±ë¨
- [ ] ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸ ì„±ê³µ

### ì„±ëŠ¥ ê¸°ì¤€

- **Training Loss**: ì ì§„ì  ê°ì†Œ
- **Validation Loss**: í•™ìŠµ ì¤‘ë°˜ë¶€í„° ì•ˆì •í™”
- **Test MSE**: < 1.0 (ì •ê·œí™”ëœ ë°ì´í„° ê¸°ì¤€)
- **Isolation Forest Score**: ëŒ€ë¶€ë¶„ ìŒìˆ˜ê°’ (ì •ìƒ ë°ì´í„°)

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„ (í•™ìŠµ ì™„ë£Œ í›„)

1. **í•™ìŠµëœ ëª¨ë¸ í†µí•©**
   ```bash
   # ResidualDetector, MultivariateDetector ì—…ë°ì´íŠ¸
   # inference_with_report.py ìˆ˜ì •
   ```

2. **ONNX ë³€í™˜**
   ```bash
   python scripts/convert_to_onnx.py \
       --model-path ocad/models/tcn/udp_echo_v2.0.0.pth \
       --output ocad/models/onnx/udp_echo_v2.0.0.onnx
   ```

3. **ì„±ëŠ¥ ë¹„êµ**
   ```bash
   # ë£° ê¸°ë°˜ vs í•™ìŠµëœ ëª¨ë¸ ë¹„êµ
   python scripts/compare_detection_performance.py
   ```

---

## ğŸ’¡ ìœ ìš©í•œ ëª…ë ¹ì–´

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
source .venv/bin/activate

# ëª¨ë“  í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ í•œë²ˆì— ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
nohup python scripts/train_tcn_model.py --metric-type udp_echo --epochs 50 > logs/train_udp.log 2>&1 &
nohup python scripts/train_tcn_model.py --metric-type ecpri --epochs 50 > logs/train_ecpri.log 2>&1 &
nohup python scripts/train_tcn_model.py --metric-type lbm --epochs 50 > logs/train_lbm.log 2>&1 &

# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… í™•ì¸
jobs
ps aux | grep train_tcn

# ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f logs/train_*.log

# ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
df -h
du -sh ocad/models/*
```

---

**ì‘ì—… ì‹œê°„ ì˜ˆìƒ**: ì´ 4-8ì‹œê°„ (CPU ê¸°ì¤€)
- ë°ì´í„° ì¤€ë¹„: 30ë¶„
- TCN í•™ìŠµ (3ê°œ): 1.5-3ì‹œê°„
- Isolation Forest: 30ë¶„
- ê²€ì¦ ë° í…ŒìŠ¤íŠ¸: 1-2ì‹œê°„

**ìµœì¢… ëª©í‘œ**: ì˜¤ëŠ˜ ë‚´ë¡œ ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ âœ…
