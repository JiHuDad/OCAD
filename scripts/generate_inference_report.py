#!/usr/bin/env python3
"""ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸.

ì¶”ë¡  ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”ëœ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- ì‹œê³„ì—´ ê·¸ë˜í”„ë¡œ ì´ìƒ êµ¬ê°„ í‘œì‹œ
- ì´ìƒ ë°ì´í„° í†µê³„ ë° ì„¤ëª…
- Markdown í˜•ì‹ì˜ ë¦¬í¬íŠ¸ ìƒì„±
"""

import argparse
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))


class InferenceReportGenerator:
    """ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±ê¸°."""

    def __init__(self, inference_result_path: Path, original_data_path: Path):
        """ì´ˆê¸°í™”.

        Args:
            inference_result_path: ì¶”ë¡  ê²°ê³¼ CSV íŒŒì¼ ê²½ë¡œ
            original_data_path: ì›ë³¸ ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œ
        """
        self.inference_result_path = inference_result_path
        self.original_data_path = original_data_path

        # ë°ì´í„° ë¡œë“œ
        self.results_df = pd.read_csv(inference_result_path)
        self.original_df = pd.read_csv(original_data_path)

        # timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
        self.results_df['timestamp'] = pd.to_datetime(self.results_df['timestamp'])
        self.original_df['timestamp'] = pd.to_datetime(self.original_df['timestamp'])

        # ë‘ ë°ì´í„° ë³‘í•©
        self.merged_df = pd.merge(
            self.original_df,
            self.results_df[['timestamp', 'endpoint_id', 'residual_score',
                             'multivariate_score', 'final_score', 'is_anomaly']],
            on=['timestamp', 'endpoint_id'],
            how='left'
        )

    def generate_summary(self) -> dict:
        """ì „ì²´ ìš”ì•½ í†µê³„ ìƒì„±."""
        total_samples = len(self.results_df)
        anomaly_count = self.results_df['is_anomaly'].sum()
        anomaly_rate = (anomaly_count / total_samples) * 100

        # ì ìˆ˜ í†µê³„
        residual_mean = self.results_df['residual_score'].mean()
        multivariate_mean = self.results_df['multivariate_score'].mean()
        final_mean = self.results_df['final_score'].mean()

        return {
            'total_samples': total_samples,
            'anomaly_count': anomaly_count,
            'anomaly_rate': anomaly_rate,
            'normal_count': total_samples - anomaly_count,
            'residual_mean': residual_mean,
            'multivariate_mean': multivariate_mean,
            'final_mean': final_mean,
        }

    def find_anomaly_periods(self) -> list:
        """ì´ìƒ êµ¬ê°„ ì°¾ê¸°."""
        anomaly_df = self.merged_df[self.merged_df['is_anomaly'] == 1].copy()

        if len(anomaly_df) == 0:
            return []

        # ì—°ì†ëœ ì´ìƒ êµ¬ê°„ ê·¸ë£¹í™”
        anomaly_df['group'] = (anomaly_df['timestamp'].diff() > pd.Timedelta(minutes=2)).cumsum()

        periods = []
        for group_id, group in anomaly_df.groupby('group'):
            period = {
                'start': group['timestamp'].min(),
                'end': group['timestamp'].max(),
                'duration_minutes': (group['timestamp'].max() - group['timestamp'].min()).total_seconds() / 60,
                'count': len(group),
                'max_score': group['final_score'].max(),
                'avg_score': group['final_score'].mean(),
            }
            periods.append(period)

        return periods

    def analyze_anomaly_causes(self) -> dict:
        """ì´ìƒ ì›ì¸ ë¶„ì„."""
        anomaly_df = self.merged_df[self.merged_df['is_anomaly'] == 1]

        if len(anomaly_df) == 0:
            return {}

        # ë©”íŠ¸ë¦­ë³„ í‰ê· ê°’ ë¹„êµ
        normal_df = self.merged_df[self.merged_df['is_anomaly'] == 0]

        analysis = {}
        metrics = ['udp_echo_rtt_ms', 'ecpri_delay_us', 'lbm_rtt_ms', 'ccm_miss_count']

        for metric in metrics:
            if metric in anomaly_df.columns and metric in normal_df.columns:
                normal_mean = normal_df[metric].mean()
                anomaly_mean = anomaly_df[metric].mean()
                normal_std = normal_df[metric].std()

                # ë³€í™”ìœ¨ ê³„ì‚°
                if normal_mean > 0:
                    change_pct = ((anomaly_mean - normal_mean) / normal_mean) * 100
                else:
                    change_pct = 0

                # í‘œì¤€í¸ì°¨ ë°°ìˆ˜
                if normal_std > 0:
                    sigma_diff = (anomaly_mean - normal_mean) / normal_std
                else:
                    sigma_diff = 0

                analysis[metric] = {
                    'normal_mean': normal_mean,
                    'anomaly_mean': anomaly_mean,
                    'change_pct': change_pct,
                    'sigma_diff': sigma_diff,
                    'is_significant': abs(change_pct) > 20 or abs(sigma_diff) > 2,
                }

        return analysis

    def _create_metric_chart(self, value: float, normal: float, range_min: float, range_max: float) -> str:
        """ë©”íŠ¸ë¦­ ê°’ì„ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê°„ë‹¨í•œ ì°¨íŠ¸ ìƒì„±.

        Args:
            value: í˜„ì¬ ê°’
            normal: ì •ìƒ í‰ê· ê°’
            range_min: ì •ìƒ ë²”ìœ„ ìµœì†Œê°’
            range_max: ì •ìƒ ë²”ìœ„ ìµœëŒ€ê°’

        Returns:
            str: ASCII ì°¨íŠ¸ ë¬¸ìì—´
        """
        # ì°¨íŠ¸ ê¸¸ì´ (ì´ 50ì¹¸)
        chart_width = 50

        # ë²”ìœ„ í™•ì¥ (ì—¬ìœ  20%)
        margin = (range_max - range_min) * 0.2
        chart_min = max(0, range_min - margin)
        chart_max = range_max + margin

        # ìœ„ì¹˜ ê³„ì‚°
        def calc_pos(val):
            if chart_max == chart_min:
                return chart_width // 2
            pos = int((val - chart_min) / (chart_max - chart_min) * chart_width)
            return max(0, min(chart_width - 1, pos))

        normal_pos = calc_pos(normal)
        value_pos = calc_pos(value)
        range_start = calc_pos(range_min)
        range_end = calc_pos(range_max)

        # ì°¨íŠ¸ ìƒì„±
        chart = ['Â·'] * chart_width

        # ì •ìƒ ë²”ìœ„ í‘œì‹œ (â”)
        for i in range(range_start, range_end + 1):
            chart[i] = 'â”'

        # ì •ìƒ í‰ê·  ìœ„ì¹˜ (â”‚)
        chart[normal_pos] = 'â”‚'

        # í˜„ì¬ ê°’ ìœ„ì¹˜
        if value < range_min:
            chart[value_pos] = 'â–¼'  # ì •ìƒ ë²”ìœ„ ì•„ë˜
        elif value > range_max:
            chart[value_pos] = 'â–²'  # ì •ìƒ ë²”ìœ„ ìœ„
        else:
            chart[value_pos] = 'â—'  # ì •ìƒ ë²”ìœ„ ë‚´

        return ''.join(chart)

    def analyze_multivariate_patterns(self) -> dict:
        """ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë¶„ì„ (ê°œë³„ ë©”íŠ¸ë¦­ì´ ì •ìƒì´ì§€ë§Œ ì¡°í•©ì´ ì´ìƒì¸ ê²½ìš°)."""
        anomaly_df = self.merged_df[self.merged_df['is_anomaly'] == 1]

        if len(anomaly_df) == 0:
            return {}

        normal_df = self.merged_df[self.merged_df['is_anomaly'] == 0]

        # Multivariate Detectorê°€ ì£¼ë„í•œ ì´ìƒ íƒì§€ ì°¾ê¸°
        # (Multivariate Scoreê°€ ë†’ê³ , ê°œë³„ ë©”íŠ¸ë¦­ì€ ì •ìƒ ë²”ìœ„ì¸ ì¼€ì´ìŠ¤)
        multivariate_driven = anomaly_df[
            (anomaly_df['multivariate_score'] > 0.3) &
            (anomaly_df['residual_score'] < 0.3)
        ]

        if len(multivariate_driven) == 0:
            return {}

        # ë©”íŠ¸ë¦­ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
        metrics = ['udp_echo_rtt_ms', 'ecpri_delay_us', 'lbm_rtt_ms']
        available_metrics = [m for m in metrics if m in normal_df.columns]

        if len(available_metrics) < 2:
            return {}

        # ì •ìƒ ë°ì´í„°ì˜ ìƒê´€ê´€ê³„
        normal_corr = normal_df[available_metrics].corr()

        # ì´ìƒ ë°ì´í„°ì˜ ìƒê´€ê´€ê³„
        anomaly_corr = multivariate_driven[available_metrics].corr()

        # ìƒê´€ê´€ê³„ ë³€í™” ê³„ì‚°
        corr_changes = []
        for i in range(len(available_metrics)):
            for j in range(i + 1, len(available_metrics)):
                metric1 = available_metrics[i]
                metric2 = available_metrics[j]
                normal_val = normal_corr.loc[metric1, metric2]
                anomaly_val = anomaly_corr.loc[metric1, metric2]
                change = abs(anomaly_val - normal_val)

                if change > 0.3:  # ìƒê´€ê´€ê³„ê°€ í¬ê²Œ ë³€í•œ ê²½ìš°
                    corr_changes.append({
                        'metric1': metric1,
                        'metric2': metric2,
                        'normal_corr': normal_val,
                        'anomaly_corr': anomaly_val,
                        'change': change,
                    })

        return {
            'multivariate_driven_count': len(multivariate_driven),
            'correlation_changes': corr_changes,
            'available_metrics': available_metrics,
        }

    def generate_markdown_report(self, output_path: Path):
        """Markdown ë¦¬í¬íŠ¸ ìƒì„±."""
        summary = self.generate_summary()
        periods = self.find_anomaly_periods()
        causes = self.analyze_anomaly_causes()
        multivariate = self.analyze_multivariate_patterns()

        report_lines = []

        # í—¤ë”
        report_lines.append("# OCAD ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸")
        report_lines.append("")
        report_lines.append(f"**ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"**ì›ë³¸ ë°ì´í„°**: {self.original_data_path.name}")
        report_lines.append(f"**ì¶”ë¡  ê²°ê³¼**: {self.inference_result_path.name}")
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # ì „ì²´ ìš”ì•½
        report_lines.append("## ğŸ“Š ì „ì²´ ìš”ì•½")
        report_lines.append("")
        report_lines.append(f"- **ì´ ìƒ˜í”Œ ìˆ˜**: {summary['total_samples']:,}ê°œ")
        report_lines.append(f"- **ì •ìƒ ë°ì´í„°**: {summary['normal_count']:,}ê°œ ({100 - summary['anomaly_rate']:.1f}%)")
        report_lines.append(f"- **ì´ìƒ ë°ì´í„°**: {summary['anomaly_count']:,}ê°œ ({summary['anomaly_rate']:.1f}%)")
        report_lines.append("")
        report_lines.append("### íƒì§€ ì ìˆ˜ í‰ê· ")
        report_lines.append("")
        report_lines.append(f"- **Residual Detector**: {summary['residual_mean']:.4f}")
        report_lines.append(f"- **Multivariate Detector**: {summary['multivariate_mean']:.4f}")
        report_lines.append(f"- **Final Score**: {summary['final_mean']:.4f}")
        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # ì´ìƒ êµ¬ê°„ ë¶„ì„
        if periods:
            report_lines.append("## âš ï¸ ì´ìƒ êµ¬ê°„ ë¶„ì„")
            report_lines.append("")
            report_lines.append(f"**ì´ {len(periods)}ê°œì˜ ì´ìƒ êµ¬ê°„ì´ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.**")
            report_lines.append("")

            for i, period in enumerate(periods, 1):
                report_lines.append(f"### ì´ìƒ êµ¬ê°„ #{i}")
                report_lines.append("")
                report_lines.append(f"- **ì‹œì‘ ì‹œê°„**: {period['start'].strftime('%Y-%m-%d %H:%M:%S')}")
                report_lines.append(f"- **ì¢…ë£Œ ì‹œê°„**: {period['end'].strftime('%Y-%m-%d %H:%M:%S')}")
                report_lines.append(f"- **ì§€ì† ì‹œê°„**: {period['duration_minutes']:.1f}ë¶„")
                report_lines.append(f"- **ì´ìƒ ìƒ˜í”Œ ìˆ˜**: {period['count']}ê°œ")
                report_lines.append(f"- **ìµœëŒ€ ì´ìƒ ì ìˆ˜**: {period['max_score']:.4f}")
                report_lines.append(f"- **í‰ê·  ì´ìƒ ì ìˆ˜**: {period['avg_score']:.4f}")
                report_lines.append("")

            report_lines.append("---")
            report_lines.append("")
        else:
            report_lines.append("## âœ… ì´ìƒ êµ¬ê°„ ì—†ìŒ")
            report_lines.append("")
            report_lines.append("ëª¨ë“  ë°ì´í„°ê°€ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.")
            report_lines.append("")
            report_lines.append("---")
            report_lines.append("")

        # ì´ìƒ ì›ì¸ ë¶„ì„
        if causes:
            report_lines.append("## ğŸ” ì´ìƒ ì›ì¸ ë¶„ì„")
            report_lines.append("")
            report_lines.append("ì •ìƒ ë°ì´í„°ì™€ ì´ìƒ ë°ì´í„°ì˜ ë©”íŠ¸ë¦­ ë¹„êµ:")
            report_lines.append("")

            metric_names = {
                'udp_echo_rtt_ms': 'UDP Echo RTT',
                'ecpri_delay_us': 'eCPRI Delay',
                'lbm_rtt_ms': 'LBM RTT',
                'ccm_miss_count': 'CCM Miss Count',
            }

            for metric, data in causes.items():
                if data['is_significant']:
                    report_lines.append(f"### âš ï¸ {metric_names.get(metric, metric)}")
                    report_lines.append("")
                    report_lines.append(f"- **ì •ìƒ ì‹œ í‰ê· **: {data['normal_mean']:.2f}")
                    report_lines.append(f"- **ì´ìƒ ì‹œ í‰ê· **: {data['anomaly_mean']:.2f}")
                    report_lines.append(f"- **ë³€í™”ìœ¨**: {data['change_pct']:+.1f}%")
                    report_lines.append(f"- **í‘œì¤€í¸ì°¨ ë°°ìˆ˜**: {data['sigma_diff']:+.2f}Ïƒ")
                    report_lines.append("")

                    # ì„¤ëª… ì¶”ê°€
                    if data['change_pct'] > 50:
                        report_lines.append(f"**ğŸ’¡ ë¶„ì„**: {metric_names.get(metric, metric)}ê°€ ì •ìƒ ëŒ€ë¹„ **{data['change_pct']:.0f}% ì´ìƒ ì¦ê°€**í–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì§€ì—° ë˜ëŠ” ì„±ëŠ¥ ì €í•˜ê°€ ë°œìƒí–ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
                    elif data['change_pct'] > 20:
                        report_lines.append(f"**ğŸ’¡ ë¶„ì„**: {metric_names.get(metric, metric)}ê°€ ì •ìƒ ëŒ€ë¹„ **{data['change_pct']:.0f}% ì¦ê°€**í–ˆìŠµë‹ˆë‹¤. ì„±ëŠ¥ ì €í•˜ ì§•í›„ê°€ ê´€ì°°ë©ë‹ˆë‹¤.")
                    elif data['change_pct'] < -20:
                        report_lines.append(f"**ğŸ’¡ ë¶„ì„**: {metric_names.get(metric, metric)}ê°€ ì •ìƒ ëŒ€ë¹„ **{abs(data['change_pct']):.0f}% ê°ì†Œ**í–ˆìŠµë‹ˆë‹¤.")

                    if abs(data['sigma_diff']) > 3:
                        report_lines.append(f"**âš ï¸ ê²½ê³ **: ì •ìƒ ë²”ìœ„ì—ì„œ **{abs(data['sigma_diff']):.1f} í‘œì¤€í¸ì°¨** ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤. ë§¤ìš° ì´ë¡€ì ì¸ íŒ¨í„´ì…ë‹ˆë‹¤.")

                    report_lines.append("")

            report_lines.append("---")
            report_lines.append("")

        # ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë¶„ì„
        if multivariate and multivariate.get('multivariate_driven_count', 0) > 0:
            report_lines.append("## ğŸ§© ë‹¤ë³€ëŸ‰ íŒ¨í„´ ì´ìƒ íƒì§€")
            report_lines.append("")
            report_lines.append(f"**{multivariate['multivariate_driven_count']}ê°œì˜ ìƒ˜í”Œ**ì´ ê°œë³„ ë©”íŠ¸ë¦­ì€ ì •ìƒ ë²”ìœ„ì´ì§€ë§Œ, **ë©”íŠ¸ë¦­ ê°„ ìƒê´€ê´€ê³„(ì¡°í•© íŒ¨í„´)ê°€ ë¹„ì •ìƒ**ìœ¼ë¡œ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            report_lines.append("")
            report_lines.append("### ğŸ’¡ ë‹¤ë³€ëŸ‰ ì´ìƒ íƒì§€ë€?")
            report_lines.append("")
            report_lines.append("- **ê°œë³„ ë©”íŠ¸ë¦­ ë¶„ì„**: ê° ë©”íŠ¸ë¦­ì„ ë…ë¦½ì ìœ¼ë¡œ í‰ê°€ (ì˜ˆ: RTT < 10ms, ì†ì‹¤ < 1%)")
            report_lines.append("- **ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë¶„ì„**: ì—¬ëŸ¬ ë©”íŠ¸ë¦­ì˜ **ì¡°í•© íŒ¨í„´**ì„ í‰ê°€")
            report_lines.append("- **í•µì‹¬**: ê°œë³„ ê°’ì€ ì •ìƒì´ì§€ë§Œ, **ë©”íŠ¸ë¦­ ê°„ì˜ ìƒê´€ê´€ê³„ê°€ í•™ìŠµ ë°ì´í„°ì™€ ë‹¤ë¥¸ ê²½ìš°** ì´ìƒìœ¼ë¡œ íƒì§€")
            report_lines.append("")
            report_lines.append("### ğŸ” íƒì§€ëœ íŒ¨í„´ ë³€í™”")
            report_lines.append("")

            if multivariate.get('correlation_changes'):
                metric_names = {
                    'udp_echo_rtt_ms': 'UDP Echo RTT',
                    'ecpri_delay_us': 'eCPRI Delay',
                    'lbm_rtt_ms': 'LBM RTT',
                }

                report_lines.append("ì •ìƒ ë°ì´í„°ì™€ ì´ìƒ ë°ì´í„°ì˜ **ë©”íŠ¸ë¦­ ê°„ ìƒê´€ê´€ê³„ ë³€í™”**:")
                report_lines.append("")

                for change in multivariate['correlation_changes']:
                    m1_name = metric_names.get(change['metric1'], change['metric1'])
                    m2_name = metric_names.get(change['metric2'], change['metric2'])

                    report_lines.append(f"#### {m1_name} â†” {m2_name}")
                    report_lines.append("")
                    report_lines.append(f"- **ì •ìƒ ì‹œ ìƒê´€ê³„ìˆ˜**: {change['normal_corr']:.3f}")
                    report_lines.append(f"- **ì´ìƒ ì‹œ ìƒê´€ê³„ìˆ˜**: {change['anomaly_corr']:.3f}")
                    report_lines.append(f"- **ë³€í™”ëŸ‰**: {change['change']:.3f}")
                    report_lines.append("")

                    # í•´ì„ ì¶”ê°€
                    if abs(change['normal_corr']) > 0.5 and abs(change['anomaly_corr']) < 0.2:
                        report_lines.append(f"**ğŸ’¡ í•´ì„**: ì •ìƒ ì‹œì—ëŠ” {m1_name}ê³¼ {m2_name}ì´ **{'ì •' if change['normal_corr'] > 0 else 'ë¶€'}ì˜ ìƒê´€ê´€ê³„**ë¥¼ ë³´ì˜€ìœ¼ë‚˜, ì´ìƒ êµ¬ê°„ì—ì„œëŠ” **ìƒê´€ê´€ê³„ê°€ ì•½í™”**ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‘ ë©”íŠ¸ë¦­ì´ ë…ë¦½ì ìœ¼ë¡œ ë³€ë™í•˜ëŠ” ë¹„ì •ìƒ íŒ¨í„´ì…ë‹ˆë‹¤.")
                    elif abs(change['normal_corr']) < 0.2 and abs(change['anomaly_corr']) > 0.5:
                        report_lines.append(f"**ğŸ’¡ í•´ì„**: ì •ìƒ ì‹œì—ëŠ” {m1_name}ê³¼ {m2_name}ì´ **ë…ë¦½ì **ì´ì—ˆìœ¼ë‚˜, ì´ìƒ êµ¬ê°„ì—ì„œëŠ” **ê°•í•œ {'ì •' if change['anomaly_corr'] > 0 else 'ë¶€'}ì˜ ìƒê´€ê´€ê³„**ê°€ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ëŠ” í•™ìŠµ ë°ì´í„°ì—ì„œ ë³´ì§€ ëª»í•œ ë¹„ì •ìƒ íŒ¨í„´ì…ë‹ˆë‹¤.")
                    else:
                        report_lines.append(f"**ğŸ’¡ í•´ì„**: {m1_name}ê³¼ {m2_name}ì˜ ìƒê´€ê´€ê³„ê°€ ì •ìƒ ë°ì´í„°ì™€ í¬ê²Œ ë‹¬ë¼ì¡ŒìŠµë‹ˆë‹¤. ì´ëŠ” ë„¤íŠ¸ì›Œí¬ ê²½ë¡œ ë³€ê²½, ì¥ë¹„ ë™ì‘ ëª¨ë“œ ë³€í™” ë“±ì˜ ì‹ í˜¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                    report_lines.append("")

            else:
                report_lines.append("ë©”íŠ¸ë¦­ ê°„ ìƒê´€ê´€ê³„ ë³€í™”ëŠ” ë¯¸ë¯¸í•˜ì§€ë§Œ, **ê³ ì°¨ì› ê³µê°„ì—ì„œì˜ íŒ¨í„´**ì´ ì •ìƒ í•™ìŠµ ë°ì´í„°ì™€ ë‹¤ë¥¸ ê²ƒìœ¼ë¡œ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                report_lines.append("")
                report_lines.append("ì´ëŠ” Isolation Forestê°€ 2ê°œ ì´ìƒì˜ ë©”íŠ¸ë¦­ì„ ì¡°í•©í–ˆì„ ë•Œ í•™ìŠµ ë°ì´í„°ì™€ ë‹¤ë¥¸ **ë“œë¬¸ íŒ¨í„´(isolated)**ì„ ë°œê²¬í–ˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.")
                report_lines.append("")

            report_lines.append("### âš ï¸ ì™œ ì¤‘ìš”í•œê°€?")
            report_lines.append("")
            report_lines.append("ë‹¤ë³€ëŸ‰ íŒ¨í„´ ì´ìƒ íƒì§€ëŠ” **ê°œë³„ ì„ê³„ê°’ ê¸°ë°˜ íƒì§€ë¡œëŠ” ë†“ì¹  ìˆ˜ ìˆëŠ” ë¯¸ë¬˜í•œ ì¥ì•  ì‹ í˜¸**ë¥¼ ì¡°ê¸° ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            report_lines.append("")
            report_lines.append("- **í•˜ë“œì›¨ì–´ ë¶€ë¶„ ê³ ì¥**: ê°œë³„ ë©”íŠ¸ë¦­ì€ ì„ê³„ê°’ ì´í•˜ì§€ë§Œ, ë©”íŠ¸ë¦­ ì¡°í•©ì´ ë¹„ì •ìƒ")
            report_lines.append("- **ë„¤íŠ¸ì›Œí¬ ê²½ë¡œ ë³€ê²½**: RTT, ì†ì‹¤ë¥ ì€ ì •ìƒì´ì§€ë§Œ, ê·¸ë“¤ì˜ ê´€ê³„ê°€ í‰ì†Œì™€ ë‹¤ë¦„")
            report_lines.append("- **ê°„í—ì  ë¬¸ì œ**: í‰ê· ì ìœ¼ë¡œ ì •ìƒì´ì§€ë§Œ, ë©”íŠ¸ë¦­ ê°„ ë™ê¸°í™” íŒ¨í„´ì´ ë³€í•¨")
            report_lines.append("")

            report_lines.append("---")
            report_lines.append("")

        # ê¶Œì¥ ì‚¬í•­
        report_lines.append("## ğŸ’¡ ê¶Œì¥ ì‚¬í•­")
        report_lines.append("")

        if summary['anomaly_rate'] > 50:
            report_lines.append("### ğŸ”´ ë†’ì€ ì´ìƒ íƒì§€ìœ¨ (50% ì´ìƒ)")
            report_lines.append("")
            report_lines.append("1. **ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”**: ë„¤íŠ¸ì›Œí¬ ë˜ëŠ” ì¥ë¹„ì— ì‹¬ê°í•œ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            report_lines.append("2. **ì›ì¸ íŒŒì•…**: ì´ìƒ êµ¬ê°„ì˜ ì‹œì‘ ì‹œê°„ê³¼ ì‹œìŠ¤í…œ ë¡œê·¸ë¥¼ ëŒ€ì¡°í•˜ì—¬ ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.")
            report_lines.append("3. **ì¥ë¹„ ì ê²€**: í•´ë‹¹ ì‹œê°„ëŒ€ì— ì¥ë¹„ ì¬ì‹œì‘, ì„¤ì • ë³€ê²½ ë“±ì´ ìˆì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        elif summary['anomaly_rate'] > 20:
            report_lines.append("### ğŸŸ¡ ì¤‘ê°„ ì´ìƒ íƒì§€ìœ¨ (20-50%)")
            report_lines.append("")
            report_lines.append("1. **ëª¨ë‹ˆí„°ë§ ê°•í™”**: ì´ìƒ êµ¬ê°„ì´ ê³„ì† ì¦ê°€í•˜ëŠ”ì§€ ê´€ì°°í•˜ì„¸ìš”.")
            report_lines.append("2. **ì„±ëŠ¥ ë¶„ì„**: ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ì¦ê°€, ê°„ì„­ ë“± ì™¸ë¶€ ìš”ì¸ì„ í™•ì¸í•˜ì„¸ìš”.")
            report_lines.append("3. **ì˜ˆë°© ì¡°ì¹˜**: í•„ìš”ì‹œ ì¥ë¹„ ì„¤ì • ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        elif summary['anomaly_rate'] > 5:
            report_lines.append("### ğŸŸ¢ ë‚®ì€ ì´ìƒ íƒì§€ìœ¨ (5-20%)")
            report_lines.append("")
            report_lines.append("1. **ì •ìƒ ë²”ìœ„**: ì¼ì‹œì ì¸ ì´ìƒ íŒ¨í„´ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.")
            report_lines.append("2. **ê³„ì† ëª¨ë‹ˆí„°ë§**: ì´ìƒ êµ¬ê°„ì´ ë°˜ë³µë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            report_lines.append("3. **íŒ¨í„´ ë¶„ì„**: íŠ¹ì • ì‹œê°„ëŒ€ì— ì´ìƒì´ ì§‘ì¤‘ë˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        else:
            report_lines.append("### âœ… ì •ìƒ ìƒíƒœ (5% ë¯¸ë§Œ)")
            report_lines.append("")
            report_lines.append("1. **ì–‘í˜¸í•œ ìƒíƒœ**: ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            report_lines.append("2. **ì¼ìƒì  ëª¨ë‹ˆí„°ë§**: ì •ê¸°ì ì¸ ì ê²€ì„ ê³„ì†í•˜ì„¸ìš”.")

        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

        # ë°ì´í„° ìƒ˜í”Œ (ìƒì„¸ ì„¤ëª… í¬í•¨)
        report_lines.append("## ğŸ“‹ ì´ìƒ ë°ì´í„° ìƒ˜í”Œ (ìƒìœ„ 10ê°œ)")
        report_lines.append("")

        # ìµœì¢… ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 10ê°œ ì¶”ì¶œ
        anomaly_samples = self.merged_df[self.merged_df['is_anomaly'] == 1].nlargest(10, 'final_score')

        if len(anomaly_samples) > 0:
            # ì •ìƒ ë°ì´í„° ê¸°ì¤€ê°’ ê³„ì‚°
            normal_df = self.merged_df[self.merged_df['is_anomaly'] == 0]
            normal_means = {}
            normal_stds = {}
            normal_ranges = {}  # ì •ìƒ ë²”ìœ„ (mean Â± 2*std)

            for metric in ['udp_echo_rtt_ms', 'ecpri_delay_us', 'lbm_rtt_ms', 'ccm_miss_count']:
                if metric in normal_df.columns:
                    normal_means[metric] = normal_df[metric].mean()
                    normal_stds[metric] = normal_df[metric].std()
                    # ì •ìƒ ë²”ìœ„: mean Â± 2*std (ì•½ 95% ì‹ ë¢°êµ¬ê°„)
                    normal_ranges[metric] = {
                        'min': normal_means[metric] - 2 * normal_stds[metric],
                        'max': normal_means[metric] + 2 * normal_stds[metric],
                    }

            report_lines.append("ê° ìƒ˜í”Œì´ **ì™œ ì´ìƒìœ¼ë¡œ íŒë‹¨ë˜ì—ˆëŠ”ì§€** êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤:")
            report_lines.append("")

            for idx, (_, row) in enumerate(anomaly_samples.iterrows(), 1):
                report_lines.append(f"### ğŸ”´ ì´ìƒ ìƒ˜í”Œ #{idx}")
                report_lines.append("")
                report_lines.append(f"**ì‹œê°„**: {row['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                report_lines.append(f"**ìµœì¢… ì´ìƒ ì ìˆ˜**: {row['final_score']:.4f}")
                report_lines.append("")

                # íƒì§€ê¸°ë³„ ì ìˆ˜ ë¶„ì„
                residual_score = row['residual_score'] if 'residual_score' in row.index else 0
                multivariate_score = row['multivariate_score'] if 'multivariate_score' in row.index else 0

                report_lines.append("**íƒì§€ê¸° ë¶„ì„**:")
                report_lines.append("")
                report_lines.append(f"- **Residual Score (TCN)**: {residual_score:.4f} {'ğŸ”´' if residual_score > 0.7 else 'ğŸŸ¡' if residual_score > 0.3 else 'ğŸŸ¢'}")
                report_lines.append(f"- **Multivariate Score (Isolation Forest)**: {multivariate_score:.4f} {'ğŸ”´' if multivariate_score > 0.7 else 'ğŸŸ¡' if multivariate_score > 0.3 else 'ğŸŸ¢'}")
                report_lines.append("")

                # ì£¼ë„ íƒì§€ê¸° íŒŒì•…
                if residual_score > multivariate_score and residual_score > 0.3:
                    report_lines.append("**ğŸ¯ ì£¼ë„ íƒì§€ê¸°**: TCN (Residual Detector)")
                    report_lines.append("â†’ ì‹œê³„ì—´ íŒ¨í„´ì´ í•™ìŠµ ë°ì´í„°ì™€ ë‹¤ë¦…ë‹ˆë‹¤.")
                elif multivariate_score > residual_score and multivariate_score > 0.3:
                    report_lines.append("**ğŸ¯ ì£¼ë„ íƒì§€ê¸°**: Isolation Forest (Multivariate Detector)")
                    report_lines.append("â†’ ë©”íŠ¸ë¦­ ê°„ ì¡°í•© íŒ¨í„´ì´ ë¹„ì •ìƒì…ë‹ˆë‹¤.")
                else:
                    report_lines.append("**ğŸ¯ ì£¼ë„ íƒì§€ê¸°**: ë³µí•© íƒì§€ (ì—¬ëŸ¬ íƒì§€ê¸°ê°€ í•¨ê»˜ íƒì§€)")
                report_lines.append("")

                # ë©”íŠ¸ë¦­ë³„ ìƒì„¸ ë¶„ì„
                report_lines.append("**ë©”íŠ¸ë¦­ ë¶„ì„**:")
                report_lines.append("")

                problems = []
                metric_details = []

                # UDP Echo RTT
                if 'udp_echo_rtt_ms' in row.index and 'udp_echo_rtt_ms' in normal_means:
                    value = row['udp_echo_rtt_ms']
                    normal = normal_means['udp_echo_rtt_ms']
                    std = normal_stds['udp_echo_rtt_ms']
                    range_min = normal_ranges['udp_echo_rtt_ms']['min']
                    range_max = normal_ranges['udp_echo_rtt_ms']['max']

                    diff_pct = ((value - normal) / normal * 100) if normal > 0 else 0
                    sigma = ((value - normal) / std) if std > 0 else 0

                    # ì •ìƒ ë²”ìœ„ ë²—ì–´ë‚¨ íŒë‹¨
                    out_of_range = value < range_min or value > range_max

                    status = "ğŸ”´" if abs(diff_pct) > 50 or abs(sigma) > 3 else "ğŸŸ¡" if abs(diff_pct) > 20 or abs(sigma) > 2 else "ğŸŸ¢"
                    report_lines.append(f"- {status} **UDP Echo RTT**: {value:.2f} ms")
                    report_lines.append(f"  - ì •ìƒ í‰ê· : {normal:.2f} ms (ë²”ìœ„: {max(0, range_min):.2f} ~ {range_max:.2f} ms)")
                    report_lines.append(f"  - ì°¨ì´: {diff_pct:+.1f}% ({sigma:+.2f}Ïƒ)")

                    # ì‹œê°ì  í‘œí˜„ (ê°„ë‹¨í•œ ì°¨íŠ¸)
                    chart = self._create_metric_chart(value, normal, range_min, range_max)
                    report_lines.append(f"  - ì‹œê°í™”: {chart}")

                    if out_of_range:
                        if value > range_max:
                            problems.append(f"UDP Echo RTTê°€ ì •ìƒ ë²”ìœ„ë¥¼ í¬ê²Œ ì´ˆê³¼ ({value:.1f}ms > {range_max:.1f}ms)")
                            metric_details.append("**ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì¦ê°€**")
                        else:
                            problems.append(f"UDP Echo RTTê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ìŒ ({value:.1f}ms < {range_min:.1f}ms)")
                            metric_details.append("**ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ì€ RTT (ìºì‹±/ìš°íšŒ?)**")
                    elif abs(diff_pct) > 20:
                        problems.append(f"UDP Echo RTTê°€ ì•½ê°„ {'ë†’ìŒ' if diff_pct > 0 else 'ë‚®ìŒ'} (ì •ìƒ ëŒ€ë¹„ {abs(diff_pct):.0f}%)")
                    report_lines.append("")

                # eCPRI Delay
                if 'ecpri_delay_us' in row.index and 'ecpri_delay_us' in normal_means:
                    value = row['ecpri_delay_us']
                    normal = normal_means['ecpri_delay_us']
                    std = normal_stds['ecpri_delay_us']
                    range_min = normal_ranges['ecpri_delay_us']['min']
                    range_max = normal_ranges['ecpri_delay_us']['max']

                    diff_pct = ((value - normal) / normal * 100) if normal > 0 else 0
                    sigma = ((value - normal) / std) if std > 0 else 0

                    out_of_range = value < range_min or value > range_max

                    status = "ğŸ”´" if abs(diff_pct) > 50 or abs(sigma) > 3 else "ğŸŸ¡" if abs(diff_pct) > 20 or abs(sigma) > 2 else "ğŸŸ¢"
                    report_lines.append(f"- {status} **eCPRI Delay**: {value:.2f} Î¼s")
                    report_lines.append(f"  - ì •ìƒ í‰ê· : {normal:.2f} Î¼s (ë²”ìœ„: {max(0, range_min):.2f} ~ {range_max:.2f} Î¼s)")
                    report_lines.append(f"  - ì°¨ì´: {diff_pct:+.1f}% ({sigma:+.2f}Ïƒ)")

                    chart = self._create_metric_chart(value, normal, range_min, range_max)
                    report_lines.append(f"  - ì‹œê°í™”: {chart}")

                    if out_of_range:
                        if value > range_max:
                            problems.append(f"eCPRI ì§€ì—°ì´ ì •ìƒ ë²”ìœ„ë¥¼ ì´ˆê³¼ ({value:.1f}Î¼s > {range_max:.1f}Î¼s)")
                            metric_details.append("**í”„ë¡ íŠ¸í™€ ì§€ì—° ì¦ê°€**")
                        else:
                            problems.append(f"eCPRI ì§€ì—°ì´ ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ìŒ ({value:.1f}Î¼s < {range_min:.1f}Î¼s)")
                    elif abs(diff_pct) > 20:
                        problems.append(f"eCPRI ì§€ì—°ì´ ì•½ê°„ {'ë†’ìŒ' if diff_pct > 0 else 'ë‚®ìŒ'} (ì •ìƒ ëŒ€ë¹„ {abs(diff_pct):.0f}%)")
                    report_lines.append("")

                # LBM RTT
                if 'lbm_rtt_ms' in row.index and 'lbm_rtt_ms' in normal_means:
                    value = row['lbm_rtt_ms']
                    normal = normal_means['lbm_rtt_ms']
                    std = normal_stds['lbm_rtt_ms']
                    range_min = normal_ranges['lbm_rtt_ms']['min']
                    range_max = normal_ranges['lbm_rtt_ms']['max']

                    diff_pct = ((value - normal) / normal * 100) if normal > 0 else 0
                    sigma = ((value - normal) / std) if std > 0 else 0

                    out_of_range = value < range_min or value > range_max

                    status = "ğŸ”´" if abs(diff_pct) > 50 or abs(sigma) > 3 else "ğŸŸ¡" if abs(diff_pct) > 20 or abs(sigma) > 2 else "ğŸŸ¢"
                    report_lines.append(f"- {status} **LBM RTT**: {value:.2f} ms")
                    report_lines.append(f"  - ì •ìƒ í‰ê· : {normal:.2f} ms (ë²”ìœ„: {max(0, range_min):.2f} ~ {range_max:.2f} ms)")
                    report_lines.append(f"  - ì°¨ì´: {diff_pct:+.1f}% ({sigma:+.2f}Ïƒ)")

                    chart = self._create_metric_chart(value, normal, range_min, range_max)
                    report_lines.append(f"  - ì‹œê°í™”: {chart}")

                    if out_of_range:
                        if value > range_max:
                            problems.append(f"LBM RTTê°€ ì •ìƒ ë²”ìœ„ë¥¼ ì´ˆê³¼ ({value:.1f}ms > {range_max:.1f}ms)")
                            metric_details.append("**ì´ë”ë„· ë§í¬ ì§€ì—° ì¦ê°€**")
                        else:
                            problems.append(f"LBM RTTê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë‚®ìŒ ({value:.1f}ms < {range_min:.1f}ms)")
                    elif abs(diff_pct) > 20:
                        problems.append(f"LBM RTTê°€ ì•½ê°„ {'ë†’ìŒ' if diff_pct > 0 else 'ë‚®ìŒ'} (ì •ìƒ ëŒ€ë¹„ {abs(diff_pct):.0f}%)")
                    report_lines.append("")

                # CCM Miss Count
                if 'ccm_miss_count' in row.index and 'ccm_miss_count' in normal_means:
                    value = int(row['ccm_miss_count'])
                    normal = normal_means['ccm_miss_count']

                    status = "ğŸ”´" if value > 5 else "ğŸŸ¡" if value > 0 else "ğŸŸ¢"
                    report_lines.append(f"- {status} **CCM Miss Count**: {value}íšŒ")
                    report_lines.append(f"  - ì •ìƒ í‰ê· : {normal:.1f}íšŒ")

                    if value > 5:
                        problems.append(f"íŒ¨í‚· ì†ì‹¤ì´ ì‹¬ê°í•¨ ({value}íšŒ)")
                        metric_details.append("**ì‹¬ê°í•œ íŒ¨í‚· ì†ì‹¤**")
                    elif value > 0:
                        problems.append(f"íŒ¨í‚· ì†ì‹¤ ë°œìƒ ({value}íšŒ)")
                        metric_details.append("**ê°„í—ì  íŒ¨í‚· ì†ì‹¤**")
                    report_lines.append("")

                # ì¢…í•© íŒë‹¨ (ê°œì„ ëœ ë²„ì „)
                report_lines.append("**ğŸ’¡ ì¢…í•© íŒë‹¨ - ì™œ ì´ìƒìœ¼ë¡œ íƒì§€ë˜ì—ˆë‚˜?**:")
                report_lines.append("")

                if problems:
                    report_lines.append("**ë©”íŠ¸ë¦­ ê¸°ë°˜ ì´ìƒ íƒì§€**:")
                    report_lines.append("")
                    for problem in problems:
                        report_lines.append(f"  - {problem}")
                    report_lines.append("")

                    if metric_details:
                        report_lines.append("**ì§„ë‹¨**:")
                        for detail in metric_details:
                            report_lines.append(f"  - {detail}")
                        report_lines.append("")

                # íƒì§€ê¸°ë³„ êµ¬ì²´ì  ì„¤ëª…
                if residual_score > 0.5:
                    report_lines.append("**TCN (Residual Detector) íƒì§€ ì´ìœ **:")
                    report_lines.append("")
                    report_lines.append(f"  - TCN ëª¨ë¸ì´ í•™ìŠµí•œ ì‹œê³„ì—´ íŒ¨í„´ê³¼ **í˜„ì¬ íŒ¨í„´ì´ {residual_score:.1%} ì°¨ì´**")
                    report_lines.append("  - ë©”íŠ¸ë¦­ ê°„ ìƒê´€ê´€ê³„ê°€ í•™ìŠµ ë°ì´í„°ì™€ ë‹¤ë¦„")
                    report_lines.append("  - ì˜ˆ: ì •ìƒ ì‹œ 'UDP RTT â†‘ â†’ eCPRI Delay â†‘'ì¸ë°, í˜„ì¬ëŠ” ì—­ê´€ê³„ ë˜ëŠ” ë¬´ìƒê´€")
                    report_lines.append("")

                if multivariate_score > 0.3:
                    report_lines.append("**Isolation Forest (Multivariate Detector) íƒì§€ ì´ìœ **:")
                    report_lines.append("")
                    report_lines.append(f"  - ë©”íŠ¸ë¦­ ì¡°í•© íŒ¨í„´ì´ í•™ìŠµ ë°ì´í„°ì—ì„œ **{multivariate_score:.1%} isolated (ë“œë¬¸ íŒ¨í„´)**")
                    report_lines.append("  - ê°œë³„ ë©”íŠ¸ë¦­ì€ ì •ìƒì´ì–´ë„, ì¡°í•©ì´ ë¹„ì •ìƒ")
                    report_lines.append("  - ì˜ˆ: UDP RTT=5ms, eCPRI=150Î¼s ê°ê°ì€ ì •ìƒì´ì§€ë§Œ, ì´ ì¡°í•©ì€ í•™ìŠµ ë°ì´í„°ì— ì—†ìŒ")
                    report_lines.append("")

                # ê²°ë¡ 
                if not problems and (residual_score < 0.3 and multivariate_score < 0.3):
                    report_lines.append("**âš ï¸ ê²½ë¯¸í•œ ì´ìƒ**: ë©”íŠ¸ë¦­ ê°’ì€ ì •ìƒ ë²”ìœ„ì´ì§€ë§Œ, ë¯¸ë¬˜í•œ íŒ¨í„´ ë³€í™”ê°€ ê°ì§€ë¨")
                    report_lines.append("")
                elif residual_score > 0.7 or multivariate_score > 0.7:
                    report_lines.append("**ğŸš¨ ì‹¬ê°í•œ ì´ìƒ**: ì¦‰ì‹œ ì¡°ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
                    report_lines.append("")
                else:
                    report_lines.append("**âš ï¸ ì¤‘ê°„ ìˆ˜ì¤€ ì´ìƒ**: ëª¨ë‹ˆí„°ë§ ê°•í™” ê¶Œì¥")
                    report_lines.append("")

                report_lines.append("---")
                report_lines.append("")
        else:
            report_lines.append("ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            report_lines.append("")
            report_lines.append("---")
            report_lines.append("")

        # í‘¸í„°
        report_lines.append("## ğŸ“Œ ì°¸ê³ ì‚¬í•­")
        report_lines.append("")
        report_lines.append("- **ì´ìƒ ì ìˆ˜ (Final Score)**: 0.0 (ì •ìƒ) ~ 1.0 (ì´ìƒ)")
        report_lines.append("- **ì´ìƒ ê¸°ì¤€**: Final Score > 0.5")
        report_lines.append("- **Residual Detector**: ì‹œê³„ì—´ ì˜ˆì¸¡-ì”ì°¨ ê¸°ë°˜ íƒì§€")
        report_lines.append("- **Multivariate Detector**: ë‹¤ë³€ëŸ‰ ì´ìƒ íƒì§€ (Isolation Forest)")
        report_lines.append("")

        # íŒŒì¼ ì €ì¥
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))

        print(f"\nâœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_path}")
        return output_path


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(
        description="ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "--inference-result",
        type=Path,
        required=True,
        help="ì¶”ë¡  ê²°ê³¼ CSV íŒŒì¼ (inference_simple.py ì¶œë ¥)",
    )
    parser.add_argument(
        "--original-data",
        type=Path,
        required=True,
        help="ì›ë³¸ ë°ì´í„° CSV íŒŒì¼",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=None,
        help="ì¶œë ¥ ë¦¬í¬íŠ¸ ê²½ë¡œ (ê¸°ë³¸: ìë™ ìƒì„±)",
    )

    args = parser.parse_args()

    # ì¶œë ¥ ê²½ë¡œ ìë™ ìƒì„±
    if args.output is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        args.output = Path(f"reports/inference_report_{timestamp}.md")

    print("=" * 70)
    print("ğŸ“Š OCAD ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±ê¸°")
    print("=" * 70)
    print(f"\nì¶”ë¡  ê²°ê³¼: {args.inference_result}")
    print(f"ì›ë³¸ ë°ì´í„°: {args.original_data}")
    print(f"ì¶œë ¥ ê²½ë¡œ: {args.output}")

    # ë¦¬í¬íŠ¸ ìƒì„±
    generator = InferenceReportGenerator(args.inference_result, args.original_data)
    output_path = generator.generate_markdown_report(args.output)

    print("\n" + "=" * 70)
    print("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
    print("=" * 70)
    print(f"\në¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”: {output_path.absolute()}")
    print(f"\nëª…ë ¹ì–´: cat {output_path}")


if __name__ == "__main__":
    main()
