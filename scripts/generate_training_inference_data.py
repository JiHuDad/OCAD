#!/usr/bin/env python3
"""í•™ìŠµìš© ë° ì¶”ë¡ ìš© ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸.

ì´ìƒ íƒì§€ ì›Œí¬í”Œë¡œìš°:
1. í•™ìŠµ: ì •ìƒ ë°ì´í„°ë¡œë§Œ í•™ìŠµ (normal pattern í•™ìŠµ)
2. ì¶”ë¡ : ì •ìƒ/ë¹„ì •ìƒ ë°ì´í„° ëª¨ë‘ í…ŒìŠ¤íŠ¸ (ì´ìƒ ì—¬ë¶€ íŒë‹¨)
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))


class TrainingInferenceDataGenerator:
    """í•™ìŠµ/ì¶”ë¡  ë°ì´í„° ìƒì„±ê¸°."""

    def __init__(self, output_dir: Path):
        """ì´ˆê¸°í™”."""
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def generate_normal_training_data(
        self,
        num_endpoints: int = 5,
        duration_hours: int = 48,
        interval_seconds: int = 30
    ) -> pd.DataFrame:
        """ì •ìƒ ë°ì´í„° ìƒì„± (í•™ìŠµìš©).

        ì´ìƒ íƒì§€ ëª¨ë¸ì€ ì •ìƒ íŒ¨í„´ë§Œ í•™ìŠµí•©ë‹ˆë‹¤.

        Args:
            num_endpoints: ì—”ë“œí¬ì¸íŠ¸ ìˆ˜
            duration_hours: ìƒì„±í•  ë°ì´í„° ê¸°ê°„ (ì‹œê°„)
            interval_seconds: ì¸¡ì • ê°„ê²© (ì´ˆ)

        Returns:
            DataFrame: ì •ìƒ ë°ì´í„°
        """
        base_time = datetime(2025, 10, 1, 0, 0, 0)
        num_samples = int(duration_hours * 3600 / interval_seconds)

        data = []

        # ì—”ë“œí¬ì¸íŠ¸ë³„ ê¸°ì¤€ê°’ (ì•½ê°„ì”© ë‹¤ë¦„)
        endpoints_config = {
            "o-ru-001": {"udp": 5.0, "ecpri": 100.0, "lbm": 7.0, "site": "Tower-A", "zone": "Urban"},
            "o-ru-002": {"udp": 4.8, "ecpri": 98.0, "lbm": 6.8, "site": "Tower-B", "zone": "Rural"},
            "o-ru-003": {"udp": 5.2, "ecpri": 102.0, "lbm": 7.2, "site": "Tower-C", "zone": "Suburban"},
            "o-du-001": {"udp": 3.5, "ecpri": 85.0, "lbm": 5.0, "site": "DC-A", "zone": "Urban"},
            "o-du-002": {"udp": 3.3, "ecpri": 83.0, "lbm": 4.8, "site": "DC-B", "zone": "Urban"},
        }

        selected_endpoints = list(endpoints_config.keys())[:num_endpoints]

        for endpoint_id in selected_endpoints:
            config = endpoints_config[endpoint_id]

            for i in range(num_samples):
                timestamp = base_time + timedelta(seconds=i * interval_seconds)

                # ì •ìƒ ë²”ìœ„ ë‚´ ë³€ë™ (Â±10%, ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ)
                udp_rtt = config["udp"] + np.random.normal(0, config["udp"] * 0.05)
                ecpri = config["ecpri"] + np.random.normal(0, config["ecpri"] * 0.05)
                lbm_rtt = config["lbm"] + np.random.normal(0, config["lbm"] * 0.05)

                # ì¼ì¼ ì£¼ê¸° ë°˜ì˜ (ë°¤ì—ëŠ” ì•½ê°„ ë‚®ìŒ)
                hour = timestamp.hour
                if 0 <= hour < 6:  # ì•¼ê°„
                    daily_factor = 0.95
                elif 9 <= hour < 18:  # ì£¼ê°„ (íŠ¸ë˜í”½ ë§ìŒ)
                    daily_factor = 1.05
                else:  # ì¶œí‡´ê·¼ ì‹œê°„
                    daily_factor = 1.0

                udp_rtt *= daily_factor
                ecpri *= daily_factor
                lbm_rtt *= daily_factor

                data.append({
                    "timestamp": timestamp.strftime("%Y-%m-%d %H:%M:%S"),
                    "endpoint_id": endpoint_id,
                    "site_name": config["site"],
                    "zone": config["zone"],
                    "udp_echo_rtt_ms": round(max(0, udp_rtt), 2),
                    "ecpri_delay_us": round(max(0, ecpri), 2),
                    "lbm_rtt_ms": round(max(0, lbm_rtt), 2),
                    "lbm_success": True,
                    "ccm_interval_ms": 1000,
                    "ccm_miss_count": 0,
                    "label": "normal"  # í•™ìŠµìš© ë¼ë²¨
                })

        return pd.DataFrame(data)

    def generate_inference_test_data(self) -> pd.DataFrame:
        """ì¶”ë¡  í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„± (ì •ìƒ + ë¹„ì •ìƒ).

        ë‹¤ì–‘í•œ ì´ìƒ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

        Returns:
            DataFrame: í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì •ìƒ + ë¹„ì •ìƒ)
        """
        base_time = datetime(2025, 10, 15, 12, 0, 0)
        data = []

        # ========================================
        # Scenario 1: ì •ìƒ ë°ì´í„° (30ë¶„)
        # ========================================
        print("  [1/6] ì •ìƒ ë°ì´í„° ìƒì„± ì¤‘...")
        for i in range(180):  # 10ì´ˆ ê°„ê²©, 30ë¶„
            timestamp = base_time + timedelta(seconds=i * 10)
            data.append({
                "timestamp": timestamp.strftime("%Y-%m-%d %H:%M:%S"),
                "endpoint_id": "o-ru-test-001",
                "site_name": "Test-Site-A",
                "zone": "Urban",
                "udp_echo_rtt_ms": round(5.0 + np.random.normal(0, 0.3), 2),
                "ecpri_delay_us": round(100.0 + np.random.normal(0, 5.0), 2),
                "lbm_rtt_ms": round(7.0 + np.random.normal(0, 0.4), 2),
                "lbm_success": True,
                "ccm_interval_ms": 1000,
                "ccm_miss_count": 0,
                "label": "normal",
                "scenario": "ì •ìƒ ìš´ì˜"
            })

        base_time += timedelta(minutes=30)

        # ========================================
        # Scenario 2: Drift (ì ì§„ì  ì¦ê°€) - 30ë¶„
        # ========================================
        print("  [2/6] Drift ì´ìƒ íŒ¨í„´ ìƒì„± ì¤‘...")
        for i in range(180):
            timestamp = base_time + timedelta(seconds=i * 10)
            progress = i / 180.0  # 0 to 1

            # ì ì§„ì ìœ¼ë¡œ ì¦ê°€
            udp_rtt = 5.0 + (progress * 20.0) + np.random.normal(0, 0.5)
            ecpri = 100.0 + (progress * 250.0) + np.random.normal(0, 10.0)
            lbm_rtt = 7.0 + (progress * 18.0) + np.random.normal(0, 0.6)

            data.append({
                "timestamp": timestamp.strftime("%Y-%m-%d %H:%M:%S"),
                "endpoint_id": "o-ru-test-001",
                "site_name": "Test-Site-A",
                "zone": "Urban",
                "udp_echo_rtt_ms": round(udp_rtt, 2),
                "ecpri_delay_us": round(ecpri, 2),
                "lbm_rtt_ms": round(lbm_rtt, 2),
                "lbm_success": progress < 0.8,
                "ccm_interval_ms": 1000,
                "ccm_miss_count": 1 if progress > 0.7 else 0,
                "label": "anomaly",
                "scenario": "Drift (ì ì§„ì  ì¦ê°€)"
            })

        base_time += timedelta(minutes=30)

        # ========================================
        # Scenario 3: Spike (ê¸‰ê²©í•œ ì¼ì‹œì  ì¦ê°€) - 20ë¶„
        # ========================================
        print("  [3/6] Spike ì´ìƒ íŒ¨í„´ ìƒì„± ì¤‘...")
        for i in range(120):
            timestamp = base_time + timedelta(seconds=i * 10)

            # ë§¤ 2ë¶„ë§ˆë‹¤ spike
            is_spike = (i % 12 == 6)

            if is_spike:
                udp_rtt = 25.0 + np.random.normal(0, 2.0)
                ecpri = 350.0 + np.random.normal(0, 20.0)
                lbm_rtt = 23.0 + np.random.normal(0, 2.0)
                lbm_success = False
                label = "anomaly"
            else:
                udp_rtt = 5.0 + np.random.normal(0, 0.3)
                ecpri = 100.0 + np.random.normal(0, 5.0)
                lbm_rtt = 7.0 + np.random.normal(0, 0.4)
                lbm_success = True
                label = "normal"

            data.append({
                "timestamp": timestamp.strftime("%Y-%m-%d %H:%M:%S"),
                "endpoint_id": "o-ru-test-001",
                "site_name": "Test-Site-A",
                "zone": "Urban",
                "udp_echo_rtt_ms": round(udp_rtt, 2),
                "ecpri_delay_us": round(ecpri, 2),
                "lbm_rtt_ms": round(lbm_rtt, 2),
                "lbm_success": lbm_success,
                "ccm_interval_ms": 1000,
                "ccm_miss_count": 1 if is_spike else 0,
                "label": label,
                "scenario": "Spike (ì¼ì‹œì  ê¸‰ì¦)"
            })

        base_time += timedelta(minutes=20)

        # ========================================
        # Scenario 4: Jitter (ë¶ˆì•ˆì •) - 20ë¶„
        # ========================================
        print("  [4/6] Jitter ì´ìƒ íŒ¨í„´ ìƒì„± ì¤‘...")
        for i in range(120):
            timestamp = base_time + timedelta(seconds=i * 10)

            # ë¶ˆê·œì¹™í•œ ë³€ë™ (ì§„í­ í¼)
            if i % 3 == 0:
                udp_rtt = 5.0 + np.random.uniform(-2, 15)
                ecpri = 100.0 + np.random.uniform(-20, 200)
                label = "anomaly" if udp_rtt > 10 else "normal"
            else:
                udp_rtt = 5.0 + np.random.normal(0, 0.3)
                ecpri = 100.0 + np.random.normal(0, 5.0)
                label = "normal"

            lbm_rtt = 7.0 + np.random.normal(0, 1.0)

            data.append({
                "timestamp": timestamp.strftime("%Y-%m-%d %H:%M:%S"),
                "endpoint_id": "o-ru-test-001",
                "site_name": "Test-Site-A",
                "zone": "Urban",
                "udp_echo_rtt_ms": round(max(0, udp_rtt), 2),
                "ecpri_delay_us": round(max(0, ecpri), 2),
                "lbm_rtt_ms": round(max(0, lbm_rtt), 2),
                "lbm_success": True,
                "ccm_interval_ms": 1000,
                "ccm_miss_count": 0,
                "label": label,
                "scenario": "Jitter (ë¶ˆì•ˆì •)"
            })

        base_time += timedelta(minutes=20)

        # ========================================
        # Scenario 5: ë³µí•© ì¥ì•  (ì—¬ëŸ¬ ë©”íŠ¸ë¦­ ë™ì‹œ ì´ìƒ) - 15ë¶„
        # ========================================
        print("  [5/6] ë³µí•© ì¥ì•  íŒ¨í„´ ìƒì„± ì¤‘...")
        for i in range(90):
            timestamp = base_time + timedelta(seconds=i * 10)

            # ëª¨ë“  ë©”íŠ¸ë¦­ì´ ë™ì‹œì— ë‚˜ë¹ ì§
            udp_rtt = 30.0 + np.random.normal(0, 3.0)
            ecpri = 400.0 + np.random.normal(0, 30.0)
            lbm_rtt = 28.0 + np.random.normal(0, 3.0)

            data.append({
                "timestamp": timestamp.strftime("%Y-%m-%d %H:%M:%S"),
                "endpoint_id": "o-ru-test-001",
                "site_name": "Test-Site-A",
                "zone": "Urban",
                "udp_echo_rtt_ms": round(udp_rtt, 2),
                "ecpri_delay_us": round(ecpri, 2),
                "lbm_rtt_ms": round(lbm_rtt, 2),
                "lbm_success": False,
                "ccm_interval_ms": 1000,
                "ccm_miss_count": 2,
                "label": "anomaly",
                "scenario": "ë³µí•© ì¥ì•  (Multi-metric)"
            })

        base_time += timedelta(minutes=15)

        # ========================================
        # Scenario 6: ì •ìƒ ë³µêµ¬ - 15ë¶„
        # ========================================
        print("  [6/6] ì •ìƒ ë³µêµ¬ íŒ¨í„´ ìƒì„± ì¤‘...")
        for i in range(90):
            timestamp = base_time + timedelta(seconds=i * 10)

            data.append({
                "timestamp": timestamp.strftime("%Y-%m-%d %H:%M:%S"),
                "endpoint_id": "o-ru-test-001",
                "site_name": "Test-Site-A",
                "zone": "Urban",
                "udp_echo_rtt_ms": round(5.0 + np.random.normal(0, 0.3), 2),
                "ecpri_delay_us": round(100.0 + np.random.normal(0, 5.0), 2),
                "lbm_rtt_ms": round(7.0 + np.random.normal(0, 0.4), 2),
                "lbm_success": True,
                "ccm_interval_ms": 1000,
                "ccm_miss_count": 0,
                "label": "normal",
                "scenario": "ì •ìƒ ë³µêµ¬"
            })

        return pd.DataFrame(data)


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    print("\n" + "=" * 70)
    print("í•™ìŠµ/ì¶”ë¡  ë°ì´í„° ìƒì„±")
    print("=" * 70)
    print("\nì´ìƒ íƒì§€ ì›Œí¬í”Œë¡œìš°:")
    print("  1. í•™ìŠµ: ì •ìƒ ë°ì´í„°ë¡œë§Œ í•™ìŠµ (ì •ìƒ íŒ¨í„´ í•™ìŠµ)")
    print("  2. ì¶”ë¡ : ì •ìƒ/ë¹„ì •ìƒ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ (ì´ìƒ ì—¬ë¶€ íŒë‹¨)")
    print("=" * 70)

    output_dir = Path(__file__).parent.parent / "data"
    generator = TrainingInferenceDataGenerator(output_dir)

    # ========================================
    # 1. í•™ìŠµ ë°ì´í„° (ì •ìƒë§Œ)
    # ========================================
    print("\n[1/2] í•™ìŠµìš© ë°ì´í„° ìƒì„± ì¤‘ (ì •ìƒ ë°ì´í„°ë§Œ)...")
    print("  - ì—”ë“œí¬ì¸íŠ¸ ìˆ˜: 5ê°œ")
    print("  - ê¸°ê°„: 48ì‹œê°„")
    print("  - ê°„ê²©: 30ì´ˆ")

    df_training = generator.generate_normal_training_data(
        num_endpoints=5,
        duration_hours=48,
        interval_seconds=30
    )

    # CSV ì €ì¥
    training_csv = output_dir / "training_normal_only.csv"
    df_training.to_csv(training_csv, index=False)
    print(f"\nâœ… í•™ìŠµ ë°ì´í„° ì €ì¥: {training_csv}")
    print(f"   ë ˆì½”ë“œ ìˆ˜: {len(df_training):,}ê°œ")
    print(f"   íŒŒì¼ í¬ê¸°: {training_csv.stat().st_size / 1024:.2f} KB")
    print(f"   ëª¨ë“  ë ˆì½”ë“œ: ì •ìƒ (label=normal)")

    # Parquet ì €ì¥ (í•™ìŠµ ì‹œ ì‚¬ìš©)
    training_parquet = output_dir / "training" / "normal_data.parquet"
    training_parquet.parent.mkdir(parents=True, exist_ok=True)
    df_training.to_parquet(training_parquet, engine="pyarrow", compression="snappy")
    print(f"   Parquet: {training_parquet}")

    # ========================================
    # 2. ì¶”ë¡  í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì •ìƒ + ë¹„ì •ìƒ)
    # ========================================
    print("\n[2/2] ì¶”ë¡  í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„± ì¤‘ (ì •ìƒ + ë¹„ì •ìƒ)...")

    df_inference = generator.generate_inference_test_data()

    # CSV ì €ì¥
    inference_csv = output_dir / "inference_test_scenarios.csv"
    df_inference.to_csv(inference_csv, index=False)
    print(f"\nâœ… ì¶”ë¡  í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥: {inference_csv}")
    print(f"   ë ˆì½”ë“œ ìˆ˜: {len(df_inference):,}ê°œ")
    print(f"   íŒŒì¼ í¬ê¸°: {inference_csv.stat().st_size / 1024:.2f} KB")

    # ë¼ë²¨ ë¶„í¬
    label_dist = df_inference['label'].value_counts()
    print(f"\n   ë¼ë²¨ ë¶„í¬:")
    for label, count in label_dist.items():
        percentage = count / len(df_inference) * 100
        print(f"     {label}: {count:,}ê°œ ({percentage:.1f}%)")

    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ë¶„í¬
    print(f"\n   ì‹œë‚˜ë¦¬ì˜¤ë³„:")
    scenario_dist = df_inference.groupby(['scenario', 'label']).size()
    for (scenario, label), count in scenario_dist.items():
        print(f"     [{label:7}] {scenario}: {count:,}ê°œ")

    print("\n" + "=" * 70)
    print("âœ… ëª¨ë“  ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    print("=" * 70)

    print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"  1. {training_csv.name}")
    print(f"     - ìš©ë„: ëª¨ë¸ í•™ìŠµ")
    print(f"     - ë‚´ìš©: ì •ìƒ ë°ì´í„°ë§Œ ({len(df_training):,}ê°œ)")
    print(f"     - ëª…ë ¹: python scripts/train_models.py")

    print(f"\n  2. {inference_csv.name}")
    print(f"     - ìš©ë„: ì¶”ë¡  í…ŒìŠ¤íŠ¸")
    print(f"     - ë‚´ìš©: ì •ìƒ + ë¹„ì •ìƒ ({len(df_inference):,}ê°œ)")
    print(f"     - ëª…ë ¹: python scripts/test_inference.py")

    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. í•™ìŠµ: python scripts/train_models.py")
    print("  2. ì¶”ë¡ : python scripts/test_inference.py")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
