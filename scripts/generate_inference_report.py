#!/usr/bin/env python3
"""
ì¶”ë¡  ê²°ê³¼ ìƒì„¸ ë³´ê³ ì„œ ìƒì„±

Usage:
    python scripts/generate_inference_report.py \\
        --input data/inference_results.csv \\
        --output reports/inference_report.md
"""

import argparse
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns


def generate_report(input_file: Path, output_file: Path):
    """ì¶”ë¡  ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""

    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(input_file)

    # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜
    df['timestamp_dt'] = pd.to_datetime(df['timestamp'], unit='ms')

    # ë³´ê³ ì„œ ì‘ì„±
    report_lines = []

    # í—¤ë”
    report_lines.append("# OCAD ì¶”ë¡  ê²°ê³¼ ë³´ê³ ì„œ")
    report_lines.append("")
    report_lines.append(f"**ìƒì„± ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"**ì…ë ¥ íŒŒì¼**: {input_file}")
    report_lines.append(f"**ì´ ë ˆì½”ë“œ**: {len(df):,}ê°œ")
    report_lines.append("")
    report_lines.append("---")
    report_lines.append("")

    # 1. ì „ì²´ ìš”ì•½
    report_lines.append("## ğŸ“Š ì „ì²´ ìš”ì•½")
    report_lines.append("")

    # ì‹œê°„ ë²”ìœ„
    start_time = df['timestamp_dt'].min()
    end_time = df['timestamp_dt'].max()
    duration = end_time - start_time
    report_lines.append(f"- **ë¶„ì„ ê¸°ê°„**: {start_time} ~ {end_time}")
    report_lines.append(f"- **ë¶„ì„ ì‹œê°„**: {duration}")
    report_lines.append("")

    # ì—”ë“œí¬ì¸íŠ¸
    endpoints = df['endpoint_id'].unique()
    report_lines.append(f"- **ì—”ë“œí¬ì¸íŠ¸ ìˆ˜**: {len(endpoints)}ê°œ")
    for endpoint in endpoints:
        count = len(df[df['endpoint_id'] == endpoint])
        report_lines.append(f"  - `{endpoint}`: {count:,}ê°œ ë ˆì½”ë“œ")
    report_lines.append("")

    # ë¼ë²¨ ë¶„í¬
    if 'label' in df.columns:
        label_dist = df['label'].value_counts()
        report_lines.append("### ì‹¤ì œ ë¼ë²¨ ë¶„í¬")
        report_lines.append("")
        for label, count in label_dist.items():
            pct = count / len(df) * 100
            report_lines.append(f"- **{label}**: {count:,}ê°œ ({pct:.1f}%)")
        report_lines.append("")

    # ì˜ˆì¸¡ ë¶„í¬
    pred_dist = df['predicted_label'].value_counts()
    report_lines.append("### ì˜ˆì¸¡ ë¼ë²¨ ë¶„í¬")
    report_lines.append("")
    for label, count in pred_dist.items():
        pct = count / len(df) * 100
        report_lines.append(f"- **{label}**: {count:,}ê°œ ({pct:.1f}%)")
    report_lines.append("")

    report_lines.append("---")
    report_lines.append("")

    # 2. ì„±ëŠ¥ ì§€í‘œ
    if 'label' in df.columns:
        report_lines.append("## ğŸ¯ ì„±ëŠ¥ ì§€í‘œ")
        report_lines.append("")

        # ì •í™•ë„
        accuracy = (df['label'] == df['predicted_label']).mean() * 100
        report_lines.append(f"### ì •í™•ë„: **{accuracy:.2f}%**")
        report_lines.append("")

        # Confusion Matrix
        cm = confusion_matrix(df['label'], df['predicted_label'])
        report_lines.append("### Confusion Matrix")
        report_lines.append("")
        report_lines.append("```")
        report_lines.append("ì˜ˆì¸¡       anomaly  normal")
        report_lines.append("ì‹¤ì œ")

        labels = sorted(df['label'].unique())
        for i, actual_label in enumerate(labels):
            row = f"{actual_label:10s}"
            for j in range(len(labels)):
                row += f" {cm[i][j]:7d}"
            report_lines.append(row)
        report_lines.append("```")
        report_lines.append("")

        # ì„¸ë¶€ ì§€í‘œ
        from sklearn.metrics import precision_recall_fscore_support

        precision, recall, f1, support = precision_recall_fscore_support(
            df['label'], df['predicted_label'], average='binary', pos_label='anomaly'
        )

        report_lines.append("### ì„¸ë¶€ ì„±ëŠ¥ ì§€í‘œ")
        report_lines.append("")
        report_lines.append(f"- **Precision (ì •ë°€ë„)**: {precision:.2%}")
        report_lines.append(f"  - ì´ìƒìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œ ì´ìƒ ë¹„ìœ¨")
        report_lines.append(f"- **Recall (ì¬í˜„ìœ¨)**: {recall:.2%}")
        report_lines.append(f"  - ì‹¤ì œ ì´ìƒ ì¤‘ íƒì§€í•œ ë¹„ìœ¨")
        report_lines.append(f"- **F1 Score**: {f1:.2%}")
        report_lines.append(f"  - Precisionê³¼ Recallì˜ ì¡°í™” í‰ê· ")
        report_lines.append("")

        # True/False Positive/Negative
        tp = ((df['label'] == 'anomaly') & (df['predicted_label'] == 'anomaly')).sum()
        fp = ((df['label'] == 'normal') & (df['predicted_label'] == 'anomaly')).sum()
        tn = ((df['label'] == 'normal') & (df['predicted_label'] == 'normal')).sum()
        fn = ((df['label'] == 'anomaly') & (df['predicted_label'] == 'normal')).sum()

        report_lines.append("### ë¶„ë¥˜ ê²°ê³¼ ìƒì„¸")
        report_lines.append("")
        report_lines.append(f"- **True Positive (TP)**: {tp:,}ê°œ - âœ… ì´ìƒì„ ì´ìƒìœ¼ë¡œ ì •í™•íˆ íƒì§€")
        report_lines.append(f"- **False Positive (FP)**: {fp:,}ê°œ - âš ï¸ ì •ìƒì„ ì´ìƒìœ¼ë¡œ ì˜¤íƒ")
        report_lines.append(f"- **True Negative (TN)**: {tn:,}ê°œ - âœ… ì •ìƒì„ ì •ìƒìœ¼ë¡œ ì •í™•íˆ ë¶„ë¥˜")
        report_lines.append(f"- **False Negative (FN)**: {fn:,}ê°œ - âŒ ì´ìƒì„ ì •ìƒìœ¼ë¡œ ë¯¸íƒ")
        report_lines.append("")

        report_lines.append("---")
        report_lines.append("")

    # 3. íƒì§€ê¸°ë³„ ë¶„ì„
    report_lines.append("## ğŸ” íƒì§€ê¸°ë³„ ë¶„ì„")
    report_lines.append("")

    detector_cols = [col for col in df.columns if col.endswith('_score')]

    for col in detector_cols:
        detector_name = col.replace('_score', '')
        mean_score = df[col].mean()
        max_score = df[col].max()

        # ì ìˆ˜ > 0ì¸ ê²½ìš°
        active = df[df[col] > 0]
        active_count = len(active)
        active_pct = active_count / len(df) * 100

        report_lines.append(f"### {detector_name.replace('_', ' ').title()}")
        report_lines.append("")
        report_lines.append(f"- **í‰ê·  ì ìˆ˜**: {mean_score:.3f}")
        report_lines.append(f"- **ìµœëŒ€ ì ìˆ˜**: {max_score:.3f}")
        report_lines.append(f"- **í™œì„±í™” íšŸìˆ˜**: {active_count:,}íšŒ ({active_pct:.1f}%)")

        if len(active) > 0:
            report_lines.append(f"- **í™œì„±í™” ì‹œ í‰ê·  ì ìˆ˜**: {active[col].mean():.3f}")
        report_lines.append("")

    report_lines.append("---")
    report_lines.append("")

    # 4. ë©”íŠ¸ë¦­ í†µê³„
    report_lines.append("## ğŸ“ˆ ë©”íŠ¸ë¦­ í†µê³„")
    report_lines.append("")

    metric_cols = ['udp_echo_rtt', 'ecpri_delay', 'lbm_rtt']

    for col in metric_cols:
        if col not in df.columns:
            continue

        col_data = df[col]

        report_lines.append(f"### {col.replace('_', ' ').upper()}")
        report_lines.append("")
        report_lines.append(f"- **í‰ê· **: {col_data.mean():.2f}")
        report_lines.append(f"- **í‘œì¤€í¸ì°¨**: {col_data.std():.2f}")
        report_lines.append(f"- **ìµœì†Œê°’**: {col_data.min():.2f}")
        report_lines.append(f"- **ìµœëŒ€ê°’**: {col_data.max():.2f}")
        report_lines.append(f"- **ì¤‘ì•™ê°’**: {col_data.median():.2f}")
        report_lines.append(f"- **P95**: {col_data.quantile(0.95):.2f}")
        report_lines.append(f"- **P99**: {col_data.quantile(0.99):.2f}")
        report_lines.append("")

    report_lines.append("---")
    report_lines.append("")

    # 5. False Negative ë¶„ì„ (ì´ìƒì„ ì •ìƒìœ¼ë¡œ ì˜¤íŒ)
    if 'label' in df.columns:
        false_negatives = df[(df['label'] == 'anomaly') & (df['predicted_label'] == 'normal')]

        if len(false_negatives) > 0:
            report_lines.append("## âŒ False Negative ë¶„ì„ (ë¯¸íƒì§€)")
            report_lines.append("")
            report_lines.append(f"**ì´ {len(false_negatives):,}ê±´ì˜ ì´ìƒì´ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**")
            report_lines.append("")

            report_lines.append("### ë¯¸íƒì§€ ë©”íŠ¸ë¦­ ë²”ìœ„")
            report_lines.append("")
            for col in metric_cols:
                if col in false_negatives.columns:
                    fn_data = false_negatives[col]
                    report_lines.append(f"- **{col}**: {fn_data.min():.2f} ~ {fn_data.max():.2f} (í‰ê· : {fn_data.mean():.2f})")
            report_lines.append("")

            report_lines.append("### ë¯¸íƒì§€ ì‚¬ë¡€ (ì²˜ìŒ 10ê°œ)")
            report_lines.append("")
            report_lines.append("| ì‹œê°„ | UDP RTT | eCPRI Delay | LBM RTT | Composite Score |")
            report_lines.append("|------|---------|-------------|---------|-----------------|")

            for _, row in false_negatives.head(10).iterrows():
                time_str = row['timestamp_dt'].strftime('%H:%M:%S')
                report_lines.append(
                    f"| {time_str} | "
                    f"{row.get('udp_echo_rtt', 0):.2f} | "
                    f"{row.get('ecpri_delay', 0):.2f} | "
                    f"{row.get('lbm_rtt', 0):.2f} | "
                    f"{row.get('composite_score', 0):.3f} |"
                )

            report_lines.append("")
            report_lines.append("---")
            report_lines.append("")

    # 6. íƒì§€ëœ ì´ìƒ ì¼€ì´ìŠ¤ (Top 10)
    anomalies = df[df['predicted_label'] == 'anomaly'].sort_values('composite_score', ascending=False)

    if len(anomalies) > 0:
        report_lines.append("## âš ï¸ íƒì§€ëœ ì´ìƒ ì¼€ì´ìŠ¤ (ìƒìœ„ 10ê°œ)")
        report_lines.append("")
        report_lines.append("ê°€ì¥ ë†’ì€ ì´ìƒ ì ìˆ˜ë¥¼ ê¸°ë¡í•œ ì¼€ì´ìŠ¤ë“¤:")
        report_lines.append("")

        report_lines.append("| ìˆœìœ„ | ì‹œê°„ | UDP RTT | eCPRI Delay | LBM RTT | Composite Score | ì‹¤ì œ ë¼ë²¨ |")
        report_lines.append("|------|------|---------|-------------|---------|-----------------|-----------|")

        for idx, (_, row) in enumerate(anomalies.head(10).iterrows(), 1):
            time_str = row['timestamp_dt'].strftime('%H:%M:%S')
            actual_label = row.get('label', '-')
            match = "âœ…" if actual_label == 'anomaly' else "âŒ"

            report_lines.append(
                f"| {idx} | {time_str} | "
                f"{row.get('udp_echo_rtt', 0):.2f} | "
                f"{row.get('ecpri_delay', 0):.2f} | "
                f"{row.get('lbm_rtt', 0):.2f} | "
                f"{row.get('composite_score', 0):.3f} | "
                f"{actual_label} {match} |"
            )

        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

    # 7. ì‹œê°„ëŒ€ë³„ ë¶„ì„
    if 'label' in df.columns:
        report_lines.append("## ğŸ“… ì‹œê°„ëŒ€ë³„ ë¶„ì„")
        report_lines.append("")

        # 5ë¶„ ê°„ê²©ìœ¼ë¡œ ê·¸ë£¹í™”
        df['time_window'] = df['timestamp_dt'].dt.floor('5min')
        time_analysis = df.groupby('time_window').agg({
            'predicted_label': lambda x: (x == 'anomaly').sum(),
            'composite_score': 'mean'
        }).reset_index()

        report_lines.append("### 5ë¶„ ê°„ê²© ì´ìƒ íƒì§€ ë¹ˆë„")
        report_lines.append("")

        for _, row in time_analysis.head(20).iterrows():
            time_str = row['time_window'].strftime('%H:%M')
            anomaly_count = int(row['predicted_label'])
            avg_score = row['composite_score']

            bar = "â–ˆ" * max(1, int(anomaly_count / 2))
            report_lines.append(f"`{time_str}` {bar} {anomaly_count}ê±´ (í‰ê·  ì ìˆ˜: {avg_score:.3f})")

        report_lines.append("")
        report_lines.append("---")
        report_lines.append("")

    # 8. ê¶Œì¥ ì‚¬í•­
    report_lines.append("## ğŸ’¡ ê¶Œì¥ ì‚¬í•­")
    report_lines.append("")

    if 'label' in df.columns:
        fn_rate = fn / (tp + fn) if (tp + fn) > 0 else 0
        fp_rate = fp / (fp + tn) if (fp + tn) > 0 else 0

        if fn_rate > 0.2:
            report_lines.append("### âš ï¸ ë†’ì€ False Negativeìœ¨")
            report_lines.append("")
            report_lines.append(f"- í˜„ì¬ **{fn_rate:.1%}**ì˜ ì´ìƒì´ íƒì§€ë˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤.")
            report_lines.append("- **ê¶Œì¥ ì¡°ì¹˜**:")
            report_lines.append("  1. íƒì§€ ì„ê³„ê°’ ë‚®ì¶”ê¸° (`--threshold 0.3`)")
            report_lines.append("  2. ë£° ê¸°ë°˜ ì„ê³„ê°’ ì¡°ì • (`--rule-threshold 8.0`)")
            report_lines.append("  3. ë³€í™”ì  íƒì§€ê¸° ì¶”ê°€ ê³ ë ¤")
            report_lines.append("")

        if fp_rate > 0.05:
            report_lines.append("### âš ï¸ False Positive ì£¼ì˜")
            report_lines.append("")
            report_lines.append(f"- í˜„ì¬ **{fp_rate:.1%}**ì˜ ì˜¤íƒì´ ë°œìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            report_lines.append("- **ê¶Œì¥ ì¡°ì¹˜**:")
            report_lines.append("  1. íƒì§€ ì„ê³„ê°’ ë†’ì´ê¸° (`--threshold 0.7`)")
            report_lines.append("  2. ì—¬ëŸ¬ íƒì§€ê¸°ì˜ í•©ì˜ ìš”êµ¬")
            report_lines.append("")

        if fn_rate <= 0.2 and fp_rate <= 0.05:
            report_lines.append("### âœ… ì–‘í˜¸í•œ íƒì§€ ì„±ëŠ¥")
            report_lines.append("")
            report_lines.append("í˜„ì¬ íƒì§€ ì„±ëŠ¥ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤:")
            report_lines.append(f"- False Negativeìœ¨: {fn_rate:.1%} (ëª©í‘œ: â‰¤ 20%)")
            report_lines.append(f"- False Positiveìœ¨: {fp_rate:.1%} (ëª©í‘œ: â‰¤ 5%)")
            report_lines.append("")

    report_lines.append("---")
    report_lines.append("")

    # í‘¸í„°
    report_lines.append("## ğŸ“ ë¶€ë¡")
    report_lines.append("")
    report_lines.append("### íŒŒì¼ ì •ë³´")
    report_lines.append("")
    report_lines.append(f"- **ë³´ê³ ì„œ íŒŒì¼**: {output_file}")
    report_lines.append(f"- **ë°ì´í„° íŒŒì¼**: {input_file}")
    report_lines.append(f"- **ìƒì„± ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append("")

    # íŒŒì¼ ì €ì¥
    output_file.parent.mkdir(parents=True, exist_ok=True)
    output_file.write_text("\n".join(report_lines), encoding='utf-8')

    print(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_file}")
    print(f"   íŒŒì¼ í¬ê¸°: {output_file.stat().st_size / 1024:.2f} KB")


def main():
    parser = argparse.ArgumentParser(description="ì¶”ë¡  ê²°ê³¼ ìƒì„¸ ë³´ê³ ì„œ ìƒì„±")
    parser.add_argument(
        "--input",
        type=Path,
        default=Path("data/inference_results.csv"),
        help="ì¶”ë¡  ê²°ê³¼ CSV íŒŒì¼ (ê¸°ë³¸ê°’: data/inference_results.csv)"
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=None,
        help="ë³´ê³ ì„œ ì¶œë ¥ íŒŒì¼ (ê¸°ë³¸ê°’: reports/inference_report_YYYYMMDD_HHMMSS.md)"
    )

    args = parser.parse_args()

    # ê¸°ë³¸ ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    if args.output is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        args.output = Path(f"reports/inference_report_{timestamp}.md")

    print("="*70)
    print("OCAD ì¶”ë¡  ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±")
    print("="*70)
    print(f"ì…ë ¥: {args.input}")
    print(f"ì¶œë ¥: {args.output}")
    print("")

    if not args.input.exists():
        print(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input}")
        return 1

    generate_report(args.input, args.output)

    print("")
    print("ë³´ê³ ì„œ í™•ì¸:")
    print(f"  cat {args.output}")
    print(f"  code {args.output}")
    print("="*70)

    return 0


if __name__ == "__main__":
    exit(main())
